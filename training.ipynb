{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, BertForTokenClassification\n",
    "\n",
    "from model_trainer import GeneralModelTrainer\n",
    "\n",
    "from blstm.dataset import TextDataset\n",
    "from blstm.lstm_token_classifier import LSTMTokenClassifier\n",
    "from blstm.utils import create_glove_matrix\n",
    "# from blstm.model_trainer import ModelTrainer\n",
    "\n",
    "from bert.bert_dataset import BertTextDataset\n",
    "# from bert.bert_trainer import ModelTrainer\n",
    "# from bert.bert_for_token_classification_weighted import BertForTokenClassificationWeighted\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "weights_dir = './weights'\n",
    "device = 'cuda'\n",
    "max_line_len = 150\n",
    "# batch_size = 128  # BERT\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATASET] Maximum line length: 150\n",
      "[DATASET] Vocabulary size: 18928\n",
      "[DATASET] Maximum line length: 150\n",
      "[DATASET] Vocabulary size: 18928\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(base_path=data_dir,\n",
    "                            split_name='train_small',\n",
    "                            max_len=max_line_len)\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "\n",
    "val_dataset = TextDataset(base_path=data_dir,\n",
    "                          split_name='dev',\n",
    "                          max_len=max_line_len,\n",
    "                          vocab=vocab)\n",
    "\n",
    "# train_dataset = BERTTextDataset(base_path=data_dir,\n",
    "#                                 split_name='train',\n",
    "#                                 max_len=max_line_len)\n",
    "\n",
    "# val_dataset = BERTTextDataset(base_path=data_dir,\n",
    "#                               split_name='dev',\n",
    "#                               max_len=max_line_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=6)\n",
    "\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        sampler=val_sampler,\n",
    "                        num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  25,  136, 2651,  812,    8,   13,  808,   12,  141, 1967,   25, 2627,\n",
      "        8703,   16,  356, 1726,    3,  497,  473,  471, 1256,   12,   13,  655,\n",
      "         311,    3,   13,  555,  384,   27,   19,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    batch_lines, batch_labels, batch_masks = batch\n",
    "    print(batch_lines[10])\n",
    "    print(batch_labels[10])\n",
    "    print(batch_masks[10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings found for 18310/18928 tokens\n",
      "2376802 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "word2id = train_dataset.word2id\n",
    "pretrained_embeddings = create_glove_matrix('../glove.6B/glove.6B.100d.txt',\n",
    "                                                word2id,\n",
    "                                                embed_dim=100)\n",
    "\n",
    "model = LSTMTokenClassifier(len(word2id),\n",
    "                            embedding_dim=100,\n",
    "                            hidden_dim=200,\n",
    "                            batch_size=batch_size,\n",
    "                            pretrained_embeddings=pretrained_embeddings).to(device)\n",
    "\n",
    "num_trainable_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('{} trainable parameters'.format(num_trainable_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108893186 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    # 2 labels -> logits: (32, 200, 2)\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ").to(device)\n",
    "\n",
    "num_trainable_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('{} trainable parameters'.format(num_trainable_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "            'weight_decay_rate': 0.01\n",
    "        },\n",
    "        {\n",
    "            'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "            'weight_decay_rate': 0.0\n",
    "        }\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('./weights/subst_detector_0019_0.0730.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(11.0))\n",
    "# optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 11.0]).to(device))\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=5e-5,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "trainer = GeneralModelTrainer(model, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "[100/ 196] loss: 0.669\n",
      "Epoch 0 train loss: 0.6669\n",
      "Validation Accuracy: 0.93611\n",
      "Precision: 0.14669344068561985\n",
      "Recall: 0.6849708389412292\n",
      "Validation F0.5-Score: 0.1740482519937804\n",
      "Epoch 0 val loss: 0.6291\n",
      "--------------------------------------------------\n",
      "Epoch 1/9\n",
      "[100/ 196] loss: 0.605\n",
      "Epoch 1 train loss: 0.6158\n",
      "Validation Accuracy: 0.9372626666666667\n",
      "Precision: 0.15675722178675894\n",
      "Recall: 0.7357110812023329\n",
      "Validation F0.5-Score: 0.18603685569466316\n",
      "Epoch 1 val loss: 0.5976\n",
      "--------------------------------------------------\n",
      "Epoch 2/9\n",
      "[100/ 196] loss: 0.585\n",
      "Epoch 2 train loss: 0.5955\n",
      "Validation Accuracy: 0.9363773333333333\n",
      "Precision: 0.15883055337885743\n",
      "Recall: 0.763840287124271\n",
      "Validation F0.5-Score: 0.1887273485060101\n",
      "Epoch 2 val loss: 0.5825\n",
      "--------------------------------------------------\n",
      "Epoch 3/9\n",
      "[100/ 196] loss: 0.590\n",
      "Epoch 3 train loss: 0.5839\n",
      "Validation Accuracy: 0.9362353333333333\n",
      "Precision: 0.16030562630238482\n",
      "Recall: 0.7765365634813818\n",
      "Validation F0.5-Score: 0.19054800854268036\n",
      "Epoch 3 val loss: 0.5736\n",
      "--------------------------------------------------\n",
      "Epoch 4/9\n",
      "[100/ 196] loss: 0.575\n",
      "Epoch 4 train loss: 0.5768\n",
      "Validation Accuracy: 0.9392086666666667\n",
      "Precision: 0.16497281736576447\n",
      "Recall: 0.7610139075818753\n",
      "Validation F0.5-Score: 0.19561467035070643\n",
      "Epoch 4 val loss: 0.5681\n",
      "--------------------------------------------------\n",
      "Epoch 5/9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1d370c211fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/grammarly-test-task/substituted-words/model_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, val_loader, start_epoch, num_epochs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mavg_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {} train loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/grammarly-test-task/substituted-words/model_trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mevery_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch-nlp/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch-nlp/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = trainer.fit(train_loader, val_loader, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training after non-ascii characters removed 22.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "[100/34598] loss: 0.157\n",
      "[200/34598] loss: 0.153\n",
      "[300/34598] loss: 0.131\n",
      "[400/34598] loss: 0.137\n",
      "[500/34598] loss: 0.142\n",
      "[600/34598] loss: 0.137\n",
      "[700/34598] loss: 0.129\n",
      "[800/34598] loss: 0.114\n",
      "[900/34598] loss: 0.170\n",
      "[1000/34598] loss: 0.129\n",
      "[1100/34598] loss: 0.123\n",
      "[1200/34598] loss: 0.149\n",
      "[1300/34598] loss: 0.142\n",
      "[1400/34598] loss: 0.123\n",
      "[1500/34598] loss: 0.106\n",
      "[1600/34598] loss: 0.134\n",
      "[1700/34598] loss: 0.132\n",
      "[1800/34598] loss: 0.114\n",
      "[1900/34598] loss: 0.117\n",
      "[2000/34598] loss: 0.118\n",
      "[2100/34598] loss: 0.121\n",
      "[2200/34598] loss: 0.112\n",
      "[2300/34598] loss: 0.119\n",
      "[2400/34598] loss: 0.125\n",
      "[2500/34598] loss: 0.120\n",
      "[2600/34598] loss: 0.123\n",
      "[2700/34598] loss: 0.120\n",
      "[2800/34598] loss: 0.121\n",
      "[2900/34598] loss: 0.124\n",
      "[3000/34598] loss: 0.099\n",
      "[3100/34598] loss: 0.085\n",
      "[3200/34598] loss: 0.135\n",
      "[3300/34598] loss: 0.147\n",
      "[3400/34598] loss: 0.100\n",
      "[3500/34598] loss: 0.134\n",
      "[3600/34598] loss: 0.122\n",
      "[3700/34598] loss: 0.103\n",
      "[3800/34598] loss: 0.120\n",
      "[3900/34598] loss: 0.092\n",
      "[4000/34598] loss: 0.117\n",
      "[4100/34598] loss: 0.111\n",
      "[4200/34598] loss: 0.102\n",
      "[4300/34598] loss: 0.115\n",
      "[4400/34598] loss: 0.109\n",
      "[4500/34598] loss: 0.097\n",
      "[4600/34598] loss: 0.110\n",
      "[4700/34598] loss: 0.114\n",
      "[4800/34598] loss: 0.106\n",
      "[4900/34598] loss: 0.107\n",
      "[5000/34598] loss: 0.121\n",
      "[5100/34598] loss: 0.105\n",
      "[5200/34598] loss: 0.088\n",
      "[5300/34598] loss: 0.094\n",
      "[5400/34598] loss: 0.115\n",
      "[5500/34598] loss: 0.120\n",
      "[5600/34598] loss: 0.114\n",
      "[5700/34598] loss: 0.104\n",
      "[5800/34598] loss: 0.111\n",
      "[5900/34598] loss: 0.112\n",
      "[6000/34598] loss: 0.121\n",
      "[6100/34598] loss: 0.108\n",
      "[6200/34598] loss: 0.096\n",
      "[6300/34598] loss: 0.108\n",
      "[6400/34598] loss: 0.083\n",
      "[6500/34598] loss: 0.107\n",
      "[6600/34598] loss: 0.110\n",
      "[6700/34598] loss: 0.101\n",
      "[6800/34598] loss: 0.112\n",
      "[6900/34598] loss: 0.110\n",
      "[7000/34598] loss: 0.083\n",
      "[7100/34598] loss: 0.100\n",
      "[7200/34598] loss: 0.089\n",
      "[7300/34598] loss: 0.097\n",
      "[7400/34598] loss: 0.112\n",
      "[7500/34598] loss: 0.096\n",
      "[7600/34598] loss: 0.081\n",
      "[7700/34598] loss: 0.099\n",
      "[7800/34598] loss: 0.104\n",
      "[7900/34598] loss: 0.115\n",
      "[8000/34598] loss: 0.103\n",
      "[8100/34598] loss: 0.085\n",
      "[8300/34598] loss: 0.083\n",
      "[8400/34598] loss: 0.096\n",
      "[8500/34598] loss: 0.092\n",
      "[8600/34598] loss: 0.124\n",
      "[8700/34598] loss: 0.107\n",
      "[8800/34598] loss: 0.144\n",
      "[8900/34598] loss: 0.131\n",
      "[9000/34598] loss: 0.088\n",
      "[9100/34598] loss: 0.088\n",
      "[9200/34598] loss: 0.101\n",
      "[9300/34598] loss: 0.088\n",
      "[9400/34598] loss: 0.086\n",
      "[9500/34598] loss: 0.103\n",
      "[9600/34598] loss: 0.110\n",
      "[9700/34598] loss: 0.097\n",
      "[9800/34598] loss: 0.091\n",
      "[9900/34598] loss: 0.113\n",
      "[10000/34598] loss: 0.119\n",
      "[10100/34598] loss: 0.080\n",
      "[10200/34598] loss: 0.136\n",
      "[10300/34598] loss: 0.125\n",
      "[10400/34598] loss: 0.113\n",
      "[10500/34598] loss: 0.111\n",
      "[10600/34598] loss: 0.110\n",
      "[10700/34598] loss: 0.108\n",
      "[10800/34598] loss: 0.114\n",
      "[10900/34598] loss: 0.101\n",
      "[11000/34598] loss: 0.096\n",
      "[11100/34598] loss: 0.095\n",
      "[11200/34598] loss: 0.082\n",
      "[11300/34598] loss: 0.108\n",
      "[11400/34598] loss: 0.081\n",
      "[11500/34598] loss: 0.109\n",
      "[11600/34598] loss: 0.109\n",
      "[11700/34598] loss: 0.090\n",
      "[11800/34598] loss: 0.106\n",
      "[11900/34598] loss: 0.100\n",
      "[12000/34598] loss: 0.119\n",
      "[12100/34598] loss: 0.083\n",
      "[12200/34598] loss: 0.109\n",
      "[12300/34598] loss: 0.097\n",
      "[12400/34598] loss: 0.126\n",
      "[12500/34598] loss: 0.089\n",
      "[12600/34598] loss: 0.098\n",
      "[12700/34598] loss: 0.094\n",
      "[12800/34598] loss: 0.108\n",
      "[12900/34598] loss: 0.099\n",
      "[13000/34598] loss: 0.098\n",
      "[13100/34598] loss: 0.127\n",
      "[13200/34598] loss: 0.100\n",
      "[13300/34598] loss: 0.098\n",
      "[13400/34598] loss: 0.101\n",
      "[13500/34598] loss: 0.097\n",
      "[13600/34598] loss: 0.123\n",
      "[13700/34598] loss: 0.103\n",
      "[13800/34598] loss: 0.079\n",
      "[13900/34598] loss: 0.108\n",
      "[14000/34598] loss: 0.103\n",
      "[14100/34598] loss: 0.115\n",
      "[14200/34598] loss: 0.066\n",
      "[14300/34598] loss: 0.101\n",
      "[14400/34598] loss: 0.080\n",
      "[14500/34598] loss: 0.085\n",
      "[14600/34598] loss: 0.139\n",
      "[14700/34598] loss: 0.097\n",
      "[14800/34598] loss: 0.084\n",
      "[14900/34598] loss: 0.109\n",
      "[15000/34598] loss: 0.110\n",
      "[15100/34598] loss: 0.103\n",
      "[15200/34598] loss: 0.117\n",
      "[15300/34598] loss: 0.094\n",
      "[15400/34598] loss: 0.101\n",
      "[15500/34598] loss: 0.105\n",
      "[15600/34598] loss: 0.091\n",
      "[15700/34598] loss: 0.079\n",
      "[15800/34598] loss: 0.103\n",
      "[15900/34598] loss: 0.101\n",
      "[16000/34598] loss: 0.120\n",
      "[16100/34598] loss: 0.100\n",
      "[16200/34598] loss: 0.114\n",
      "[16300/34598] loss: 0.106\n",
      "[16400/34598] loss: 0.095\n",
      "[16500/34598] loss: 0.115\n",
      "[16600/34598] loss: 0.074\n",
      "[16700/34598] loss: 0.097\n",
      "[16800/34598] loss: 0.111\n",
      "[16900/34598] loss: 0.097\n",
      "[17000/34598] loss: 0.077\n",
      "[17100/34598] loss: 0.104\n",
      "[17200/34598] loss: 0.094\n",
      "[17300/34598] loss: 0.111\n",
      "[17400/34598] loss: 0.102\n",
      "[17500/34598] loss: 0.090\n",
      "[17600/34598] loss: 0.090\n",
      "[17700/34598] loss: 0.104\n",
      "[17800/34598] loss: 0.099\n",
      "[17900/34598] loss: 0.093\n",
      "[18000/34598] loss: 0.094\n",
      "[18100/34598] loss: 0.099\n",
      "[18200/34598] loss: 0.116\n",
      "[18300/34598] loss: 0.078\n",
      "[18400/34598] loss: 0.094\n",
      "[18500/34598] loss: 0.092\n",
      "[18600/34598] loss: 0.072\n",
      "[18700/34598] loss: 0.062\n",
      "[18800/34598] loss: 0.114\n",
      "[18900/34598] loss: 0.112\n",
      "[19000/34598] loss: 0.110\n",
      "[19100/34598] loss: 0.092\n",
      "[19200/34598] loss: 0.078\n",
      "[19300/34598] loss: 0.085\n",
      "[19400/34598] loss: 0.084\n",
      "[19500/34598] loss: 0.120\n",
      "[19600/34598] loss: 0.085\n",
      "[19700/34598] loss: 0.101\n",
      "[19800/34598] loss: 0.085\n",
      "[19900/34598] loss: 0.076\n",
      "[20000/34598] loss: 0.074\n",
      "[20100/34598] loss: 0.121\n",
      "[20200/34598] loss: 0.093\n",
      "[20300/34598] loss: 0.095\n",
      "[20400/34598] loss: 0.088\n",
      "[20500/34598] loss: 0.092\n",
      "[20600/34598] loss: 0.102\n",
      "[20700/34598] loss: 0.074\n",
      "[20800/34598] loss: 0.105\n",
      "[20900/34598] loss: 0.096\n",
      "[21000/34598] loss: 0.121\n",
      "[21100/34598] loss: 0.088\n",
      "[21200/34598] loss: 0.072\n",
      "[21300/34598] loss: 0.121\n",
      "[21400/34598] loss: 0.114\n",
      "[21500/34598] loss: 0.084\n",
      "[21600/34598] loss: 0.072\n",
      "[21700/34598] loss: 0.093\n",
      "[21800/34598] loss: 0.072\n",
      "[21900/34598] loss: 0.097\n",
      "[22000/34598] loss: 0.107\n",
      "[22100/34598] loss: 0.109\n",
      "[22200/34598] loss: 0.102\n",
      "[22300/34598] loss: 0.080\n",
      "[22400/34598] loss: 0.096\n",
      "[22500/34598] loss: 0.121\n",
      "[22600/34598] loss: 0.109\n",
      "[22700/34598] loss: 0.100\n",
      "[22800/34598] loss: 0.117\n",
      "[22900/34598] loss: 0.099\n",
      "[23000/34598] loss: 0.085\n",
      "[23100/34598] loss: 0.096\n",
      "[23200/34598] loss: 0.088\n",
      "[23300/34598] loss: 0.102\n",
      "[23400/34598] loss: 0.119\n",
      "[23500/34598] loss: 0.108\n",
      "[23600/34598] loss: 0.088\n",
      "[23700/34598] loss: 0.065\n",
      "[23800/34598] loss: 0.086\n",
      "[23900/34598] loss: 0.095\n",
      "[24000/34598] loss: 0.096\n",
      "[24100/34598] loss: 0.081\n",
      "[24200/34598] loss: 0.109\n",
      "[24300/34598] loss: 0.088\n",
      "[24400/34598] loss: 0.096\n",
      "[24500/34598] loss: 0.104\n",
      "[24600/34598] loss: 0.059\n",
      "[24700/34598] loss: 0.111\n",
      "[24800/34598] loss: 0.084\n",
      "[24900/34598] loss: 0.093\n",
      "[25000/34598] loss: 0.084\n",
      "[25100/34598] loss: 0.084\n",
      "[25200/34598] loss: 0.111\n",
      "[25300/34598] loss: 0.109\n",
      "[25400/34598] loss: 0.090\n",
      "[25500/34598] loss: 0.103\n",
      "[25600/34598] loss: 0.074\n",
      "[25700/34598] loss: 0.085\n",
      "[25800/34598] loss: 0.099\n",
      "[25900/34598] loss: 0.087\n",
      "[26000/34598] loss: 0.106\n",
      "[26100/34598] loss: 0.105\n",
      "[26200/34598] loss: 0.124\n",
      "[26300/34598] loss: 0.085\n",
      "[26400/34598] loss: 0.073\n",
      "[26500/34598] loss: 0.117\n",
      "[26600/34598] loss: 0.095\n",
      "[26700/34598] loss: 0.083\n",
      "[26800/34598] loss: 0.075\n",
      "[26900/34598] loss: 0.106\n",
      "[27000/34598] loss: 0.091\n",
      "[27100/34598] loss: 0.087\n",
      "[27200/34598] loss: 0.102\n",
      "[27300/34598] loss: 0.083\n",
      "[27400/34598] loss: 0.093\n",
      "[27500/34598] loss: 0.088\n",
      "[27600/34598] loss: 0.089\n",
      "[27700/34598] loss: 0.109\n",
      "[27800/34598] loss: 0.092\n",
      "[27900/34598] loss: 0.080\n",
      "[28000/34598] loss: 0.101\n",
      "[28100/34598] loss: 0.084\n",
      "[28200/34598] loss: 0.096\n",
      "[28300/34598] loss: 0.078\n",
      "[28400/34598] loss: 0.105\n",
      "[28500/34598] loss: 0.118\n",
      "[28600/34598] loss: 0.106\n",
      "[28700/34598] loss: 0.083\n",
      "[28800/34598] loss: 0.096\n",
      "[28900/34598] loss: 0.081\n",
      "[29000/34598] loss: 0.097\n",
      "[29100/34598] loss: 0.083\n",
      "[29200/34598] loss: 0.072\n",
      "[29300/34598] loss: 0.084\n",
      "[29400/34598] loss: 0.084\n",
      "[29500/34598] loss: 0.085\n",
      "[29600/34598] loss: 0.061\n",
      "[29700/34598] loss: 0.101\n",
      "[29800/34598] loss: 0.083\n",
      "[29900/34598] loss: 0.077\n",
      "[30000/34598] loss: 0.099\n",
      "[30100/34598] loss: 0.121\n",
      "[30200/34598] loss: 0.081\n",
      "[30300/34598] loss: 0.088\n",
      "[30400/34598] loss: 0.070\n",
      "[30500/34598] loss: 0.118\n",
      "[30600/34598] loss: 0.094\n",
      "[30700/34598] loss: 0.093\n",
      "[30800/34598] loss: 0.078\n",
      "[30900/34598] loss: 0.111\n",
      "[31000/34598] loss: 0.096\n",
      "[31100/34598] loss: 0.082\n",
      "[31200/34598] loss: 0.115\n",
      "[31300/34598] loss: 0.113\n",
      "[31400/34598] loss: 0.096\n",
      "[31500/34598] loss: 0.077\n",
      "[31600/34598] loss: 0.085\n",
      "[31700/34598] loss: 0.105\n",
      "[31800/34598] loss: 0.083\n",
      "[31900/34598] loss: 0.104\n",
      "[32000/34598] loss: 0.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32100/34598] loss: 0.083\n",
      "[32200/34598] loss: 0.087\n",
      "[32300/34598] loss: 0.077\n",
      "[32400/34598] loss: 0.112\n",
      "[32500/34598] loss: 0.082\n",
      "[32600/34598] loss: 0.094\n",
      "[32700/34598] loss: 0.087\n",
      "[32800/34598] loss: 0.085\n",
      "[32900/34598] loss: 0.089\n",
      "[33000/34598] loss: 0.096\n",
      "[33100/34598] loss: 0.094\n",
      "[33200/34598] loss: 0.106\n",
      "[33300/34598] loss: 0.084\n",
      "[33400/34598] loss: 0.095\n",
      "[33500/34598] loss: 0.083\n",
      "[33600/34598] loss: 0.090\n",
      "[33700/34598] loss: 0.088\n",
      "[33800/34598] loss: 0.107\n",
      "[33900/34598] loss: 0.071\n",
      "[34000/34598] loss: 0.082\n",
      "[34100/34598] loss: 0.096\n",
      "[34200/34598] loss: 0.081\n",
      "[34300/34598] loss: 0.096\n",
      "[34400/34598] loss: 0.090\n",
      "[34500/34598] loss: 0.105\n",
      "Epoch 0 train loss: 0.1008\n",
      "Validation Accuracy: 0.9854173333333334\n",
      "Precision: 0.5072470555178308\n",
      "Recall: 0.9630996309963099\n",
      "Validation F0.5-Score: 0.5602857423663233\n",
      "Epoch 0 val loss: 0.0812\n",
      "--------------------------------------------------\n",
      "Epoch 1/2\n",
      "[100/34598] loss: 0.065\n",
      "[200/34598] loss: 0.059\n",
      "[300/34598] loss: 0.058\n",
      "[400/34598] loss: 0.071\n",
      "[500/34598] loss: 0.070\n",
      "[600/34598] loss: 0.063\n",
      "[700/34598] loss: 0.080\n",
      "[800/34598] loss: 0.057\n",
      "[900/34598] loss: 0.081\n",
      "[1000/34598] loss: 0.073\n",
      "[1100/34598] loss: 0.071\n",
      "[1200/34598] loss: 0.068\n",
      "[1300/34598] loss: 0.077\n",
      "[1400/34598] loss: 0.055\n",
      "[1500/34598] loss: 0.073\n",
      "[1600/34598] loss: 0.065\n",
      "[1700/34598] loss: 0.082\n",
      "[1800/34598] loss: 0.081\n",
      "[1900/34598] loss: 0.073\n",
      "[2000/34598] loss: 0.068\n",
      "[2100/34598] loss: 0.077\n",
      "[2200/34598] loss: 0.068\n",
      "[2300/34598] loss: 0.085\n",
      "[2400/34598] loss: 0.068\n",
      "[2500/34598] loss: 0.061\n",
      "[2600/34598] loss: 0.065\n",
      "[2700/34598] loss: 0.066\n",
      "[2800/34598] loss: 0.069\n",
      "[2900/34598] loss: 0.083\n",
      "[3000/34598] loss: 0.070\n",
      "[3100/34598] loss: 0.067\n",
      "[3200/34598] loss: 0.055\n",
      "[3300/34598] loss: 0.085\n",
      "[3400/34598] loss: 0.072\n",
      "[3500/34598] loss: 0.068\n",
      "[3600/34598] loss: 0.090\n",
      "[3700/34598] loss: 0.117\n",
      "[3800/34598] loss: 0.076\n",
      "[3900/34598] loss: 0.064\n",
      "[4000/34598] loss: 0.067\n",
      "[4100/34598] loss: 0.056\n",
      "[4200/34598] loss: 0.061\n",
      "[4300/34598] loss: 0.064\n",
      "[4400/34598] loss: 0.114\n",
      "[4500/34598] loss: 0.066\n",
      "[4600/34598] loss: 0.070\n",
      "[4700/34598] loss: 0.079\n",
      "[4800/34598] loss: 0.070\n",
      "[4900/34598] loss: 0.061\n",
      "[5000/34598] loss: 0.058\n",
      "[5100/34598] loss: 0.071\n",
      "[5200/34598] loss: 0.076\n",
      "[5300/34598] loss: 0.086\n",
      "[5400/34598] loss: 0.071\n",
      "[5500/34598] loss: 0.100\n",
      "[5600/34598] loss: 0.104\n",
      "[5700/34598] loss: 0.065\n",
      "[5800/34598] loss: 0.071\n",
      "[5900/34598] loss: 0.055\n",
      "[6000/34598] loss: 0.092\n",
      "[6100/34598] loss: 0.097\n",
      "[6200/34598] loss: 0.065\n",
      "[6300/34598] loss: 0.069\n",
      "[6400/34598] loss: 0.056\n",
      "[6500/34598] loss: 0.082\n",
      "[6600/34598] loss: 0.075\n",
      "[6700/34598] loss: 0.080\n",
      "[6800/34598] loss: 0.088\n",
      "[6900/34598] loss: 0.074\n",
      "[7000/34598] loss: 0.076\n",
      "[7100/34598] loss: 0.073\n",
      "[7200/34598] loss: 0.071\n",
      "[7300/34598] loss: 0.096\n",
      "[7400/34598] loss: 0.083\n",
      "[7500/34598] loss: 0.082\n",
      "[7600/34598] loss: 0.066\n",
      "[7700/34598] loss: 0.080\n",
      "[7800/34598] loss: 0.059\n",
      "[7900/34598] loss: 0.071\n",
      "[8000/34598] loss: 0.059\n",
      "[8100/34598] loss: 0.075\n",
      "[8200/34598] loss: 0.072\n",
      "[8300/34598] loss: 0.081\n",
      "[8400/34598] loss: 0.063\n",
      "[8500/34598] loss: 0.093\n",
      "[8600/34598] loss: 0.060\n",
      "[8700/34598] loss: 0.075\n",
      "[8800/34598] loss: 0.070\n",
      "[8900/34598] loss: 0.085\n",
      "[9000/34598] loss: 0.081\n",
      "[9100/34598] loss: 0.074\n",
      "[9200/34598] loss: 0.104\n",
      "[9300/34598] loss: 0.102\n",
      "[9400/34598] loss: 0.095\n",
      "[9500/34598] loss: 0.061\n",
      "[9600/34598] loss: 0.061\n",
      "[9700/34598] loss: 0.075\n",
      "[9800/34598] loss: 0.068\n",
      "[9900/34598] loss: 0.064\n",
      "[10000/34598] loss: 0.054\n",
      "[10100/34598] loss: 0.064\n",
      "[10200/34598] loss: 0.074\n",
      "[10300/34598] loss: 0.052\n",
      "[10400/34598] loss: 0.052\n",
      "[10500/34598] loss: 0.069\n",
      "[10600/34598] loss: 0.079\n",
      "[10700/34598] loss: 0.069\n",
      "[10800/34598] loss: 0.084\n",
      "[10900/34598] loss: 0.056\n",
      "[11000/34598] loss: 0.071\n",
      "[11100/34598] loss: 0.083\n",
      "[11200/34598] loss: 0.059\n",
      "[11300/34598] loss: 0.076\n",
      "[11400/34598] loss: 0.066\n",
      "[11500/34598] loss: 0.064\n",
      "[11600/34598] loss: 0.075\n",
      "[11700/34598] loss: 0.072\n",
      "[11800/34598] loss: 0.057\n",
      "[11900/34598] loss: 0.067\n",
      "[12000/34598] loss: 0.060\n",
      "[12100/34598] loss: 0.079\n",
      "[12200/34598] loss: 0.056\n",
      "[12300/34598] loss: 0.067\n",
      "[12400/34598] loss: 0.081\n",
      "[12500/34598] loss: 0.067\n",
      "[12600/34598] loss: 0.102\n",
      "[12700/34598] loss: 0.077\n",
      "[12800/34598] loss: 0.076\n",
      "[12900/34598] loss: 0.054\n",
      "[13000/34598] loss: 0.079\n",
      "[13100/34598] loss: 0.057\n",
      "[13200/34598] loss: 0.055\n",
      "[13300/34598] loss: 0.115\n",
      "[13400/34598] loss: 0.080\n",
      "[13500/34598] loss: 0.073\n",
      "[13600/34598] loss: 0.090\n",
      "[13700/34598] loss: 0.109\n",
      "[13800/34598] loss: 0.053\n",
      "[13900/34598] loss: 0.067\n",
      "[14000/34598] loss: 0.058\n",
      "[14100/34598] loss: 0.063\n",
      "[14200/34598] loss: 0.059\n",
      "[14300/34598] loss: 0.058\n",
      "[14400/34598] loss: 0.088\n",
      "[14500/34598] loss: 0.062\n",
      "[14600/34598] loss: 0.079\n",
      "[14700/34598] loss: 0.066\n",
      "[14800/34598] loss: 0.105\n",
      "[14900/34598] loss: 0.059\n",
      "[15000/34598] loss: 0.058\n",
      "[15100/34598] loss: 0.078\n",
      "[15200/34598] loss: 0.064\n",
      "[15300/34598] loss: 0.080\n",
      "[15400/34598] loss: 0.058\n",
      "[15500/34598] loss: 0.072\n",
      "[15600/34598] loss: 0.079\n",
      "[15700/34598] loss: 0.076\n",
      "[15800/34598] loss: 0.067\n",
      "[15900/34598] loss: 0.087\n",
      "[16000/34598] loss: 0.081\n",
      "[16100/34598] loss: 0.080\n",
      "[16200/34598] loss: 0.074\n",
      "[16300/34598] loss: 0.065\n",
      "[16400/34598] loss: 0.061\n",
      "[16500/34598] loss: 0.073\n",
      "[16600/34598] loss: 0.060\n",
      "[16700/34598] loss: 0.061\n",
      "[16800/34598] loss: 0.050\n",
      "[16900/34598] loss: 0.104\n",
      "[17000/34598] loss: 0.079\n",
      "[17100/34598] loss: 0.070\n",
      "[17200/34598] loss: 0.067\n",
      "[17300/34598] loss: 0.063\n",
      "[17400/34598] loss: 0.090\n",
      "[17500/34598] loss: 0.060\n",
      "[17600/34598] loss: 0.090\n",
      "[17700/34598] loss: 0.091\n",
      "[17800/34598] loss: 0.083\n",
      "[17900/34598] loss: 0.064\n",
      "[18000/34598] loss: 0.072\n",
      "[18100/34598] loss: 0.078\n",
      "[18200/34598] loss: 0.067\n",
      "[18300/34598] loss: 0.073\n",
      "[18400/34598] loss: 0.077\n",
      "[18500/34598] loss: 0.076\n",
      "[18600/34598] loss: 0.086\n",
      "[18700/34598] loss: 0.096\n",
      "[18800/34598] loss: 0.059\n",
      "[18900/34598] loss: 0.071\n",
      "[19000/34598] loss: 0.067\n",
      "[19100/34598] loss: 0.063\n",
      "[19200/34598] loss: 0.090\n",
      "[19300/34598] loss: 0.077\n",
      "[19400/34598] loss: 0.083\n",
      "[19500/34598] loss: 0.059\n",
      "[19600/34598] loss: 0.065\n",
      "[19700/34598] loss: 0.073\n",
      "[19800/34598] loss: 0.060\n",
      "[19900/34598] loss: 0.075\n",
      "[20000/34598] loss: 0.063\n",
      "[20100/34598] loss: 0.071\n",
      "[20200/34598] loss: 0.074\n",
      "[20300/34598] loss: 0.062\n",
      "[20400/34598] loss: 0.070\n",
      "[20500/34598] loss: 0.085\n",
      "[20600/34598] loss: 0.060\n",
      "[20700/34598] loss: 0.074\n",
      "[20800/34598] loss: 0.076\n",
      "[20900/34598] loss: 0.075\n",
      "[21000/34598] loss: 0.059\n",
      "[21100/34598] loss: 0.089\n",
      "[21200/34598] loss: 0.060\n",
      "[21300/34598] loss: 0.064\n",
      "[21400/34598] loss: 0.082\n",
      "[21500/34598] loss: 0.067\n",
      "[21600/34598] loss: 0.045\n",
      "[21700/34598] loss: 0.068\n",
      "[21800/34598] loss: 0.086\n",
      "[21900/34598] loss: 0.072\n",
      "[22000/34598] loss: 0.063\n",
      "[22100/34598] loss: 0.070\n",
      "[22200/34598] loss: 0.055\n",
      "[22300/34598] loss: 0.070\n",
      "[22400/34598] loss: 0.089\n",
      "[22500/34598] loss: 0.077\n",
      "[22600/34598] loss: 0.078\n",
      "[22700/34598] loss: 0.086\n",
      "[22800/34598] loss: 0.095\n",
      "[22900/34598] loss: 0.055\n",
      "[23000/34598] loss: 0.086\n",
      "[23100/34598] loss: 0.072\n",
      "[23200/34598] loss: 0.081\n",
      "[23300/34598] loss: 0.090\n",
      "[23400/34598] loss: 0.058\n",
      "[23500/34598] loss: 0.060\n",
      "[23600/34598] loss: 0.082\n",
      "[23700/34598] loss: 0.058\n",
      "[23800/34598] loss: 0.067\n",
      "[23900/34598] loss: 0.063\n",
      "[24000/34598] loss: 0.055\n",
      "[24100/34598] loss: 0.090\n",
      "[24200/34598] loss: 0.054\n",
      "[24300/34598] loss: 0.080\n",
      "[24400/34598] loss: 0.081\n",
      "[24500/34598] loss: 0.071\n",
      "[24600/34598] loss: 0.080\n",
      "[24700/34598] loss: 0.072\n",
      "[24800/34598] loss: 0.073\n",
      "[24900/34598] loss: 0.069\n",
      "[25000/34598] loss: 0.070\n",
      "[25100/34598] loss: 0.072\n",
      "[25200/34598] loss: 0.083\n",
      "[25300/34598] loss: 0.067\n",
      "[25400/34598] loss: 0.091\n",
      "[25500/34598] loss: 0.081\n",
      "[25600/34598] loss: 0.068\n",
      "[25700/34598] loss: 0.067\n",
      "[25800/34598] loss: 0.061\n",
      "[25900/34598] loss: 0.042\n",
      "[26000/34598] loss: 0.066\n",
      "[26100/34598] loss: 0.075\n",
      "[26200/34598] loss: 0.073\n",
      "[26300/34598] loss: 0.070\n",
      "[26400/34598] loss: 0.071\n",
      "[26500/34598] loss: 0.059\n",
      "[26600/34598] loss: 0.060\n",
      "[26700/34598] loss: 0.078\n",
      "[26800/34598] loss: 0.055\n",
      "[26900/34598] loss: 0.089\n",
      "[27000/34598] loss: 0.060\n",
      "[27100/34598] loss: 0.083\n",
      "[27200/34598] loss: 0.063\n",
      "[27300/34598] loss: 0.056\n",
      "[27400/34598] loss: 0.068\n",
      "[27500/34598] loss: 0.066\n",
      "[27600/34598] loss: 0.057\n",
      "[27700/34598] loss: 0.078\n",
      "[27800/34598] loss: 0.068\n",
      "[27900/34598] loss: 0.057\n",
      "[28000/34598] loss: 0.069\n",
      "[28100/34598] loss: 0.080\n",
      "[28200/34598] loss: 0.076\n",
      "[28300/34598] loss: 0.073\n",
      "[28400/34598] loss: 0.074\n",
      "[28500/34598] loss: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28600/34598] loss: 0.077\n",
      "[28700/34598] loss: 0.077\n",
      "[28800/34598] loss: 0.050\n",
      "[28900/34598] loss: 0.087\n",
      "[29000/34598] loss: 0.051\n",
      "[29100/34598] loss: 0.070\n",
      "[29200/34598] loss: 0.066\n",
      "[29300/34598] loss: 0.081\n",
      "[29400/34598] loss: 0.076\n",
      "[29500/34598] loss: 0.063\n",
      "[29600/34598] loss: 0.083\n",
      "[29700/34598] loss: 0.062\n",
      "[29800/34598] loss: 0.073\n",
      "[29900/34598] loss: 0.078\n",
      "[30000/34598] loss: 0.081\n",
      "[30100/34598] loss: 0.052\n",
      "[30200/34598] loss: 0.071\n",
      "[30300/34598] loss: 0.052\n",
      "[30400/34598] loss: 0.056\n",
      "[30500/34598] loss: 0.066\n",
      "[30600/34598] loss: 0.084\n",
      "[30700/34598] loss: 0.051\n",
      "[30800/34598] loss: 0.072\n",
      "[30900/34598] loss: 0.071\n",
      "[31000/34598] loss: 0.078\n",
      "[31100/34598] loss: 0.071\n",
      "[31200/34598] loss: 0.101\n",
      "[31300/34598] loss: 0.074\n",
      "[31400/34598] loss: 0.058\n",
      "[31500/34598] loss: 0.063\n",
      "[31600/34598] loss: 0.084\n",
      "[31700/34598] loss: 0.075\n",
      "[31800/34598] loss: 0.066\n",
      "[31900/34598] loss: 0.057\n",
      "[32000/34598] loss: 0.043\n",
      "[32100/34598] loss: 0.075\n",
      "[32200/34598] loss: 0.068\n",
      "[32300/34598] loss: 0.056\n",
      "[32400/34598] loss: 0.068\n",
      "[32500/34598] loss: 0.082\n",
      "[32600/34598] loss: 0.087\n",
      "[32700/34598] loss: 0.054\n",
      "[32800/34598] loss: 0.068\n",
      "[32900/34598] loss: 0.066\n",
      "[33000/34598] loss: 0.065\n",
      "[33100/34598] loss: 0.045\n",
      "[33200/34598] loss: 0.058\n",
      "[33300/34598] loss: 0.082\n",
      "[33400/34598] loss: 0.068\n",
      "[33500/34598] loss: 0.059\n",
      "[33600/34598] loss: 0.071\n",
      "[33700/34598] loss: 0.076\n",
      "[33800/34598] loss: 0.059\n",
      "[33900/34598] loss: 0.075\n",
      "[34000/34598] loss: 0.055\n",
      "[34100/34598] loss: 0.071\n",
      "[34200/34598] loss: 0.038\n",
      "[34300/34598] loss: 0.071\n",
      "[34400/34598] loss: 0.071\n",
      "[34500/34598] loss: 0.098\n",
      "Epoch 1 train loss: 0.0717\n",
      "Validation Accuracy: 0.9766466666666667\n",
      "Precision: 0.38806050108037643\n",
      "Recall: 0.9661227937580581\n",
      "Validation F0.5-Score: 0.440810746118488\n",
      "Epoch 1 val loss: 0.0769\n",
      "--------------------------------------------------\n",
      "Epoch 2/2\n",
      "[100/34598] loss: 0.071\n",
      "[200/34598] loss: 0.062\n",
      "[300/34598] loss: 0.054\n",
      "[400/34598] loss: 0.059\n",
      "[500/34598] loss: 0.055\n",
      "[600/34598] loss: 0.060\n",
      "[700/34598] loss: 0.097\n",
      "[800/34598] loss: 0.048\n",
      "[900/34598] loss: 0.058\n",
      "[1000/34598] loss: 0.058\n",
      "[1100/34598] loss: 0.051\n",
      "[1200/34598] loss: 0.068\n",
      "[1300/34598] loss: 0.067\n",
      "[1400/34598] loss: 0.033\n",
      "[1500/34598] loss: 0.052\n",
      "[1600/34598] loss: 0.054\n",
      "[1700/34598] loss: 0.049\n",
      "[1800/34598] loss: 0.050\n",
      "[1900/34598] loss: 0.051\n",
      "[2000/34598] loss: 0.059\n",
      "[2100/34598] loss: 0.070\n",
      "[2200/34598] loss: 0.058\n",
      "[2300/34598] loss: 0.045\n",
      "[2400/34598] loss: 0.062\n",
      "[2500/34598] loss: 0.048\n",
      "[2600/34598] loss: 0.055\n",
      "[2700/34598] loss: 0.061\n",
      "[2800/34598] loss: 0.059\n",
      "[2900/34598] loss: 0.043\n",
      "[3000/34598] loss: 0.061\n",
      "[3100/34598] loss: 0.060\n",
      "[3200/34598] loss: 0.059\n",
      "[3300/34598] loss: 0.059\n",
      "[3400/34598] loss: 0.061\n",
      "[3500/34598] loss: 0.052\n",
      "[3600/34598] loss: 0.058\n",
      "[3700/34598] loss: 0.053\n",
      "[3800/34598] loss: 0.048\n",
      "[3900/34598] loss: 0.037\n",
      "[4000/34598] loss: 0.051\n",
      "[4100/34598] loss: 0.049\n",
      "[4200/34598] loss: 0.041\n",
      "[4300/34598] loss: 0.056\n",
      "[4400/34598] loss: 0.065\n",
      "[4500/34598] loss: 0.030\n",
      "[4600/34598] loss: 0.054\n",
      "[4700/34598] loss: 0.045\n",
      "[4800/34598] loss: 0.055\n",
      "[4900/34598] loss: 0.053\n",
      "[5000/34598] loss: 0.040\n",
      "[5100/34598] loss: 0.056\n",
      "[5200/34598] loss: 0.035\n",
      "[5300/34598] loss: 0.062\n",
      "[5400/34598] loss: 0.059\n",
      "[5500/34598] loss: 0.060\n",
      "[5600/34598] loss: 0.064\n",
      "[5700/34598] loss: 0.070\n",
      "[5800/34598] loss: 0.061\n",
      "[5900/34598] loss: 0.049\n",
      "[6000/34598] loss: 0.059\n",
      "[6100/34598] loss: 0.053\n",
      "[6200/34598] loss: 0.058\n",
      "[6300/34598] loss: 0.059\n",
      "[6500/34598] loss: 0.040\n",
      "[6600/34598] loss: 0.046\n",
      "[6700/34598] loss: 0.061\n",
      "[6800/34598] loss: 0.059\n",
      "[6900/34598] loss: 0.070\n",
      "[7000/34598] loss: 0.059\n",
      "[7100/34598] loss: 0.059\n",
      "[7200/34598] loss: 0.040\n",
      "[7300/34598] loss: 0.048\n",
      "[7400/34598] loss: 0.055\n",
      "[7500/34598] loss: 0.040\n",
      "[7600/34598] loss: 0.050\n",
      "[7700/34598] loss: 0.050\n",
      "[7800/34598] loss: 0.051\n",
      "[7900/34598] loss: 0.050\n",
      "[8000/34598] loss: 0.060\n",
      "[8100/34598] loss: 0.042\n",
      "[8200/34598] loss: 0.057\n",
      "[8300/34598] loss: 0.077\n",
      "[8400/34598] loss: 0.094\n",
      "[8500/34598] loss: 0.041\n",
      "[8600/34598] loss: 0.070\n",
      "[8700/34598] loss: 0.049\n",
      "[8800/34598] loss: 0.061\n",
      "[8900/34598] loss: 0.046\n",
      "[9000/34598] loss: 0.064\n",
      "[9100/34598] loss: 0.058\n",
      "[9200/34598] loss: 0.052\n",
      "[9300/34598] loss: 0.054\n",
      "[9400/34598] loss: 0.056\n",
      "[9500/34598] loss: 0.095\n",
      "[9600/34598] loss: 0.035\n",
      "[9700/34598] loss: 0.050\n",
      "[9800/34598] loss: 0.057\n",
      "[9900/34598] loss: 0.063\n",
      "[10000/34598] loss: 0.064\n",
      "[10100/34598] loss: 0.052\n",
      "[10200/34598] loss: 0.046\n",
      "[10300/34598] loss: 0.048\n",
      "[10400/34598] loss: 0.054\n",
      "[10500/34598] loss: 0.057\n",
      "[10600/34598] loss: 0.035\n",
      "[10700/34598] loss: 0.066\n",
      "[10800/34598] loss: 0.066\n",
      "[10900/34598] loss: 0.046\n",
      "[11000/34598] loss: 0.040\n",
      "[11100/34598] loss: 0.046\n",
      "[11200/34598] loss: 0.054\n",
      "[11300/34598] loss: 0.048\n",
      "[11400/34598] loss: 0.064\n",
      "[11500/34598] loss: 0.058\n",
      "[11600/34598] loss: 0.049\n",
      "[11700/34598] loss: 0.059\n",
      "[11800/34598] loss: 0.054\n",
      "[11900/34598] loss: 0.067\n",
      "[12000/34598] loss: 0.048\n",
      "[12100/34598] loss: 0.082\n",
      "[12200/34598] loss: 0.062\n",
      "[12300/34598] loss: 0.038\n",
      "[12400/34598] loss: 0.041\n",
      "[12500/34598] loss: 0.049\n",
      "[12600/34598] loss: 0.054\n",
      "[12700/34598] loss: 0.052\n",
      "[12800/34598] loss: 0.065\n",
      "[12900/34598] loss: 0.065\n",
      "[13000/34598] loss: 0.067\n",
      "[13100/34598] loss: 0.072\n",
      "[13200/34598] loss: 0.032\n",
      "[13300/34598] loss: 0.062\n",
      "[13400/34598] loss: 0.055\n",
      "[13500/34598] loss: 0.063\n",
      "[13600/34598] loss: 0.073\n",
      "[13700/34598] loss: 0.066\n",
      "[13800/34598] loss: 0.053\n",
      "[13900/34598] loss: 0.087\n",
      "[14000/34598] loss: 0.059\n",
      "[14100/34598] loss: 0.052\n",
      "[14200/34598] loss: 0.060\n",
      "[14300/34598] loss: 0.049\n",
      "[14400/34598] loss: 0.046\n",
      "[14500/34598] loss: 0.052\n",
      "[14600/34598] loss: 0.054\n",
      "[14700/34598] loss: 0.041\n",
      "[14800/34598] loss: 0.048\n",
      "[14900/34598] loss: 0.047\n",
      "[15000/34598] loss: 0.034\n",
      "[15100/34598] loss: 0.052\n",
      "[15200/34598] loss: 0.044\n",
      "[15300/34598] loss: 0.066\n",
      "[15400/34598] loss: 0.062\n",
      "[15500/34598] loss: 0.049\n",
      "[15600/34598] loss: 0.062\n",
      "[15700/34598] loss: 0.056\n",
      "[15800/34598] loss: 0.060\n",
      "[15900/34598] loss: 0.063\n",
      "[16000/34598] loss: 0.039\n",
      "[16100/34598] loss: 0.049\n",
      "[16200/34598] loss: 0.052\n",
      "[16300/34598] loss: 0.053\n",
      "[16400/34598] loss: 0.057\n",
      "[16500/34598] loss: 0.041\n",
      "[16600/34598] loss: 0.054\n",
      "[16700/34598] loss: 0.061\n",
      "[16800/34598] loss: 0.044\n",
      "[16900/34598] loss: 0.044\n",
      "[17000/34598] loss: 0.046\n",
      "[17100/34598] loss: 0.059\n",
      "[17200/34598] loss: 0.067\n",
      "[17300/34598] loss: 0.063\n",
      "[17400/34598] loss: 0.045\n",
      "[17500/34598] loss: 0.072\n",
      "[17600/34598] loss: 0.047\n",
      "[17700/34598] loss: 0.065\n",
      "[17800/34598] loss: 0.041\n",
      "[17900/34598] loss: 0.050\n",
      "[18000/34598] loss: 0.057\n",
      "[18100/34598] loss: 0.068\n",
      "[18200/34598] loss: 0.053\n",
      "[18300/34598] loss: 0.059\n",
      "[18400/34598] loss: 0.055\n",
      "[18500/34598] loss: 0.045\n",
      "[18600/34598] loss: 0.053\n",
      "[18700/34598] loss: 0.076\n",
      "[18800/34598] loss: 0.052\n",
      "[18900/34598] loss: 0.043\n",
      "[19000/34598] loss: 0.055\n",
      "[19100/34598] loss: 0.045\n",
      "[19200/34598] loss: 0.049\n",
      "[19300/34598] loss: 0.059\n",
      "[19400/34598] loss: 0.055\n",
      "[19500/34598] loss: 0.067\n",
      "[19600/34598] loss: 0.045\n",
      "[19700/34598] loss: 0.051\n",
      "[19800/34598] loss: 0.044\n",
      "[19900/34598] loss: 0.037\n",
      "[20000/34598] loss: 0.049\n",
      "[20100/34598] loss: 0.067\n",
      "[20200/34598] loss: 0.048\n",
      "[20300/34598] loss: 0.067\n",
      "[20400/34598] loss: 0.058\n",
      "[20500/34598] loss: 0.052\n",
      "[20600/34598] loss: 0.037\n",
      "[20700/34598] loss: 0.073\n",
      "[20800/34598] loss: 0.057\n",
      "[20900/34598] loss: 0.065\n",
      "[21000/34598] loss: 0.032\n",
      "[21100/34598] loss: 0.063\n",
      "[21200/34598] loss: 0.055\n",
      "[21300/34598] loss: 0.059\n",
      "[21400/34598] loss: 0.062\n",
      "[21500/34598] loss: 0.063\n",
      "[21600/34598] loss: 0.058\n",
      "[21700/34598] loss: 0.051\n",
      "[21800/34598] loss: 0.063\n",
      "[21900/34598] loss: 0.075\n",
      "[22000/34598] loss: 0.077\n",
      "[22100/34598] loss: 0.052\n",
      "[22200/34598] loss: 0.054\n",
      "[22300/34598] loss: 0.050\n",
      "[22400/34598] loss: 0.046\n",
      "[22500/34598] loss: 0.045\n",
      "[22600/34598] loss: 0.039\n",
      "[22700/34598] loss: 0.044\n",
      "[22800/34598] loss: 0.043\n",
      "[22900/34598] loss: 0.052\n",
      "[23000/34598] loss: 0.070\n",
      "[23100/34598] loss: 0.041\n",
      "[23200/34598] loss: 0.072\n",
      "[23300/34598] loss: 0.048\n",
      "[23400/34598] loss: 0.061\n",
      "[23500/34598] loss: 0.054\n",
      "[23600/34598] loss: 0.046\n",
      "[23700/34598] loss: 0.047\n",
      "[23800/34598] loss: 0.057\n",
      "[23900/34598] loss: 0.057\n",
      "[24000/34598] loss: 0.068\n",
      "[24100/34598] loss: 0.044\n",
      "[24200/34598] loss: 0.039\n",
      "[24300/34598] loss: 0.051\n",
      "[24400/34598] loss: 0.069\n",
      "[24500/34598] loss: 0.058\n",
      "[24600/34598] loss: 0.046\n",
      "[24700/34598] loss: 0.044\n",
      "[24800/34598] loss: 0.058\n",
      "[24900/34598] loss: 0.060\n",
      "[25000/34598] loss: 0.043\n",
      "[25100/34598] loss: 0.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25200/34598] loss: 0.051\n",
      "[25300/34598] loss: 0.051\n",
      "[25400/34598] loss: 0.038\n",
      "[25500/34598] loss: 0.051\n",
      "[25600/34598] loss: 0.067\n",
      "[25700/34598] loss: 0.069\n",
      "[25800/34598] loss: 0.056\n",
      "[25900/34598] loss: 0.048\n",
      "[26000/34598] loss: 0.060\n",
      "[26100/34598] loss: 0.054\n",
      "[26200/34598] loss: 0.052\n",
      "[26300/34598] loss: 0.053\n",
      "[26400/34598] loss: 0.081\n",
      "[26500/34598] loss: 0.063\n",
      "[26600/34598] loss: 0.054\n",
      "[26700/34598] loss: 0.045\n",
      "[26800/34598] loss: 0.044\n",
      "[26900/34598] loss: 0.062\n",
      "[27000/34598] loss: 0.067\n",
      "[27100/34598] loss: 0.051\n",
      "[27200/34598] loss: 0.040\n",
      "[27300/34598] loss: 0.050\n",
      "[27400/34598] loss: 0.045\n",
      "[27500/34598] loss: 0.044\n",
      "[27600/34598] loss: 0.058\n",
      "[27700/34598] loss: 0.056\n",
      "[27800/34598] loss: 0.044\n",
      "[27900/34598] loss: 0.071\n",
      "[28000/34598] loss: 0.047\n",
      "[28100/34598] loss: 0.054\n",
      "[28200/34598] loss: 0.068\n",
      "[28300/34598] loss: 0.052\n",
      "[28400/34598] loss: 0.052\n",
      "[28500/34598] loss: 0.049\n",
      "[28600/34598] loss: 0.060\n",
      "[28700/34598] loss: 0.057\n",
      "[28800/34598] loss: 0.060\n",
      "[28900/34598] loss: 0.063\n",
      "[29000/34598] loss: 0.065\n",
      "[29100/34598] loss: 0.059\n",
      "[29200/34598] loss: 0.050\n",
      "[29300/34598] loss: 0.067\n",
      "[29400/34598] loss: 0.070\n",
      "[29500/34598] loss: 0.075\n",
      "[29600/34598] loss: 0.054\n",
      "[29700/34598] loss: 0.052\n",
      "[29800/34598] loss: 0.043\n",
      "[29900/34598] loss: 0.093\n",
      "[30000/34598] loss: 0.062\n",
      "[30100/34598] loss: 0.052\n",
      "[30200/34598] loss: 0.047\n",
      "[30300/34598] loss: 0.054\n",
      "[30400/34598] loss: 0.056\n",
      "[30500/34598] loss: 0.051\n",
      "[30600/34598] loss: 0.058\n",
      "[30700/34598] loss: 0.046\n",
      "[30800/34598] loss: 0.057\n",
      "[30900/34598] loss: 0.050\n",
      "[31000/34598] loss: 0.050\n",
      "[31100/34598] loss: 0.050\n",
      "[31200/34598] loss: 0.054\n",
      "[31300/34598] loss: 0.056\n",
      "[31400/34598] loss: 0.055\n",
      "[31500/34598] loss: 0.059\n",
      "[31600/34598] loss: 0.050\n",
      "[31700/34598] loss: 0.051\n",
      "[31800/34598] loss: 0.065\n",
      "[31900/34598] loss: 0.068\n",
      "[32000/34598] loss: 0.038\n",
      "[32100/34598] loss: 0.071\n",
      "[32200/34598] loss: 0.038\n",
      "[32300/34598] loss: 0.034\n",
      "[32400/34598] loss: 0.062\n",
      "[32500/34598] loss: 0.040\n",
      "[32600/34598] loss: 0.043\n",
      "[32700/34598] loss: 0.059\n",
      "[32800/34598] loss: 0.052\n",
      "[32900/34598] loss: 0.068\n",
      "[33000/34598] loss: 0.055\n",
      "[33100/34598] loss: 0.053\n",
      "[33200/34598] loss: 0.040\n",
      "[33300/34598] loss: 0.043\n",
      "[33400/34598] loss: 0.063\n",
      "[33500/34598] loss: 0.043\n",
      "[33600/34598] loss: 0.068\n",
      "[33700/34598] loss: 0.071\n",
      "[33800/34598] loss: 0.040\n",
      "[33900/34598] loss: 0.057\n",
      "[34000/34598] loss: 0.060\n",
      "[34100/34598] loss: 0.043\n",
      "[34200/34598] loss: 0.046\n",
      "[34300/34598] loss: 0.057\n",
      "[34400/34598] loss: 0.055\n",
      "[34500/34598] loss: 0.050\n",
      "Epoch 2 train loss: 0.0545\n",
      "Validation Accuracy: 0.9683826666666666\n",
      "Precision: 0.3174556689558227\n",
      "Recall: 0.963855421686747\n",
      "Validation F0.5-Score: 0.366631153501429\n",
      "Epoch 2 val loss: 0.0807\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = trainer.fit(train_loader, val_loader, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT training after labels fix 17.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "[30/46130] loss: 0.234\n",
      "[60/46130] loss: 0.215\n",
      "[90/46130] loss: 0.170\n",
      "[120/46130] loss: 0.169\n",
      "[150/46130] loss: 0.178\n",
      "[180/46130] loss: 0.152\n",
      "[210/46130] loss: 0.190\n",
      "[240/46130] loss: 0.151\n",
      "[270/46130] loss: 0.163\n",
      "[300/46130] loss: 0.163\n",
      "[330/46130] loss: 0.160\n",
      "[360/46130] loss: 0.168\n",
      "[390/46130] loss: 0.143\n",
      "[420/46130] loss: 0.120\n",
      "[450/46130] loss: 0.148\n",
      "[480/46130] loss: 0.125\n",
      "[510/46130] loss: 0.149\n",
      "[540/46130] loss: 0.157\n",
      "[570/46130] loss: 0.150\n",
      "[600/46130] loss: 0.134\n",
      "[630/46130] loss: 0.137\n",
      "[660/46130] loss: 0.111\n",
      "[690/46130] loss: 0.148\n",
      "[720/46130] loss: 0.148\n",
      "[750/46130] loss: 0.129\n",
      "[780/46130] loss: 0.169\n",
      "[810/46130] loss: 0.132\n",
      "[840/46130] loss: 0.136\n",
      "[870/46130] loss: 0.130\n",
      "[900/46130] loss: 0.109\n",
      "[930/46130] loss: 0.103\n",
      "[960/46130] loss: 0.132\n",
      "[990/46130] loss: 0.128\n",
      "[1020/46130] loss: 0.120\n",
      "[1050/46130] loss: 0.170\n",
      "[1080/46130] loss: 0.137\n",
      "[1110/46130] loss: 0.120\n",
      "[1140/46130] loss: 0.119\n",
      "[1170/46130] loss: 0.158\n",
      "[1200/46130] loss: 0.157\n",
      "[1230/46130] loss: 0.127\n",
      "[1260/46130] loss: 0.150\n",
      "[1290/46130] loss: 0.164\n",
      "[1320/46130] loss: 0.149\n",
      "[1350/46130] loss: 0.106\n",
      "[1380/46130] loss: 0.117\n",
      "[1410/46130] loss: 0.135\n",
      "[1440/46130] loss: 0.116\n",
      "[1470/46130] loss: 0.137\n",
      "[1500/46130] loss: 0.123\n",
      "[1530/46130] loss: 0.109\n",
      "[1560/46130] loss: 0.130\n",
      "[1590/46130] loss: 0.116\n",
      "[1620/46130] loss: 0.142\n",
      "[1650/46130] loss: 0.126\n",
      "[1680/46130] loss: 0.143\n",
      "[1710/46130] loss: 0.113\n",
      "[1740/46130] loss: 0.131\n",
      "[1770/46130] loss: 0.124\n",
      "[1800/46130] loss: 0.134\n",
      "[1830/46130] loss: 0.135\n",
      "[1860/46130] loss: 0.133\n",
      "[1890/46130] loss: 0.105\n",
      "[1920/46130] loss: 0.104\n",
      "[1950/46130] loss: 0.133\n",
      "[1980/46130] loss: 0.128\n",
      "[2010/46130] loss: 0.162\n",
      "[2040/46130] loss: 0.130\n",
      "[2070/46130] loss: 0.133\n",
      "[2100/46130] loss: 0.105\n",
      "[2130/46130] loss: 0.095\n",
      "[2160/46130] loss: 0.107\n",
      "[2190/46130] loss: 0.115\n",
      "[2220/46130] loss: 0.093\n",
      "[2250/46130] loss: 0.139\n",
      "[2280/46130] loss: 0.121\n",
      "[2310/46130] loss: 0.128\n",
      "[2340/46130] loss: 0.129\n",
      "[2370/46130] loss: 0.111\n",
      "[2400/46130] loss: 0.116\n",
      "[2430/46130] loss: 0.112\n",
      "[2460/46130] loss: 0.134\n",
      "[2490/46130] loss: 0.130\n",
      "[2520/46130] loss: 0.126\n",
      "[2550/46130] loss: 0.127\n",
      "[2580/46130] loss: 0.124\n",
      "[2610/46130] loss: 0.152\n",
      "[2640/46130] loss: 0.093\n",
      "[2670/46130] loss: 0.140\n",
      "[2700/46130] loss: 0.123\n",
      "[2730/46130] loss: 0.122\n",
      "[2760/46130] loss: 0.178\n",
      "[2790/46130] loss: 0.113\n",
      "[2820/46130] loss: 0.115\n",
      "[2850/46130] loss: 0.127\n",
      "[2880/46130] loss: 0.107\n",
      "[2910/46130] loss: 0.117\n",
      "[2940/46130] loss: 0.105\n",
      "[2970/46130] loss: 0.107\n",
      "[3000/46130] loss: 0.150\n",
      "[3030/46130] loss: 0.113\n",
      "[3060/46130] loss: 0.114\n",
      "[3090/46130] loss: 0.109\n",
      "[3120/46130] loss: 0.094\n",
      "[3150/46130] loss: 0.125\n",
      "[3180/46130] loss: 0.133\n",
      "[3210/46130] loss: 0.111\n",
      "[3240/46130] loss: 0.120\n",
      "[3270/46130] loss: 0.136\n",
      "[3300/46130] loss: 0.118\n",
      "[3330/46130] loss: 0.128\n",
      "[3360/46130] loss: 0.130\n",
      "[3390/46130] loss: 0.135\n",
      "[3420/46130] loss: 0.138\n",
      "[3450/46130] loss: 0.123\n",
      "[3480/46130] loss: 0.131\n",
      "[3510/46130] loss: 0.087\n",
      "[3540/46130] loss: 0.123\n",
      "[3570/46130] loss: 0.082\n",
      "[3600/46130] loss: 0.119\n",
      "[3630/46130] loss: 0.084\n",
      "[3660/46130] loss: 0.123\n",
      "[3690/46130] loss: 0.134\n",
      "[3720/46130] loss: 0.130\n",
      "[3750/46130] loss: 0.110\n",
      "[3780/46130] loss: 0.126\n",
      "[3810/46130] loss: 0.176\n",
      "[3840/46130] loss: 0.107\n",
      "[3870/46130] loss: 0.139\n",
      "[3900/46130] loss: 0.093\n",
      "[3930/46130] loss: 0.104\n",
      "[3960/46130] loss: 0.090\n",
      "[3990/46130] loss: 0.096\n",
      "[4020/46130] loss: 0.117\n",
      "[4050/46130] loss: 0.143\n",
      "[4080/46130] loss: 0.102\n",
      "[4110/46130] loss: 0.105\n",
      "[4140/46130] loss: 0.117\n",
      "[4170/46130] loss: 0.115\n",
      "[4200/46130] loss: 0.162\n",
      "[4230/46130] loss: 0.164\n",
      "[4260/46130] loss: 0.129\n",
      "[4290/46130] loss: 0.127\n",
      "[4320/46130] loss: 0.117\n",
      "[4350/46130] loss: 0.102\n",
      "[4380/46130] loss: 0.081\n",
      "[4410/46130] loss: 0.106\n",
      "[4440/46130] loss: 0.133\n",
      "[4470/46130] loss: 0.111\n",
      "[4500/46130] loss: 0.132\n",
      "[4530/46130] loss: 0.119\n",
      "[4560/46130] loss: 0.123\n",
      "[4590/46130] loss: 0.127\n",
      "[4620/46130] loss: 0.115\n",
      "[4650/46130] loss: 0.128\n",
      "[4680/46130] loss: 0.095\n",
      "[4710/46130] loss: 0.115\n",
      "[4740/46130] loss: 0.119\n",
      "[4770/46130] loss: 0.160\n",
      "[4800/46130] loss: 0.122\n",
      "[4830/46130] loss: 0.115\n",
      "[4860/46130] loss: 0.121\n",
      "[4890/46130] loss: 0.108\n",
      "[4920/46130] loss: 0.099\n",
      "[4950/46130] loss: 0.122\n",
      "[4980/46130] loss: 0.110\n",
      "[5010/46130] loss: 0.109\n",
      "[5040/46130] loss: 0.108\n",
      "[5070/46130] loss: 0.117\n",
      "[5100/46130] loss: 0.101\n",
      "[5130/46130] loss: 0.116\n",
      "[5160/46130] loss: 0.132\n",
      "[5190/46130] loss: 0.109\n",
      "[5220/46130] loss: 0.117\n",
      "[5250/46130] loss: 0.128\n",
      "[5280/46130] loss: 0.107\n",
      "[5310/46130] loss: 0.132\n",
      "[5340/46130] loss: 0.112\n",
      "[5370/46130] loss: 0.116\n",
      "[5400/46130] loss: 0.117\n",
      "[5430/46130] loss: 0.127\n",
      "[5460/46130] loss: 0.107\n",
      "[5490/46130] loss: 0.109\n",
      "[5520/46130] loss: 0.116\n",
      "[5550/46130] loss: 0.122\n",
      "[5580/46130] loss: 0.096\n",
      "[5610/46130] loss: 0.120\n",
      "[5640/46130] loss: 0.110\n",
      "[5670/46130] loss: 0.109\n",
      "[5700/46130] loss: 0.114\n",
      "[5730/46130] loss: 0.099\n",
      "[5760/46130] loss: 0.132\n",
      "[5790/46130] loss: 0.106\n",
      "[5820/46130] loss: 0.130\n",
      "[5850/46130] loss: 0.083\n",
      "[5880/46130] loss: 0.141\n",
      "[5910/46130] loss: 0.137\n",
      "[5940/46130] loss: 0.111\n",
      "[5970/46130] loss: 0.115\n",
      "[6000/46130] loss: 0.101\n",
      "[6030/46130] loss: 0.100\n",
      "[6060/46130] loss: 0.111\n",
      "[6090/46130] loss: 0.139\n",
      "[6120/46130] loss: 0.096\n",
      "[6150/46130] loss: 0.091\n",
      "[6180/46130] loss: 0.100\n",
      "[6210/46130] loss: 0.095\n",
      "[6240/46130] loss: 0.114\n",
      "[6270/46130] loss: 0.124\n",
      "[6300/46130] loss: 0.110\n",
      "[6330/46130] loss: 0.108\n",
      "[6360/46130] loss: 0.101\n",
      "[6390/46130] loss: 0.135\n",
      "[6420/46130] loss: 0.120\n",
      "[6450/46130] loss: 0.124\n",
      "[6480/46130] loss: 0.086\n",
      "[6510/46130] loss: 0.119\n",
      "[6540/46130] loss: 0.115\n",
      "[6570/46130] loss: 0.095\n",
      "[6600/46130] loss: 0.091\n",
      "[6630/46130] loss: 0.151\n",
      "[6660/46130] loss: 0.126\n",
      "[6690/46130] loss: 0.137\n",
      "[6720/46130] loss: 0.140\n",
      "[6750/46130] loss: 0.107\n",
      "[6780/46130] loss: 0.116\n",
      "[6810/46130] loss: 0.107\n",
      "[6840/46130] loss: 0.113\n",
      "[6870/46130] loss: 0.155\n",
      "[6900/46130] loss: 0.093\n",
      "[6930/46130] loss: 0.110\n",
      "[6960/46130] loss: 0.093\n",
      "[6990/46130] loss: 0.101\n",
      "[7020/46130] loss: 0.134\n",
      "[7050/46130] loss: 0.122\n",
      "[7080/46130] loss: 0.100\n",
      "[7110/46130] loss: 0.106\n",
      "[7140/46130] loss: 0.102\n",
      "[7170/46130] loss: 0.092\n",
      "[7200/46130] loss: 0.109\n",
      "[7230/46130] loss: 0.137\n",
      "[7260/46130] loss: 0.098\n",
      "[7290/46130] loss: 0.108\n",
      "[7320/46130] loss: 0.085\n",
      "[7350/46130] loss: 0.118\n",
      "[7380/46130] loss: 0.107\n",
      "[7410/46130] loss: 0.101\n",
      "[7440/46130] loss: 0.092\n",
      "[7470/46130] loss: 0.135\n",
      "[7500/46130] loss: 0.110\n",
      "[7530/46130] loss: 0.089\n",
      "[7560/46130] loss: 0.110\n",
      "[7590/46130] loss: 0.121\n",
      "[7620/46130] loss: 0.099\n",
      "[7650/46130] loss: 0.104\n",
      "[7680/46130] loss: 0.143\n",
      "[7710/46130] loss: 0.093\n",
      "[7740/46130] loss: 0.119\n",
      "[7770/46130] loss: 0.107\n",
      "[7800/46130] loss: 0.091\n",
      "[7830/46130] loss: 0.119\n",
      "[7860/46130] loss: 0.114\n",
      "[7890/46130] loss: 0.109\n",
      "[7920/46130] loss: 0.110\n",
      "[7950/46130] loss: 0.128\n",
      "[7980/46130] loss: 0.089\n",
      "[8010/46130] loss: 0.098\n",
      "[8040/46130] loss: 0.088\n",
      "[8070/46130] loss: 0.098\n",
      "[8100/46130] loss: 0.101\n",
      "[8130/46130] loss: 0.140\n",
      "[8160/46130] loss: 0.105\n",
      "[8190/46130] loss: 0.119\n",
      "[8220/46130] loss: 0.134\n",
      "[8250/46130] loss: 0.130\n",
      "[8280/46130] loss: 0.130\n",
      "[8310/46130] loss: 0.099\n",
      "[8340/46130] loss: 0.098\n",
      "[8370/46130] loss: 0.146\n",
      "[8400/46130] loss: 0.112\n",
      "[8430/46130] loss: 0.139\n",
      "[8460/46130] loss: 0.086\n",
      "[8490/46130] loss: 0.106\n",
      "[8520/46130] loss: 0.084\n",
      "[8550/46130] loss: 0.119\n",
      "[8580/46130] loss: 0.122\n",
      "[8610/46130] loss: 0.111\n",
      "[8640/46130] loss: 0.084\n",
      "[8670/46130] loss: 0.086\n",
      "[8700/46130] loss: 0.128\n",
      "[8730/46130] loss: 0.117\n",
      "[8760/46130] loss: 0.108\n",
      "[8790/46130] loss: 0.152\n",
      "[8820/46130] loss: 0.155\n",
      "[8850/46130] loss: 0.108\n",
      "[8880/46130] loss: 0.090\n",
      "[8910/46130] loss: 0.109\n",
      "[8940/46130] loss: 0.087\n",
      "[8970/46130] loss: 0.133\n",
      "[9000/46130] loss: 0.098\n",
      "[9030/46130] loss: 0.107\n",
      "[9060/46130] loss: 0.093\n",
      "[9090/46130] loss: 0.123\n",
      "[9120/46130] loss: 0.076\n",
      "[9150/46130] loss: 0.080\n",
      "[9180/46130] loss: 0.116\n",
      "[9210/46130] loss: 0.105\n",
      "[9240/46130] loss: 0.105\n",
      "[9270/46130] loss: 0.111\n",
      "[9300/46130] loss: 0.126\n",
      "[9330/46130] loss: 0.113\n",
      "[9360/46130] loss: 0.116\n",
      "[9390/46130] loss: 0.119\n",
      "[9420/46130] loss: 0.093\n",
      "[9450/46130] loss: 0.104\n",
      "[9480/46130] loss: 0.092\n",
      "[9510/46130] loss: 0.106\n",
      "[9540/46130] loss: 0.095\n",
      "[9570/46130] loss: 0.109\n",
      "[9600/46130] loss: 0.103\n",
      "[9630/46130] loss: 0.108\n",
      "[9660/46130] loss: 0.090\n",
      "[9690/46130] loss: 0.085\n",
      "[9720/46130] loss: 0.083\n",
      "[9750/46130] loss: 0.113\n",
      "[9780/46130] loss: 0.091\n",
      "[9810/46130] loss: 0.117\n",
      "[9840/46130] loss: 0.096\n",
      "[9870/46130] loss: 0.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9900/46130] loss: 0.106\n",
      "[9930/46130] loss: 0.096\n",
      "[9960/46130] loss: 0.124\n",
      "[9990/46130] loss: 0.105\n",
      "[10020/46130] loss: 0.095\n",
      "[10050/46130] loss: 0.110\n",
      "[10080/46130] loss: 0.109\n",
      "[10110/46130] loss: 0.086\n",
      "[10140/46130] loss: 0.084\n",
      "[10170/46130] loss: 0.125\n",
      "[10200/46130] loss: 0.117\n",
      "[10230/46130] loss: 0.077\n",
      "[10260/46130] loss: 0.095\n",
      "[10290/46130] loss: 0.077\n",
      "[10320/46130] loss: 0.101\n",
      "[10350/46130] loss: 0.092\n",
      "[10380/46130] loss: 0.152\n",
      "[10410/46130] loss: 0.091\n",
      "[10440/46130] loss: 0.132\n",
      "[10470/46130] loss: 0.112\n",
      "[10500/46130] loss: 0.105\n",
      "[10530/46130] loss: 0.104\n",
      "[10560/46130] loss: 0.087\n",
      "[10590/46130] loss: 0.090\n",
      "[10620/46130] loss: 0.114\n",
      "[10650/46130] loss: 0.088\n",
      "[10680/46130] loss: 0.088\n",
      "[10710/46130] loss: 0.115\n",
      "[10740/46130] loss: 0.137\n",
      "[10770/46130] loss: 0.107\n",
      "[10800/46130] loss: 0.110\n",
      "[10830/46130] loss: 0.093\n",
      "[10860/46130] loss: 0.127\n",
      "[10890/46130] loss: 0.130\n",
      "[10920/46130] loss: 0.081\n",
      "[10950/46130] loss: 0.112\n",
      "[10980/46130] loss: 0.129\n",
      "[11010/46130] loss: 0.113\n",
      "[11040/46130] loss: 0.127\n",
      "[11070/46130] loss: 0.136\n",
      "[11100/46130] loss: 0.098\n",
      "[11130/46130] loss: 0.152\n",
      "[11160/46130] loss: 0.120\n",
      "[11190/46130] loss: 0.104\n",
      "[11220/46130] loss: 0.093\n",
      "[11250/46130] loss: 0.136\n",
      "[11280/46130] loss: 0.104\n",
      "[11310/46130] loss: 0.119\n",
      "[11340/46130] loss: 0.100\n",
      "[11370/46130] loss: 0.104\n",
      "[11400/46130] loss: 0.142\n",
      "[11430/46130] loss: 0.094\n",
      "[11460/46130] loss: 0.074\n",
      "[11490/46130] loss: 0.100\n",
      "[11520/46130] loss: 0.097\n",
      "[11550/46130] loss: 0.103\n",
      "[11580/46130] loss: 0.101\n",
      "[11610/46130] loss: 0.099\n",
      "[11640/46130] loss: 0.100\n",
      "[11670/46130] loss: 0.094\n",
      "[11700/46130] loss: 0.089\n",
      "[11730/46130] loss: 0.097\n",
      "[11760/46130] loss: 0.079\n",
      "[11790/46130] loss: 0.088\n",
      "[11820/46130] loss: 0.112\n",
      "[11850/46130] loss: 0.116\n",
      "[11880/46130] loss: 0.075\n",
      "[11910/46130] loss: 0.106\n",
      "[11940/46130] loss: 0.097\n",
      "[11970/46130] loss: 0.102\n",
      "[12000/46130] loss: 0.092\n",
      "[12030/46130] loss: 0.088\n",
      "[12060/46130] loss: 0.120\n",
      "[12090/46130] loss: 0.086\n",
      "[12120/46130] loss: 0.117\n",
      "[12150/46130] loss: 0.121\n",
      "[12180/46130] loss: 0.084\n",
      "[12210/46130] loss: 0.109\n",
      "[12240/46130] loss: 0.105\n",
      "[12270/46130] loss: 0.096\n",
      "[12300/46130] loss: 0.120\n",
      "[12330/46130] loss: 0.104\n",
      "[12360/46130] loss: 0.102\n",
      "[12390/46130] loss: 0.110\n",
      "[12420/46130] loss: 0.101\n",
      "[12450/46130] loss: 0.102\n",
      "[12480/46130] loss: 0.092\n",
      "[12510/46130] loss: 0.109\n",
      "[12540/46130] loss: 0.096\n",
      "[12570/46130] loss: 0.096\n",
      "[12600/46130] loss: 0.087\n",
      "[12630/46130] loss: 0.108\n",
      "[12660/46130] loss: 0.118\n",
      "[12690/46130] loss: 0.111\n",
      "[12720/46130] loss: 0.068\n",
      "[12750/46130] loss: 0.108\n",
      "[12780/46130] loss: 0.095\n",
      "[12810/46130] loss: 0.105\n",
      "[12840/46130] loss: 0.111\n",
      "[12870/46130] loss: 0.101\n",
      "[12900/46130] loss: 0.096\n",
      "[12930/46130] loss: 0.124\n",
      "[12960/46130] loss: 0.123\n",
      "[12990/46130] loss: 0.094\n",
      "[13020/46130] loss: 0.124\n",
      "[13050/46130] loss: 0.136\n",
      "[13080/46130] loss: 0.136\n",
      "[13110/46130] loss: 0.098\n",
      "[13140/46130] loss: 0.105\n",
      "[13170/46130] loss: 0.098\n",
      "[13200/46130] loss: 0.144\n",
      "[13230/46130] loss: 0.110\n",
      "[13260/46130] loss: 0.083\n",
      "[13290/46130] loss: 0.097\n",
      "[13320/46130] loss: 0.088\n",
      "[13350/46130] loss: 0.097\n",
      "[13380/46130] loss: 0.109\n",
      "[13410/46130] loss: 0.092\n",
      "[13440/46130] loss: 0.101\n",
      "[13470/46130] loss: 0.106\n",
      "[13500/46130] loss: 0.114\n",
      "[13530/46130] loss: 0.114\n",
      "[13560/46130] loss: 0.087\n",
      "[13590/46130] loss: 0.094\n",
      "[13620/46130] loss: 0.103\n",
      "[13650/46130] loss: 0.100\n",
      "[13680/46130] loss: 0.083\n",
      "[13710/46130] loss: 0.119\n",
      "[13740/46130] loss: 0.118\n",
      "[13770/46130] loss: 0.115\n",
      "[13800/46130] loss: 0.103\n",
      "[13830/46130] loss: 0.122\n",
      "[13860/46130] loss: 0.102\n",
      "[13890/46130] loss: 0.113\n",
      "[13920/46130] loss: 0.115\n",
      "[13950/46130] loss: 0.090\n",
      "[13980/46130] loss: 0.100\n",
      "[14010/46130] loss: 0.097\n",
      "[14040/46130] loss: 0.083\n",
      "[14070/46130] loss: 0.119\n",
      "[14100/46130] loss: 0.124\n",
      "[14130/46130] loss: 0.131\n",
      "[14160/46130] loss: 0.129\n",
      "[14190/46130] loss: 0.085\n",
      "[14220/46130] loss: 0.128\n",
      "[14250/46130] loss: 0.091\n",
      "[14280/46130] loss: 0.093\n",
      "[14310/46130] loss: 0.078\n",
      "[14340/46130] loss: 0.127\n",
      "[14370/46130] loss: 0.113\n",
      "[14400/46130] loss: 0.094\n",
      "[14430/46130] loss: 0.106\n",
      "[14460/46130] loss: 0.099\n",
      "[14490/46130] loss: 0.115\n",
      "[14520/46130] loss: 0.083\n",
      "[14550/46130] loss: 0.112\n",
      "[14580/46130] loss: 0.128\n",
      "[14610/46130] loss: 0.101\n",
      "[14640/46130] loss: 0.102\n",
      "[14670/46130] loss: 0.087\n",
      "[14700/46130] loss: 0.109\n",
      "[14730/46130] loss: 0.097\n",
      "[14760/46130] loss: 0.119\n",
      "[14790/46130] loss: 0.082\n",
      "[14820/46130] loss: 0.113\n",
      "[14850/46130] loss: 0.092\n",
      "[14880/46130] loss: 0.105\n",
      "[14910/46130] loss: 0.097\n",
      "[14940/46130] loss: 0.121\n",
      "[14970/46130] loss: 0.095\n",
      "[15000/46130] loss: 0.080\n",
      "[15030/46130] loss: 0.083\n",
      "[15060/46130] loss: 0.113\n",
      "[15090/46130] loss: 0.093\n",
      "[15120/46130] loss: 0.124\n",
      "[15150/46130] loss: 0.094\n",
      "[15180/46130] loss: 0.081\n",
      "[15210/46130] loss: 0.083\n",
      "[15240/46130] loss: 0.112\n",
      "[15270/46130] loss: 0.113\n",
      "[15300/46130] loss: 0.116\n",
      "[15330/46130] loss: 0.116\n",
      "[15360/46130] loss: 0.113\n",
      "[15390/46130] loss: 0.110\n",
      "[15420/46130] loss: 0.096\n",
      "[15450/46130] loss: 0.154\n",
      "[15480/46130] loss: 0.112\n",
      "[15510/46130] loss: 0.088\n",
      "[15540/46130] loss: 0.088\n",
      "[15570/46130] loss: 0.067\n",
      "[15600/46130] loss: 0.089\n",
      "[15630/46130] loss: 0.113\n",
      "[15660/46130] loss: 0.124\n",
      "[15690/46130] loss: 0.099\n",
      "[15720/46130] loss: 0.144\n",
      "[15750/46130] loss: 0.107\n",
      "[15780/46130] loss: 0.118\n",
      "[15810/46130] loss: 0.127\n",
      "[15840/46130] loss: 0.105\n",
      "[15870/46130] loss: 0.084\n",
      "[15900/46130] loss: 0.099\n",
      "[15930/46130] loss: 0.109\n",
      "[15960/46130] loss: 0.134\n",
      "[15990/46130] loss: 0.106\n",
      "[16020/46130] loss: 0.118\n",
      "[16050/46130] loss: 0.100\n",
      "[16080/46130] loss: 0.114\n",
      "[16110/46130] loss: 0.098\n",
      "[16140/46130] loss: 0.122\n",
      "[16170/46130] loss: 0.092\n",
      "[16200/46130] loss: 0.121\n",
      "[16230/46130] loss: 0.093\n",
      "[16260/46130] loss: 0.111\n",
      "[16290/46130] loss: 0.100\n",
      "[16320/46130] loss: 0.150\n",
      "[16350/46130] loss: 0.112\n",
      "[16380/46130] loss: 0.104\n",
      "[16410/46130] loss: 0.102\n",
      "[16440/46130] loss: 0.105\n",
      "[16470/46130] loss: 0.094\n",
      "[16500/46130] loss: 0.111\n",
      "[16530/46130] loss: 0.089\n",
      "[16560/46130] loss: 0.078\n",
      "[16590/46130] loss: 0.109\n",
      "[16620/46130] loss: 0.105\n",
      "[16650/46130] loss: 0.089\n",
      "[16680/46130] loss: 0.087\n",
      "[16710/46130] loss: 0.083\n",
      "[16740/46130] loss: 0.113\n",
      "[16770/46130] loss: 0.100\n",
      "[16800/46130] loss: 0.096\n",
      "[16830/46130] loss: 0.098\n",
      "[16860/46130] loss: 0.087\n",
      "[16890/46130] loss: 0.094\n",
      "[16920/46130] loss: 0.157\n",
      "[16950/46130] loss: 0.098\n",
      "[16980/46130] loss: 0.100\n",
      "[17010/46130] loss: 0.101\n",
      "[17040/46130] loss: 0.101\n",
      "[17070/46130] loss: 0.082\n",
      "[17100/46130] loss: 0.087\n",
      "[17130/46130] loss: 0.090\n",
      "[17160/46130] loss: 0.098\n",
      "[17190/46130] loss: 0.110\n",
      "[17220/46130] loss: 0.088\n",
      "[17250/46130] loss: 0.082\n",
      "[17280/46130] loss: 0.109\n",
      "[17310/46130] loss: 0.137\n",
      "[17340/46130] loss: 0.089\n",
      "[17370/46130] loss: 0.099\n",
      "[17400/46130] loss: 0.107\n",
      "[17430/46130] loss: 0.131\n",
      "[17460/46130] loss: 0.074\n",
      "[17490/46130] loss: 0.091\n",
      "[17520/46130] loss: 0.080\n",
      "[17550/46130] loss: 0.112\n",
      "[17580/46130] loss: 0.083\n",
      "[17610/46130] loss: 0.089\n",
      "[17640/46130] loss: 0.093\n",
      "[17670/46130] loss: 0.109\n",
      "[17700/46130] loss: 0.102\n",
      "[17730/46130] loss: 0.093\n",
      "[17760/46130] loss: 0.082\n",
      "[17790/46130] loss: 0.082\n",
      "[17820/46130] loss: 0.143\n",
      "[17850/46130] loss: 0.106\n",
      "[17880/46130] loss: 0.107\n",
      "[17910/46130] loss: 0.101\n",
      "[17940/46130] loss: 0.099\n",
      "[17970/46130] loss: 0.105\n",
      "[18000/46130] loss: 0.102\n",
      "[18030/46130] loss: 0.091\n",
      "[18060/46130] loss: 0.097\n",
      "[18090/46130] loss: 0.089\n",
      "[18120/46130] loss: 0.096\n",
      "[18150/46130] loss: 0.099\n",
      "[18180/46130] loss: 0.113\n",
      "[18210/46130] loss: 0.076\n",
      "[18240/46130] loss: 0.089\n",
      "[18270/46130] loss: 0.080\n",
      "[18300/46130] loss: 0.103\n",
      "[18330/46130] loss: 0.067\n",
      "[18360/46130] loss: 0.109\n",
      "[18390/46130] loss: 0.108\n",
      "[18420/46130] loss: 0.063\n",
      "[18450/46130] loss: 0.088\n",
      "[18480/46130] loss: 0.124\n",
      "[18510/46130] loss: 0.134\n",
      "[18540/46130] loss: 0.132\n",
      "[18570/46130] loss: 0.093\n",
      "[18600/46130] loss: 0.073\n",
      "[18630/46130] loss: 0.092\n",
      "[18660/46130] loss: 0.067\n",
      "[18690/46130] loss: 0.093\n",
      "[18720/46130] loss: 0.083\n",
      "[18750/46130] loss: 0.140\n",
      "[18780/46130] loss: 0.093\n",
      "[18810/46130] loss: 0.127\n",
      "[18840/46130] loss: 0.081\n",
      "[18870/46130] loss: 0.088\n",
      "[18900/46130] loss: 0.102\n",
      "[18930/46130] loss: 0.096\n",
      "[18960/46130] loss: 0.076\n",
      "[18990/46130] loss: 0.102\n",
      "[19020/46130] loss: 0.096\n",
      "[19050/46130] loss: 0.117\n",
      "[19080/46130] loss: 0.086\n",
      "[19110/46130] loss: 0.060\n",
      "[19140/46130] loss: 0.089\n",
      "[19170/46130] loss: 0.101\n",
      "[19200/46130] loss: 0.092\n",
      "[19230/46130] loss: 0.097\n",
      "[19260/46130] loss: 0.104\n",
      "[19290/46130] loss: 0.105\n",
      "[19320/46130] loss: 0.102\n",
      "[19350/46130] loss: 0.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19380/46130] loss: 0.089\n",
      "[19410/46130] loss: 0.088\n",
      "[19440/46130] loss: 0.111\n",
      "[19470/46130] loss: 0.119\n",
      "[19500/46130] loss: 0.084\n",
      "[19530/46130] loss: 0.144\n",
      "[19560/46130] loss: 0.112\n",
      "[19590/46130] loss: 0.094\n",
      "[19620/46130] loss: 0.084\n",
      "[19650/46130] loss: 0.097\n",
      "[19680/46130] loss: 0.130\n",
      "[19710/46130] loss: 0.126\n",
      "[19740/46130] loss: 0.096\n",
      "[19770/46130] loss: 0.093\n",
      "[19800/46130] loss: 0.077\n",
      "[19830/46130] loss: 0.112\n",
      "[19860/46130] loss: 0.086\n",
      "[19890/46130] loss: 0.090\n",
      "[19920/46130] loss: 0.079\n",
      "[19950/46130] loss: 0.121\n",
      "[19980/46130] loss: 0.113\n",
      "[20010/46130] loss: 0.105\n",
      "[20040/46130] loss: 0.103\n",
      "[20070/46130] loss: 0.096\n",
      "[20100/46130] loss: 0.100\n",
      "[20130/46130] loss: 0.085\n",
      "[20160/46130] loss: 0.070\n",
      "[20190/46130] loss: 0.108\n",
      "[20220/46130] loss: 0.128\n",
      "[20250/46130] loss: 0.090\n",
      "[20280/46130] loss: 0.083\n",
      "[20310/46130] loss: 0.091\n",
      "[20340/46130] loss: 0.101\n",
      "[20370/46130] loss: 0.089\n",
      "[20400/46130] loss: 0.108\n",
      "[20430/46130] loss: 0.118\n",
      "[20460/46130] loss: 0.105\n",
      "[20490/46130] loss: 0.089\n",
      "[20520/46130] loss: 0.107\n",
      "[20550/46130] loss: 0.089\n",
      "[20580/46130] loss: 0.096\n",
      "[20610/46130] loss: 0.086\n",
      "[20640/46130] loss: 0.089\n",
      "[20670/46130] loss: 0.083\n",
      "[20700/46130] loss: 0.110\n",
      "[20730/46130] loss: 0.110\n",
      "[20760/46130] loss: 0.111\n",
      "[20790/46130] loss: 0.120\n",
      "[20820/46130] loss: 0.080\n",
      "[20850/46130] loss: 0.127\n",
      "[20880/46130] loss: 0.083\n",
      "[20910/46130] loss: 0.080\n",
      "[20940/46130] loss: 0.085\n",
      "[20970/46130] loss: 0.075\n",
      "[21000/46130] loss: 0.106\n",
      "[21030/46130] loss: 0.114\n",
      "[21060/46130] loss: 0.105\n",
      "[21090/46130] loss: 0.117\n",
      "[21120/46130] loss: 0.078\n",
      "[21150/46130] loss: 0.105\n",
      "[21180/46130] loss: 0.113\n",
      "[21210/46130] loss: 0.104\n",
      "[21240/46130] loss: 0.092\n",
      "[21270/46130] loss: 0.097\n",
      "[21300/46130] loss: 0.100\n",
      "[21330/46130] loss: 0.104\n",
      "[21360/46130] loss: 0.090\n",
      "[21390/46130] loss: 0.113\n",
      "[21420/46130] loss: 0.099\n",
      "[21450/46130] loss: 0.087\n",
      "[21480/46130] loss: 0.088\n",
      "[21510/46130] loss: 0.084\n",
      "[21540/46130] loss: 0.085\n",
      "[21570/46130] loss: 0.099\n",
      "[21600/46130] loss: 0.129\n",
      "[21630/46130] loss: 0.088\n",
      "[21660/46130] loss: 0.093\n",
      "[21690/46130] loss: 0.135\n",
      "[21720/46130] loss: 0.103\n",
      "[21750/46130] loss: 0.098\n",
      "[21780/46130] loss: 0.115\n",
      "[21810/46130] loss: 0.087\n",
      "[21840/46130] loss: 0.128\n",
      "[21870/46130] loss: 0.097\n",
      "[21900/46130] loss: 0.096\n",
      "[21930/46130] loss: 0.097\n",
      "[21960/46130] loss: 0.081\n",
      "[21990/46130] loss: 0.099\n",
      "[22020/46130] loss: 0.102\n",
      "[22050/46130] loss: 0.106\n",
      "[22080/46130] loss: 0.114\n",
      "[22110/46130] loss: 0.103\n",
      "[22140/46130] loss: 0.095\n",
      "[22170/46130] loss: 0.134\n",
      "[22200/46130] loss: 0.103\n",
      "[22230/46130] loss: 0.091\n",
      "[22260/46130] loss: 0.086\n",
      "[22290/46130] loss: 0.088\n",
      "[22320/46130] loss: 0.123\n",
      "[22350/46130] loss: 0.079\n",
      "[22380/46130] loss: 0.089\n",
      "[22410/46130] loss: 0.101\n",
      "[22440/46130] loss: 0.110\n",
      "[22470/46130] loss: 0.111\n",
      "[22500/46130] loss: 0.090\n",
      "[22530/46130] loss: 0.077\n",
      "[22560/46130] loss: 0.092\n",
      "[22590/46130] loss: 0.080\n",
      "[22620/46130] loss: 0.115\n",
      "[22650/46130] loss: 0.074\n",
      "[22680/46130] loss: 0.095\n",
      "[22710/46130] loss: 0.092\n",
      "[22740/46130] loss: 0.099\n",
      "[22770/46130] loss: 0.126\n",
      "[22800/46130] loss: 0.085\n",
      "[22830/46130] loss: 0.077\n",
      "[22860/46130] loss: 0.091\n",
      "[22890/46130] loss: 0.093\n",
      "[22920/46130] loss: 0.098\n",
      "[22950/46130] loss: 0.073\n",
      "[22980/46130] loss: 0.118\n",
      "[23010/46130] loss: 0.127\n",
      "[23040/46130] loss: 0.116\n",
      "[23070/46130] loss: 0.097\n",
      "[23100/46130] loss: 0.075\n",
      "[23130/46130] loss: 0.141\n",
      "[23160/46130] loss: 0.094\n",
      "[23190/46130] loss: 0.102\n",
      "[23220/46130] loss: 0.079\n",
      "[23250/46130] loss: 0.101\n",
      "[23280/46130] loss: 0.097\n",
      "[23310/46130] loss: 0.104\n",
      "[23340/46130] loss: 0.110\n",
      "[23370/46130] loss: 0.101\n",
      "[23400/46130] loss: 0.081\n",
      "[23430/46130] loss: 0.110\n",
      "[23460/46130] loss: 0.083\n",
      "[23490/46130] loss: 0.087\n",
      "[23520/46130] loss: 0.091\n",
      "[23550/46130] loss: 0.094\n",
      "[23580/46130] loss: 0.104\n",
      "[23610/46130] loss: 0.127\n",
      "[23640/46130] loss: 0.084\n",
      "[23670/46130] loss: 0.078\n",
      "[23700/46130] loss: 0.146\n",
      "[23730/46130] loss: 0.108\n",
      "[23760/46130] loss: 0.130\n",
      "[23790/46130] loss: 0.125\n",
      "[23820/46130] loss: 0.120\n",
      "[23850/46130] loss: 0.095\n",
      "[23880/46130] loss: 0.113\n",
      "[23910/46130] loss: 0.104\n",
      "[23940/46130] loss: 0.112\n",
      "[23970/46130] loss: 0.092\n",
      "[24000/46130] loss: 0.092\n",
      "[24030/46130] loss: 0.096\n",
      "[24060/46130] loss: 0.111\n",
      "[24090/46130] loss: 0.088\n",
      "[24120/46130] loss: 0.103\n",
      "[24150/46130] loss: 0.077\n",
      "[24180/46130] loss: 0.109\n",
      "[24210/46130] loss: 0.095\n",
      "[24240/46130] loss: 0.085\n",
      "[24270/46130] loss: 0.105\n",
      "[24300/46130] loss: 0.093\n",
      "[24330/46130] loss: 0.085\n",
      "[24360/46130] loss: 0.075\n",
      "[24390/46130] loss: 0.083\n",
      "[24420/46130] loss: 0.097\n",
      "[24450/46130] loss: 0.084\n",
      "[24480/46130] loss: 0.113\n",
      "[24510/46130] loss: 0.139\n",
      "[24540/46130] loss: 0.088\n",
      "[24570/46130] loss: 0.088\n",
      "[24600/46130] loss: 0.083\n",
      "[24630/46130] loss: 0.107\n",
      "[24660/46130] loss: 0.062\n",
      "[24690/46130] loss: 0.094\n",
      "[24720/46130] loss: 0.105\n",
      "[24750/46130] loss: 0.082\n",
      "[24780/46130] loss: 0.077\n",
      "[24810/46130] loss: 0.109\n",
      "[24840/46130] loss: 0.096\n",
      "[24870/46130] loss: 0.076\n",
      "[24900/46130] loss: 0.085\n",
      "[24930/46130] loss: 0.100\n",
      "[24960/46130] loss: 0.102\n",
      "[24990/46130] loss: 0.091\n",
      "[25020/46130] loss: 0.092\n",
      "[25050/46130] loss: 0.101\n",
      "[25080/46130] loss: 0.114\n",
      "[25110/46130] loss: 0.093\n",
      "[25140/46130] loss: 0.113\n",
      "[25170/46130] loss: 0.105\n",
      "[25200/46130] loss: 0.091\n",
      "[25230/46130] loss: 0.095\n",
      "[25260/46130] loss: 0.088\n",
      "[25290/46130] loss: 0.091\n",
      "[25320/46130] loss: 0.119\n",
      "[25350/46130] loss: 0.136\n",
      "[25380/46130] loss: 0.125\n",
      "[25410/46130] loss: 0.118\n",
      "[25440/46130] loss: 0.081\n",
      "[25470/46130] loss: 0.111\n",
      "[25500/46130] loss: 0.080\n",
      "[25530/46130] loss: 0.093\n",
      "[25560/46130] loss: 0.093\n",
      "[25590/46130] loss: 0.111\n",
      "[25620/46130] loss: 0.095\n",
      "[25650/46130] loss: 0.085\n",
      "[25680/46130] loss: 0.097\n",
      "[25710/46130] loss: 0.084\n",
      "[25740/46130] loss: 0.089\n",
      "[25770/46130] loss: 0.071\n",
      "[25800/46130] loss: 0.090\n",
      "[25830/46130] loss: 0.109\n",
      "[25860/46130] loss: 0.127\n",
      "[25890/46130] loss: 0.103\n",
      "[25920/46130] loss: 0.082\n",
      "[25950/46130] loss: 0.103\n",
      "[25980/46130] loss: 0.081\n",
      "[26010/46130] loss: 0.104\n",
      "[26040/46130] loss: 0.081\n",
      "[26070/46130] loss: 0.112\n",
      "[26100/46130] loss: 0.073\n",
      "[26130/46130] loss: 0.091\n",
      "[26160/46130] loss: 0.056\n",
      "[26190/46130] loss: 0.129\n",
      "[26220/46130] loss: 0.114\n",
      "[26250/46130] loss: 0.113\n",
      "[26280/46130] loss: 0.114\n",
      "[26310/46130] loss: 0.122\n",
      "[26340/46130] loss: 0.107\n",
      "[26370/46130] loss: 0.090\n",
      "[26400/46130] loss: 0.118\n",
      "[26430/46130] loss: 0.077\n",
      "[26460/46130] loss: 0.113\n",
      "[26490/46130] loss: 0.107\n",
      "[26520/46130] loss: 0.089\n",
      "[26550/46130] loss: 0.084\n",
      "[26580/46130] loss: 0.102\n",
      "[26610/46130] loss: 0.096\n",
      "[26640/46130] loss: 0.085\n",
      "[26670/46130] loss: 0.119\n",
      "[26700/46130] loss: 0.091\n",
      "[26730/46130] loss: 0.090\n",
      "[26760/46130] loss: 0.085\n",
      "[26790/46130] loss: 0.083\n",
      "[26820/46130] loss: 0.086\n",
      "[26850/46130] loss: 0.084\n",
      "[26880/46130] loss: 0.105\n",
      "[26910/46130] loss: 0.095\n",
      "[26940/46130] loss: 0.081\n",
      "[26970/46130] loss: 0.078\n",
      "[27000/46130] loss: 0.100\n",
      "[27030/46130] loss: 0.138\n",
      "[27060/46130] loss: 0.112\n",
      "[27090/46130] loss: 0.102\n",
      "[27120/46130] loss: 0.075\n",
      "[27150/46130] loss: 0.108\n",
      "[27180/46130] loss: 0.100\n",
      "[27210/46130] loss: 0.099\n",
      "[27240/46130] loss: 0.093\n",
      "[27270/46130] loss: 0.112\n",
      "[27300/46130] loss: 0.073\n",
      "[27330/46130] loss: 0.081\n",
      "[27360/46130] loss: 0.089\n",
      "[27390/46130] loss: 0.089\n",
      "[27420/46130] loss: 0.119\n",
      "[27450/46130] loss: 0.088\n",
      "[27480/46130] loss: 0.094\n",
      "[27510/46130] loss: 0.085\n",
      "[27540/46130] loss: 0.089\n",
      "[27570/46130] loss: 0.091\n",
      "[27600/46130] loss: 0.098\n",
      "[27630/46130] loss: 0.086\n",
      "[27660/46130] loss: 0.081\n",
      "[27690/46130] loss: 0.116\n",
      "[27720/46130] loss: 0.096\n",
      "[27750/46130] loss: 0.107\n",
      "[27780/46130] loss: 0.091\n",
      "[27810/46130] loss: 0.101\n",
      "[27840/46130] loss: 0.094\n",
      "[27870/46130] loss: 0.100\n",
      "[27900/46130] loss: 0.088\n",
      "[27930/46130] loss: 0.093\n",
      "[27960/46130] loss: 0.077\n",
      "[27990/46130] loss: 0.062\n",
      "[28020/46130] loss: 0.121\n",
      "[28050/46130] loss: 0.120\n",
      "[28080/46130] loss: 0.084\n",
      "[28110/46130] loss: 0.088\n",
      "[28140/46130] loss: 0.113\n",
      "[28170/46130] loss: 0.094\n",
      "[28200/46130] loss: 0.092\n",
      "[28230/46130] loss: 0.089\n",
      "[28260/46130] loss: 0.095\n",
      "[28290/46130] loss: 0.091\n",
      "[28320/46130] loss: 0.096\n",
      "[28350/46130] loss: 0.129\n",
      "[28380/46130] loss: 0.109\n",
      "[28410/46130] loss: 0.098\n",
      "[28440/46130] loss: 0.091\n",
      "[28470/46130] loss: 0.074\n",
      "[28500/46130] loss: 0.093\n",
      "[28530/46130] loss: 0.076\n",
      "[28560/46130] loss: 0.093\n",
      "[28590/46130] loss: 0.080\n",
      "[28620/46130] loss: 0.090\n",
      "[28650/46130] loss: 0.101\n",
      "[28680/46130] loss: 0.077\n",
      "[28710/46130] loss: 0.123\n",
      "[28740/46130] loss: 0.086\n",
      "[28770/46130] loss: 0.102\n",
      "[28800/46130] loss: 0.107\n",
      "[28830/46130] loss: 0.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28860/46130] loss: 0.083\n",
      "[28890/46130] loss: 0.089\n",
      "[28920/46130] loss: 0.117\n",
      "[28950/46130] loss: 0.116\n",
      "[28980/46130] loss: 0.081\n",
      "[29010/46130] loss: 0.117\n",
      "[29040/46130] loss: 0.102\n",
      "[29070/46130] loss: 0.101\n",
      "[29100/46130] loss: 0.094\n",
      "[29130/46130] loss: 0.140\n",
      "[29160/46130] loss: 0.082\n",
      "[29190/46130] loss: 0.099\n",
      "[29220/46130] loss: 0.086\n",
      "[29250/46130] loss: 0.082\n",
      "[29280/46130] loss: 0.079\n",
      "[29310/46130] loss: 0.100\n",
      "[29340/46130] loss: 0.064\n",
      "[29370/46130] loss: 0.082\n",
      "[29400/46130] loss: 0.115\n",
      "[29430/46130] loss: 0.090\n",
      "[29460/46130] loss: 0.102\n",
      "[29490/46130] loss: 0.100\n",
      "[29520/46130] loss: 0.076\n",
      "[29550/46130] loss: 0.098\n",
      "[29580/46130] loss: 0.081\n",
      "[29610/46130] loss: 0.107\n",
      "[29640/46130] loss: 0.099\n",
      "[29670/46130] loss: 0.071\n",
      "[29700/46130] loss: 0.101\n",
      "[29730/46130] loss: 0.117\n",
      "[29760/46130] loss: 0.102\n",
      "[29790/46130] loss: 0.108\n",
      "[29820/46130] loss: 0.106\n",
      "[29850/46130] loss: 0.080\n",
      "[29880/46130] loss: 0.071\n",
      "[29910/46130] loss: 0.094\n",
      "[29940/46130] loss: 0.069\n",
      "[29970/46130] loss: 0.091\n",
      "[30000/46130] loss: 0.100\n",
      "[30030/46130] loss: 0.099\n",
      "[30060/46130] loss: 0.104\n",
      "[30090/46130] loss: 0.089\n",
      "[30120/46130] loss: 0.101\n",
      "[30150/46130] loss: 0.102\n",
      "[30180/46130] loss: 0.083\n",
      "[30210/46130] loss: 0.109\n",
      "[30240/46130] loss: 0.085\n",
      "[30270/46130] loss: 0.101\n",
      "[30300/46130] loss: 0.101\n",
      "[30330/46130] loss: 0.110\n",
      "[30360/46130] loss: 0.101\n",
      "[30390/46130] loss: 0.080\n",
      "[30420/46130] loss: 0.073\n",
      "[30450/46130] loss: 0.091\n",
      "[30480/46130] loss: 0.124\n",
      "[30510/46130] loss: 0.122\n",
      "[30540/46130] loss: 0.070\n",
      "[30570/46130] loss: 0.089\n",
      "[30600/46130] loss: 0.091\n",
      "[30630/46130] loss: 0.095\n",
      "[30660/46130] loss: 0.083\n",
      "[30690/46130] loss: 0.097\n",
      "[30720/46130] loss: 0.099\n",
      "[30750/46130] loss: 0.098\n",
      "[30780/46130] loss: 0.097\n",
      "[30810/46130] loss: 0.111\n",
      "[30840/46130] loss: 0.091\n",
      "[30870/46130] loss: 0.078\n",
      "[30900/46130] loss: 0.102\n",
      "[30930/46130] loss: 0.086\n",
      "[30960/46130] loss: 0.088\n",
      "[30990/46130] loss: 0.071\n",
      "[31020/46130] loss: 0.071\n",
      "[31050/46130] loss: 0.084\n",
      "[31080/46130] loss: 0.075\n",
      "[31110/46130] loss: 0.110\n",
      "[31140/46130] loss: 0.100\n",
      "[31170/46130] loss: 0.097\n",
      "[31200/46130] loss: 0.094\n",
      "[31230/46130] loss: 0.092\n",
      "[31260/46130] loss: 0.106\n",
      "[31290/46130] loss: 0.098\n",
      "[31320/46130] loss: 0.097\n",
      "[31350/46130] loss: 0.123\n",
      "[31380/46130] loss: 0.078\n",
      "[31410/46130] loss: 0.112\n",
      "[31440/46130] loss: 0.099\n",
      "[31470/46130] loss: 0.082\n",
      "[31500/46130] loss: 0.089\n",
      "[31530/46130] loss: 0.120\n",
      "[31560/46130] loss: 0.089\n",
      "[31590/46130] loss: 0.089\n",
      "[31620/46130] loss: 0.094\n",
      "[31650/46130] loss: 0.079\n",
      "[31680/46130] loss: 0.093\n",
      "[31710/46130] loss: 0.096\n",
      "[31740/46130] loss: 0.081\n",
      "[31770/46130] loss: 0.097\n",
      "[31800/46130] loss: 0.094\n",
      "[31830/46130] loss: 0.088\n",
      "[31860/46130] loss: 0.142\n",
      "[31890/46130] loss: 0.067\n",
      "[31920/46130] loss: 0.100\n",
      "[31950/46130] loss: 0.100\n",
      "[31980/46130] loss: 0.105\n",
      "[32010/46130] loss: 0.088\n",
      "[32040/46130] loss: 0.049\n",
      "[32070/46130] loss: 0.118\n",
      "[32100/46130] loss: 0.100\n",
      "[32130/46130] loss: 0.083\n",
      "[32160/46130] loss: 0.101\n",
      "[32190/46130] loss: 0.092\n",
      "[32220/46130] loss: 0.130\n",
      "[32250/46130] loss: 0.091\n",
      "[32280/46130] loss: 0.082\n",
      "[32310/46130] loss: 0.077\n",
      "[32340/46130] loss: 0.104\n",
      "[32370/46130] loss: 0.092\n",
      "[32400/46130] loss: 0.122\n",
      "[32430/46130] loss: 0.112\n",
      "[32460/46130] loss: 0.091\n",
      "[32490/46130] loss: 0.106\n",
      "[32520/46130] loss: 0.119\n",
      "[32550/46130] loss: 0.082\n",
      "[32580/46130] loss: 0.099\n",
      "[32610/46130] loss: 0.088\n",
      "[32640/46130] loss: 0.100\n",
      "[32670/46130] loss: 0.098\n",
      "[32700/46130] loss: 0.090\n",
      "[32730/46130] loss: 0.076\n",
      "[32760/46130] loss: 0.103\n",
      "[32790/46130] loss: 0.082\n",
      "[32820/46130] loss: 0.091\n",
      "[32850/46130] loss: 0.095\n",
      "[32880/46130] loss: 0.110\n",
      "[32910/46130] loss: 0.098\n",
      "[32940/46130] loss: 0.102\n",
      "[32970/46130] loss: 0.092\n",
      "[33000/46130] loss: 0.077\n",
      "[33030/46130] loss: 0.109\n",
      "[33060/46130] loss: 0.117\n",
      "[33090/46130] loss: 0.085\n",
      "[33120/46130] loss: 0.106\n",
      "[33150/46130] loss: 0.128\n",
      "[33180/46130] loss: 0.084\n",
      "[33210/46130] loss: 0.092\n",
      "[33240/46130] loss: 0.090\n",
      "[33270/46130] loss: 0.092\n",
      "[33300/46130] loss: 0.141\n",
      "[33330/46130] loss: 0.101\n",
      "[33360/46130] loss: 0.089\n",
      "[33390/46130] loss: 0.114\n",
      "[33420/46130] loss: 0.094\n",
      "[33450/46130] loss: 0.106\n",
      "[33480/46130] loss: 0.101\n",
      "[33510/46130] loss: 0.100\n",
      "[33540/46130] loss: 0.081\n",
      "[33570/46130] loss: 0.105\n",
      "[33600/46130] loss: 0.073\n",
      "[33630/46130] loss: 0.094\n",
      "[33660/46130] loss: 0.110\n",
      "[33690/46130] loss: 0.099\n",
      "[33720/46130] loss: 0.091\n",
      "[33750/46130] loss: 0.097\n",
      "[33780/46130] loss: 0.085\n",
      "[33810/46130] loss: 0.103\n",
      "[33840/46130] loss: 0.084\n",
      "[33870/46130] loss: 0.092\n",
      "[33900/46130] loss: 0.073\n",
      "[33930/46130] loss: 0.089\n",
      "[33960/46130] loss: 0.099\n",
      "[33990/46130] loss: 0.087\n",
      "[34020/46130] loss: 0.079\n",
      "[34050/46130] loss: 0.093\n",
      "[34080/46130] loss: 0.112\n",
      "[34110/46130] loss: 0.092\n",
      "[34140/46130] loss: 0.092\n",
      "[34170/46130] loss: 0.083\n",
      "[34200/46130] loss: 0.090\n",
      "[34230/46130] loss: 0.091\n",
      "[34260/46130] loss: 0.111\n",
      "[34290/46130] loss: 0.097\n",
      "[34320/46130] loss: 0.075\n",
      "[34350/46130] loss: 0.092\n",
      "[34380/46130] loss: 0.107\n",
      "[34410/46130] loss: 0.097\n",
      "[34440/46130] loss: 0.115\n",
      "[34470/46130] loss: 0.117\n",
      "[34500/46130] loss: 0.076\n",
      "[34530/46130] loss: 0.103\n",
      "[34560/46130] loss: 0.088\n",
      "[34590/46130] loss: 0.087\n",
      "[34620/46130] loss: 0.092\n",
      "[34650/46130] loss: 0.086\n",
      "[34680/46130] loss: 0.097\n",
      "[34710/46130] loss: 0.096\n",
      "[34740/46130] loss: 0.115\n",
      "[34770/46130] loss: 0.107\n",
      "[34800/46130] loss: 0.075\n",
      "[34830/46130] loss: 0.085\n",
      "[34860/46130] loss: 0.087\n",
      "[34890/46130] loss: 0.098\n",
      "[34920/46130] loss: 0.112\n",
      "[34950/46130] loss: 0.095\n",
      "[34980/46130] loss: 0.103\n",
      "[35010/46130] loss: 0.111\n",
      "[35040/46130] loss: 0.080\n",
      "[35070/46130] loss: 0.086\n",
      "[35100/46130] loss: 0.105\n",
      "[35130/46130] loss: 0.096\n",
      "[35160/46130] loss: 0.079\n",
      "[35190/46130] loss: 0.072\n",
      "[35220/46130] loss: 0.099\n",
      "[35250/46130] loss: 0.085\n",
      "[35280/46130] loss: 0.099\n",
      "[35310/46130] loss: 0.085\n",
      "[35340/46130] loss: 0.122\n",
      "[35370/46130] loss: 0.079\n",
      "[35400/46130] loss: 0.083\n",
      "[35430/46130] loss: 0.119\n",
      "[35460/46130] loss: 0.104\n",
      "[35490/46130] loss: 0.106\n",
      "[35520/46130] loss: 0.082\n",
      "[35550/46130] loss: 0.132\n",
      "[35580/46130] loss: 0.100\n",
      "[35610/46130] loss: 0.082\n",
      "[35640/46130] loss: 0.103\n",
      "[35670/46130] loss: 0.085\n",
      "[35700/46130] loss: 0.107\n",
      "[35730/46130] loss: 0.112\n",
      "[35760/46130] loss: 0.124\n",
      "[35790/46130] loss: 0.090\n",
      "[35820/46130] loss: 0.092\n",
      "[35850/46130] loss: 0.094\n",
      "[35880/46130] loss: 0.085\n",
      "[35910/46130] loss: 0.084\n",
      "[35940/46130] loss: 0.077\n",
      "[35970/46130] loss: 0.079\n",
      "[36000/46130] loss: 0.088\n",
      "[36030/46130] loss: 0.106\n",
      "[36060/46130] loss: 0.081\n",
      "[36090/46130] loss: 0.092\n",
      "[36120/46130] loss: 0.073\n",
      "[36150/46130] loss: 0.073\n",
      "[36180/46130] loss: 0.144\n",
      "[36210/46130] loss: 0.120\n",
      "[36240/46130] loss: 0.097\n",
      "[36270/46130] loss: 0.071\n",
      "[36300/46130] loss: 0.082\n",
      "[36330/46130] loss: 0.091\n",
      "[36360/46130] loss: 0.085\n",
      "[36390/46130] loss: 0.078\n",
      "[36420/46130] loss: 0.088\n",
      "[36450/46130] loss: 0.088\n",
      "[36480/46130] loss: 0.101\n",
      "[36510/46130] loss: 0.084\n",
      "[36540/46130] loss: 0.111\n",
      "[36570/46130] loss: 0.095\n",
      "[36600/46130] loss: 0.093\n",
      "[36630/46130] loss: 0.085\n",
      "[36660/46130] loss: 0.082\n",
      "[36690/46130] loss: 0.098\n",
      "[36720/46130] loss: 0.072\n",
      "[36750/46130] loss: 0.104\n",
      "[36780/46130] loss: 0.085\n",
      "[36810/46130] loss: 0.100\n",
      "[36840/46130] loss: 0.098\n",
      "[36870/46130] loss: 0.092\n",
      "[36900/46130] loss: 0.080\n",
      "[36930/46130] loss: 0.085\n",
      "[36960/46130] loss: 0.078\n",
      "[36990/46130] loss: 0.069\n",
      "[37020/46130] loss: 0.087\n",
      "[37050/46130] loss: 0.117\n",
      "[37080/46130] loss: 0.091\n",
      "[37110/46130] loss: 0.092\n",
      "[37140/46130] loss: 0.082\n",
      "[37170/46130] loss: 0.078\n",
      "[37200/46130] loss: 0.101\n",
      "[37230/46130] loss: 0.092\n",
      "[37260/46130] loss: 0.071\n",
      "[37290/46130] loss: 0.081\n",
      "[37320/46130] loss: 0.129\n",
      "[37350/46130] loss: 0.084\n",
      "[37380/46130] loss: 0.092\n",
      "[37410/46130] loss: 0.090\n",
      "[37440/46130] loss: 0.080\n",
      "[37470/46130] loss: 0.084\n",
      "[37500/46130] loss: 0.094\n",
      "[37530/46130] loss: 0.119\n",
      "[37560/46130] loss: 0.073\n",
      "[37590/46130] loss: 0.104\n",
      "[37620/46130] loss: 0.091\n",
      "[37650/46130] loss: 0.096\n",
      "[37680/46130] loss: 0.112\n",
      "[37710/46130] loss: 0.090\n",
      "[37740/46130] loss: 0.107\n",
      "[37770/46130] loss: 0.092\n",
      "[37800/46130] loss: 0.083\n",
      "[37830/46130] loss: 0.114\n",
      "[37860/46130] loss: 0.117\n",
      "[37890/46130] loss: 0.101\n",
      "[37920/46130] loss: 0.092\n",
      "[37950/46130] loss: 0.118\n",
      "[37980/46130] loss: 0.110\n",
      "[38010/46130] loss: 0.104\n",
      "[38040/46130] loss: 0.100\n",
      "[38070/46130] loss: 0.070\n",
      "[38100/46130] loss: 0.095\n",
      "[38130/46130] loss: 0.085\n",
      "[38160/46130] loss: 0.087\n",
      "[38190/46130] loss: 0.085\n",
      "[38220/46130] loss: 0.116\n",
      "[38250/46130] loss: 0.114\n",
      "[38280/46130] loss: 0.083\n",
      "[38310/46130] loss: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38340/46130] loss: 0.081\n",
      "[38370/46130] loss: 0.085\n",
      "[38400/46130] loss: 0.087\n",
      "[38430/46130] loss: 0.082\n",
      "[38460/46130] loss: 0.107\n",
      "[38490/46130] loss: 0.083\n",
      "[38520/46130] loss: 0.074\n",
      "[38550/46130] loss: 0.092\n",
      "[38580/46130] loss: 0.118\n",
      "[38610/46130] loss: 0.100\n",
      "[38640/46130] loss: 0.111\n",
      "[38670/46130] loss: 0.084\n",
      "[38700/46130] loss: 0.143\n",
      "[38730/46130] loss: 0.077\n",
      "[38760/46130] loss: 0.087\n",
      "[38790/46130] loss: 0.097\n",
      "[38820/46130] loss: 0.109\n",
      "[38850/46130] loss: 0.105\n",
      "[38880/46130] loss: 0.096\n",
      "[38910/46130] loss: 0.118\n",
      "[38940/46130] loss: 0.112\n",
      "[38970/46130] loss: 0.069\n",
      "[39000/46130] loss: 0.067\n",
      "[39030/46130] loss: 0.093\n",
      "[39060/46130] loss: 0.052\n",
      "[39090/46130] loss: 0.105\n",
      "[39120/46130] loss: 0.070\n",
      "[39150/46130] loss: 0.103\n",
      "[39180/46130] loss: 0.096\n",
      "[39210/46130] loss: 0.105\n",
      "[39240/46130] loss: 0.100\n",
      "[39270/46130] loss: 0.091\n",
      "[39300/46130] loss: 0.107\n",
      "[39330/46130] loss: 0.098\n",
      "[39360/46130] loss: 0.091\n",
      "[39390/46130] loss: 0.096\n",
      "[39420/46130] loss: 0.104\n",
      "[39450/46130] loss: 0.072\n",
      "[39480/46130] loss: 0.090\n",
      "[39510/46130] loss: 0.080\n",
      "[39540/46130] loss: 0.087\n",
      "[39570/46130] loss: 0.090\n",
      "[39600/46130] loss: 0.075\n",
      "[39630/46130] loss: 0.103\n",
      "[39660/46130] loss: 0.078\n",
      "[39690/46130] loss: 0.109\n",
      "[39720/46130] loss: 0.082\n",
      "[39750/46130] loss: 0.102\n",
      "[39780/46130] loss: 0.119\n",
      "[39810/46130] loss: 0.105\n",
      "[39840/46130] loss: 0.097\n",
      "[39870/46130] loss: 0.113\n",
      "[39900/46130] loss: 0.085\n",
      "[39930/46130] loss: 0.080\n",
      "[39960/46130] loss: 0.089\n",
      "[39990/46130] loss: 0.096\n",
      "[40020/46130] loss: 0.082\n",
      "[40050/46130] loss: 0.094\n",
      "[40080/46130] loss: 0.083\n",
      "[40110/46130] loss: 0.082\n",
      "[40140/46130] loss: 0.094\n",
      "[40170/46130] loss: 0.082\n",
      "[40200/46130] loss: 0.071\n",
      "[40230/46130] loss: 0.071\n",
      "[40260/46130] loss: 0.080\n",
      "[40290/46130] loss: 0.080\n",
      "[40320/46130] loss: 0.090\n",
      "[40350/46130] loss: 0.089\n",
      "[40380/46130] loss: 0.097\n",
      "[40410/46130] loss: 0.095\n",
      "[40440/46130] loss: 0.097\n",
      "[40470/46130] loss: 0.079\n",
      "[40500/46130] loss: 0.079\n",
      "[40530/46130] loss: 0.082\n",
      "[40560/46130] loss: 0.089\n",
      "[40590/46130] loss: 0.083\n",
      "[40620/46130] loss: 0.105\n",
      "[40650/46130] loss: 0.118\n",
      "[40680/46130] loss: 0.097\n",
      "[40710/46130] loss: 0.088\n",
      "[40740/46130] loss: 0.076\n",
      "[40770/46130] loss: 0.081\n",
      "[40800/46130] loss: 0.106\n",
      "[40830/46130] loss: 0.080\n",
      "[40860/46130] loss: 0.069\n",
      "[40890/46130] loss: 0.126\n",
      "[40920/46130] loss: 0.093\n",
      "[40950/46130] loss: 0.105\n",
      "[40980/46130] loss: 0.111\n",
      "[41010/46130] loss: 0.092\n",
      "[41040/46130] loss: 0.068\n",
      "[41070/46130] loss: 0.085\n",
      "[41100/46130] loss: 0.099\n",
      "[41130/46130] loss: 0.090\n",
      "[41160/46130] loss: 0.086\n",
      "[41190/46130] loss: 0.118\n",
      "[41220/46130] loss: 0.094\n",
      "[41250/46130] loss: 0.082\n",
      "[41280/46130] loss: 0.127\n",
      "[41310/46130] loss: 0.083\n",
      "[41340/46130] loss: 0.091\n",
      "[41370/46130] loss: 0.083\n",
      "[41400/46130] loss: 0.064\n",
      "[41430/46130] loss: 0.073\n",
      "[41460/46130] loss: 0.083\n",
      "[41490/46130] loss: 0.081\n",
      "[41520/46130] loss: 0.097\n",
      "[41550/46130] loss: 0.086\n",
      "[41580/46130] loss: 0.067\n",
      "[41610/46130] loss: 0.067\n",
      "[41640/46130] loss: 0.096\n",
      "[41670/46130] loss: 0.088\n",
      "[41700/46130] loss: 0.101\n",
      "[41730/46130] loss: 0.101\n",
      "[41760/46130] loss: 0.100\n",
      "[41790/46130] loss: 0.105\n",
      "[41820/46130] loss: 0.076\n",
      "[41850/46130] loss: 0.086\n",
      "[41880/46130] loss: 0.096\n",
      "[41910/46130] loss: 0.068\n",
      "[41940/46130] loss: 0.106\n",
      "[41970/46130] loss: 0.071\n",
      "[42000/46130] loss: 0.092\n",
      "[42030/46130] loss: 0.070\n",
      "[42060/46130] loss: 0.098\n",
      "[42090/46130] loss: 0.112\n",
      "[42120/46130] loss: 0.108\n",
      "[42150/46130] loss: 0.096\n",
      "[42180/46130] loss: 0.079\n",
      "[42210/46130] loss: 0.092\n",
      "[42240/46130] loss: 0.064\n",
      "[42270/46130] loss: 0.098\n",
      "[42300/46130] loss: 0.109\n",
      "[42330/46130] loss: 0.098\n",
      "[42360/46130] loss: 0.099\n",
      "[42390/46130] loss: 0.076\n",
      "[42420/46130] loss: 0.077\n",
      "[42450/46130] loss: 0.100\n",
      "[42480/46130] loss: 0.102\n",
      "[42510/46130] loss: 0.090\n",
      "[42540/46130] loss: 0.089\n",
      "[42570/46130] loss: 0.092\n",
      "[42600/46130] loss: 0.084\n",
      "[42630/46130] loss: 0.071\n",
      "[42660/46130] loss: 0.097\n",
      "[42690/46130] loss: 0.072\n",
      "[42720/46130] loss: 0.085\n",
      "[42750/46130] loss: 0.080\n",
      "[42780/46130] loss: 0.104\n",
      "[42810/46130] loss: 0.083\n",
      "[42840/46130] loss: 0.098\n",
      "[42870/46130] loss: 0.084\n",
      "[42900/46130] loss: 0.061\n",
      "[42930/46130] loss: 0.116\n",
      "[42960/46130] loss: 0.086\n",
      "[42990/46130] loss: 0.130\n",
      "[43020/46130] loss: 0.077\n",
      "[43050/46130] loss: 0.076\n",
      "[43080/46130] loss: 0.113\n",
      "[43110/46130] loss: 0.068\n",
      "[43140/46130] loss: 0.095\n",
      "[43170/46130] loss: 0.086\n",
      "[43200/46130] loss: 0.066\n",
      "[43230/46130] loss: 0.094\n",
      "[43260/46130] loss: 0.087\n",
      "[43290/46130] loss: 0.113\n",
      "[43320/46130] loss: 0.102\n",
      "[43350/46130] loss: 0.087\n",
      "[43380/46130] loss: 0.080\n",
      "[43410/46130] loss: 0.086\n",
      "[43440/46130] loss: 0.087\n",
      "[43470/46130] loss: 0.127\n",
      "[43500/46130] loss: 0.078\n",
      "[43530/46130] loss: 0.090\n",
      "[43560/46130] loss: 0.087\n",
      "[43590/46130] loss: 0.104\n",
      "[43620/46130] loss: 0.109\n",
      "[43650/46130] loss: 0.068\n",
      "[43680/46130] loss: 0.086\n",
      "[43710/46130] loss: 0.100\n",
      "[43740/46130] loss: 0.106\n",
      "[43770/46130] loss: 0.089\n",
      "[43800/46130] loss: 0.093\n",
      "[43830/46130] loss: 0.094\n",
      "[43860/46130] loss: 0.088\n",
      "[43890/46130] loss: 0.097\n",
      "[43920/46130] loss: 0.084\n",
      "[43950/46130] loss: 0.112\n",
      "[43980/46130] loss: 0.078\n",
      "[44010/46130] loss: 0.083\n",
      "[44040/46130] loss: 0.086\n",
      "[44070/46130] loss: 0.096\n",
      "[44100/46130] loss: 0.084\n",
      "[44130/46130] loss: 0.076\n",
      "[44160/46130] loss: 0.101\n",
      "[44190/46130] loss: 0.100\n",
      "[44220/46130] loss: 0.109\n",
      "[44250/46130] loss: 0.079\n",
      "[44280/46130] loss: 0.092\n",
      "[44310/46130] loss: 0.090\n",
      "[44340/46130] loss: 0.082\n",
      "[44370/46130] loss: 0.088\n",
      "[44400/46130] loss: 0.098\n",
      "[44430/46130] loss: 0.091\n",
      "[44460/46130] loss: 0.109\n",
      "[44490/46130] loss: 0.087\n",
      "[44520/46130] loss: 0.106\n",
      "[44550/46130] loss: 0.098\n",
      "[44580/46130] loss: 0.067\n",
      "[44610/46130] loss: 0.095\n",
      "[44640/46130] loss: 0.073\n",
      "[44670/46130] loss: 0.098\n",
      "[44700/46130] loss: 0.095\n",
      "[44730/46130] loss: 0.080\n",
      "[44760/46130] loss: 0.090\n",
      "[44790/46130] loss: 0.115\n",
      "[44820/46130] loss: 0.111\n",
      "[44850/46130] loss: 0.091\n",
      "[44880/46130] loss: 0.086\n",
      "[44910/46130] loss: 0.104\n",
      "[44940/46130] loss: 0.119\n",
      "[44970/46130] loss: 0.073\n",
      "[45000/46130] loss: 0.083\n",
      "[45030/46130] loss: 0.062\n",
      "[45060/46130] loss: 0.086\n",
      "[45090/46130] loss: 0.091\n",
      "[45120/46130] loss: 0.065\n",
      "[45150/46130] loss: 0.080\n",
      "[45180/46130] loss: 0.092\n",
      "[45210/46130] loss: 0.103\n",
      "[45240/46130] loss: 0.063\n",
      "[45270/46130] loss: 0.098\n",
      "[45300/46130] loss: 0.115\n",
      "[45330/46130] loss: 0.056\n",
      "[45360/46130] loss: 0.087\n",
      "[45390/46130] loss: 0.079\n",
      "[45420/46130] loss: 0.108\n",
      "[45450/46130] loss: 0.078\n",
      "[45480/46130] loss: 0.113\n",
      "[45510/46130] loss: 0.092\n",
      "[45540/46130] loss: 0.079\n",
      "[45570/46130] loss: 0.065\n",
      "[45600/46130] loss: 0.068\n",
      "[45630/46130] loss: 0.103\n",
      "[45660/46130] loss: 0.105\n",
      "[45690/46130] loss: 0.104\n",
      "[45720/46130] loss: 0.086\n",
      "[45750/46130] loss: 0.087\n",
      "[45780/46130] loss: 0.099\n",
      "[45810/46130] loss: 0.055\n",
      "[45840/46130] loss: 0.079\n",
      "[45870/46130] loss: 0.074\n",
      "[45900/46130] loss: 0.096\n",
      "[45930/46130] loss: 0.089\n",
      "[45960/46130] loss: 0.078\n",
      "[45990/46130] loss: 0.085\n",
      "[46020/46130] loss: 0.108\n",
      "[46050/46130] loss: 0.096\n",
      "[46080/46130] loss: 0.068\n",
      "[46110/46130] loss: 0.071\n",
      "Epoch 0 train loss: 0.1016\n",
      "Validation Accuracy: 0.9940175\n",
      "Precision: 0.6604405984338341\n",
      "Recall: 0.9635046230440967\n",
      "Validation F0.5-Score: 0.7047772026116588\n",
      "Epoch 0 val loss: 0.0697\n",
      "--------------------------------------------------\n",
      "Epoch 1/2\n",
      "[30/46130] loss: 0.076\n",
      "[60/46130] loss: 0.065\n",
      "[90/46130] loss: 0.055\n",
      "[120/46130] loss: 0.064\n",
      "[150/46130] loss: 0.056\n",
      "[180/46130] loss: 0.067\n",
      "[210/46130] loss: 0.060\n",
      "[240/46130] loss: 0.075\n",
      "[270/46130] loss: 0.083\n",
      "[300/46130] loss: 0.064\n",
      "[330/46130] loss: 0.080\n",
      "[360/46130] loss: 0.055\n",
      "[390/46130] loss: 0.061\n",
      "[420/46130] loss: 0.080\n",
      "[450/46130] loss: 0.089\n",
      "[480/46130] loss: 0.057\n",
      "[510/46130] loss: 0.081\n",
      "[540/46130] loss: 0.055\n",
      "[570/46130] loss: 0.056\n",
      "[600/46130] loss: 0.066\n",
      "[630/46130] loss: 0.099\n",
      "[660/46130] loss: 0.059\n",
      "[690/46130] loss: 0.089\n",
      "[720/46130] loss: 0.100\n",
      "[750/46130] loss: 0.058\n",
      "[780/46130] loss: 0.101\n",
      "[810/46130] loss: 0.082\n",
      "[840/46130] loss: 0.051\n",
      "[870/46130] loss: 0.072\n",
      "[900/46130] loss: 0.069\n",
      "[930/46130] loss: 0.098\n",
      "[960/46130] loss: 0.065\n",
      "[990/46130] loss: 0.100\n",
      "[1020/46130] loss: 0.075\n",
      "[1050/46130] loss: 0.077\n",
      "[1080/46130] loss: 0.082\n",
      "[1110/46130] loss: 0.067\n",
      "[1140/46130] loss: 0.078\n",
      "[1170/46130] loss: 0.069\n",
      "[1200/46130] loss: 0.079\n",
      "[1230/46130] loss: 0.069\n",
      "[1260/46130] loss: 0.066\n",
      "[1290/46130] loss: 0.051\n",
      "[1320/46130] loss: 0.105\n",
      "[1350/46130] loss: 0.072\n",
      "[1380/46130] loss: 0.081\n",
      "[1410/46130] loss: 0.054\n",
      "[1440/46130] loss: 0.090\n",
      "[1470/46130] loss: 0.058\n",
      "[1500/46130] loss: 0.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1530/46130] loss: 0.053\n",
      "[1560/46130] loss: 0.098\n",
      "[1590/46130] loss: 0.073\n",
      "[1620/46130] loss: 0.104\n",
      "[1650/46130] loss: 0.064\n",
      "[1680/46130] loss: 0.063\n",
      "[1710/46130] loss: 0.044\n",
      "[1740/46130] loss: 0.078\n",
      "[1770/46130] loss: 0.061\n",
      "[1800/46130] loss: 0.072\n",
      "[1830/46130] loss: 0.084\n",
      "[1860/46130] loss: 0.069\n",
      "[1890/46130] loss: 0.073\n",
      "[1920/46130] loss: 0.057\n",
      "[1950/46130] loss: 0.076\n",
      "[1980/46130] loss: 0.066\n",
      "[2010/46130] loss: 0.065\n",
      "[2040/46130] loss: 0.086\n",
      "[2070/46130] loss: 0.057\n",
      "[2100/46130] loss: 0.059\n",
      "[2130/46130] loss: 0.061\n",
      "[2160/46130] loss: 0.067\n",
      "[2190/46130] loss: 0.093\n",
      "[2220/46130] loss: 0.072\n",
      "[2250/46130] loss: 0.083\n",
      "[2280/46130] loss: 0.071\n",
      "[2310/46130] loss: 0.066\n",
      "[2340/46130] loss: 0.104\n",
      "[2370/46130] loss: 0.075\n",
      "[2400/46130] loss: 0.094\n",
      "[2430/46130] loss: 0.062\n",
      "[2460/46130] loss: 0.079\n",
      "[2490/46130] loss: 0.057\n",
      "[2520/46130] loss: 0.069\n",
      "[2550/46130] loss: 0.059\n",
      "[2580/46130] loss: 0.079\n",
      "[2610/46130] loss: 0.090\n",
      "[2640/46130] loss: 0.061\n",
      "[2670/46130] loss: 0.081\n",
      "[2700/46130] loss: 0.068\n",
      "[2730/46130] loss: 0.067\n",
      "[2760/46130] loss: 0.078\n",
      "[2790/46130] loss: 0.051\n",
      "[2820/46130] loss: 0.097\n",
      "[2850/46130] loss: 0.068\n",
      "[2880/46130] loss: 0.070\n",
      "[2910/46130] loss: 0.072\n",
      "[2940/46130] loss: 0.104\n",
      "[2970/46130] loss: 0.089\n",
      "[3000/46130] loss: 0.061\n",
      "[3030/46130] loss: 0.055\n",
      "[3060/46130] loss: 0.081\n",
      "[3090/46130] loss: 0.049\n",
      "[3120/46130] loss: 0.072\n",
      "[3150/46130] loss: 0.052\n",
      "[3180/46130] loss: 0.055\n",
      "[3210/46130] loss: 0.082\n",
      "[3240/46130] loss: 0.079\n",
      "[3270/46130] loss: 0.072\n",
      "[3300/46130] loss: 0.076\n",
      "[3330/46130] loss: 0.062\n",
      "[3360/46130] loss: 0.075\n",
      "[3390/46130] loss: 0.073\n",
      "[3420/46130] loss: 0.069\n",
      "[3450/46130] loss: 0.090\n",
      "[3480/46130] loss: 0.072\n",
      "[3510/46130] loss: 0.071\n",
      "[3540/46130] loss: 0.065\n",
      "[3570/46130] loss: 0.064\n",
      "[3600/46130] loss: 0.070\n",
      "[3630/46130] loss: 0.056\n",
      "[3660/46130] loss: 0.061\n",
      "[3690/46130] loss: 0.095\n",
      "[3720/46130] loss: 0.085\n",
      "[3750/46130] loss: 0.056\n",
      "[3780/46130] loss: 0.077\n",
      "[3810/46130] loss: 0.094\n",
      "[3840/46130] loss: 0.089\n",
      "[3870/46130] loss: 0.071\n",
      "[3900/46130] loss: 0.077\n",
      "[3930/46130] loss: 0.066\n",
      "[3960/46130] loss: 0.067\n",
      "[3990/46130] loss: 0.066\n",
      "[4020/46130] loss: 0.066\n",
      "[4050/46130] loss: 0.049\n",
      "[4080/46130] loss: 0.091\n",
      "[4110/46130] loss: 0.080\n",
      "[4140/46130] loss: 0.066\n",
      "[4170/46130] loss: 0.072\n",
      "[4200/46130] loss: 0.058\n",
      "[4230/46130] loss: 0.076\n",
      "[4260/46130] loss: 0.067\n",
      "[4290/46130] loss: 0.070\n",
      "[4320/46130] loss: 0.063\n",
      "[4350/46130] loss: 0.098\n",
      "[4380/46130] loss: 0.073\n",
      "[4410/46130] loss: 0.073\n",
      "[4440/46130] loss: 0.096\n",
      "[4470/46130] loss: 0.079\n",
      "[4500/46130] loss: 0.099\n",
      "[4530/46130] loss: 0.091\n",
      "[4560/46130] loss: 0.073\n",
      "[4590/46130] loss: 0.075\n",
      "[4620/46130] loss: 0.071\n",
      "[4650/46130] loss: 0.051\n",
      "[4680/46130] loss: 0.121\n",
      "[4710/46130] loss: 0.105\n",
      "[4740/46130] loss: 0.103\n",
      "[4770/46130] loss: 0.071\n",
      "[4800/46130] loss: 0.058\n",
      "[4830/46130] loss: 0.091\n",
      "[4860/46130] loss: 0.075\n",
      "[4890/46130] loss: 0.061\n",
      "[4920/46130] loss: 0.069\n",
      "[4950/46130] loss: 0.064\n",
      "[4980/46130] loss: 0.064\n",
      "[5010/46130] loss: 0.104\n",
      "[5040/46130] loss: 0.090\n",
      "[5070/46130] loss: 0.073\n",
      "[5100/46130] loss: 0.084\n",
      "[5130/46130] loss: 0.061\n",
      "[5160/46130] loss: 0.070\n",
      "[5190/46130] loss: 0.066\n",
      "[5220/46130] loss: 0.071\n",
      "[5250/46130] loss: 0.068\n",
      "[5280/46130] loss: 0.088\n",
      "[5310/46130] loss: 0.093\n",
      "[5340/46130] loss: 0.080\n",
      "[5370/46130] loss: 0.059\n",
      "[5400/46130] loss: 0.053\n",
      "[5430/46130] loss: 0.093\n",
      "[5460/46130] loss: 0.071\n",
      "[5490/46130] loss: 0.079\n",
      "[5520/46130] loss: 0.058\n",
      "[5550/46130] loss: 0.082\n",
      "[5580/46130] loss: 0.087\n",
      "[5610/46130] loss: 0.089\n",
      "[5640/46130] loss: 0.072\n",
      "[5670/46130] loss: 0.075\n",
      "[5700/46130] loss: 0.075\n",
      "[5730/46130] loss: 0.068\n",
      "[5760/46130] loss: 0.094\n",
      "[5790/46130] loss: 0.063\n",
      "[5820/46130] loss: 0.084\n",
      "[5850/46130] loss: 0.058\n",
      "[5880/46130] loss: 0.070\n",
      "[5910/46130] loss: 0.054\n",
      "[5940/46130] loss: 0.054\n",
      "[5970/46130] loss: 0.060\n",
      "[6000/46130] loss: 0.091\n",
      "[6030/46130] loss: 0.080\n",
      "[6060/46130] loss: 0.082\n",
      "[6090/46130] loss: 0.093\n",
      "[6120/46130] loss: 0.063\n",
      "[6150/46130] loss: 0.076\n",
      "[6180/46130] loss: 0.068\n",
      "[6210/46130] loss: 0.058\n",
      "[6240/46130] loss: 0.069\n",
      "[6270/46130] loss: 0.075\n",
      "[6300/46130] loss: 0.065\n",
      "[6330/46130] loss: 0.080\n",
      "[6360/46130] loss: 0.040\n",
      "[6390/46130] loss: 0.064\n",
      "[6420/46130] loss: 0.077\n",
      "[6450/46130] loss: 0.060\n",
      "[6480/46130] loss: 0.078\n",
      "[6510/46130] loss: 0.062\n",
      "[6540/46130] loss: 0.068\n",
      "[6570/46130] loss: 0.085\n",
      "[6600/46130] loss: 0.085\n",
      "[6630/46130] loss: 0.093\n",
      "[6660/46130] loss: 0.108\n",
      "[6690/46130] loss: 0.083\n",
      "[6720/46130] loss: 0.073\n",
      "[6750/46130] loss: 0.066\n",
      "[6780/46130] loss: 0.069\n",
      "[6810/46130] loss: 0.079\n",
      "[6840/46130] loss: 0.071\n",
      "[6870/46130] loss: 0.063\n",
      "[6900/46130] loss: 0.058\n",
      "[6930/46130] loss: 0.069\n",
      "[6960/46130] loss: 0.076\n",
      "[6990/46130] loss: 0.063\n",
      "[7020/46130] loss: 0.081\n",
      "[7050/46130] loss: 0.119\n",
      "[7080/46130] loss: 0.098\n",
      "[7110/46130] loss: 0.080\n",
      "[7140/46130] loss: 0.079\n",
      "[7170/46130] loss: 0.068\n",
      "[7200/46130] loss: 0.063\n",
      "[7230/46130] loss: 0.069\n",
      "[7260/46130] loss: 0.090\n",
      "[7290/46130] loss: 0.064\n",
      "[7320/46130] loss: 0.095\n",
      "[7350/46130] loss: 0.057\n",
      "[7380/46130] loss: 0.080\n",
      "[7410/46130] loss: 0.093\n",
      "[7440/46130] loss: 0.075\n",
      "[7470/46130] loss: 0.075\n",
      "[7500/46130] loss: 0.073\n",
      "[7530/46130] loss: 0.069\n",
      "[7560/46130] loss: 0.059\n",
      "[7590/46130] loss: 0.082\n",
      "[7620/46130] loss: 0.083\n",
      "[7650/46130] loss: 0.066\n",
      "[7680/46130] loss: 0.077\n",
      "[7710/46130] loss: 0.067\n",
      "[7740/46130] loss: 0.059\n",
      "[7770/46130] loss: 0.087\n",
      "[7800/46130] loss: 0.077\n",
      "[7830/46130] loss: 0.088\n",
      "[7860/46130] loss: 0.067\n",
      "[7890/46130] loss: 0.073\n",
      "[7920/46130] loss: 0.080\n",
      "[7950/46130] loss: 0.099\n",
      "[7980/46130] loss: 0.067\n",
      "[8010/46130] loss: 0.091\n",
      "[8040/46130] loss: 0.079\n",
      "[8070/46130] loss: 0.076\n",
      "[8100/46130] loss: 0.070\n",
      "[8130/46130] loss: 0.067\n",
      "[8160/46130] loss: 0.084\n",
      "[8190/46130] loss: 0.086\n",
      "[8220/46130] loss: 0.066\n",
      "[8250/46130] loss: 0.091\n",
      "[8280/46130] loss: 0.049\n",
      "[8310/46130] loss: 0.071\n",
      "[8340/46130] loss: 0.076\n",
      "[8370/46130] loss: 0.079\n",
      "[8400/46130] loss: 0.082\n",
      "[8430/46130] loss: 0.070\n",
      "[8460/46130] loss: 0.074\n",
      "[8490/46130] loss: 0.091\n",
      "[8520/46130] loss: 0.066\n",
      "[8550/46130] loss: 0.080\n",
      "[8580/46130] loss: 0.068\n",
      "[8610/46130] loss: 0.050\n",
      "[8640/46130] loss: 0.061\n",
      "[8670/46130] loss: 0.073\n",
      "[8700/46130] loss: 0.057\n",
      "[8730/46130] loss: 0.064\n",
      "[8760/46130] loss: 0.071\n",
      "[8790/46130] loss: 0.068\n",
      "[8820/46130] loss: 0.075\n",
      "[8850/46130] loss: 0.057\n",
      "[8880/46130] loss: 0.066\n",
      "[8910/46130] loss: 0.094\n",
      "[8940/46130] loss: 0.071\n",
      "[8970/46130] loss: 0.069\n",
      "[9000/46130] loss: 0.080\n",
      "[9030/46130] loss: 0.078\n",
      "[9060/46130] loss: 0.081\n",
      "[9090/46130] loss: 0.096\n",
      "[9120/46130] loss: 0.067\n",
      "[9150/46130] loss: 0.061\n",
      "[9180/46130] loss: 0.092\n",
      "[9210/46130] loss: 0.052\n",
      "[9240/46130] loss: 0.096\n",
      "[9270/46130] loss: 0.081\n",
      "[9300/46130] loss: 0.064\n",
      "[9330/46130] loss: 0.093\n",
      "[9360/46130] loss: 0.077\n",
      "[9390/46130] loss: 0.090\n",
      "[9420/46130] loss: 0.083\n",
      "[9450/46130] loss: 0.051\n",
      "[9480/46130] loss: 0.064\n",
      "[9510/46130] loss: 0.072\n",
      "[9540/46130] loss: 0.066\n",
      "[9570/46130] loss: 0.061\n",
      "[9600/46130] loss: 0.055\n",
      "[9630/46130] loss: 0.067\n",
      "[9660/46130] loss: 0.073\n",
      "[9690/46130] loss: 0.057\n",
      "[9720/46130] loss: 0.068\n",
      "[9750/46130] loss: 0.069\n",
      "[9780/46130] loss: 0.071\n",
      "[9810/46130] loss: 0.117\n",
      "[9840/46130] loss: 0.065\n",
      "[9870/46130] loss: 0.080\n",
      "[9900/46130] loss: 0.078\n",
      "[9930/46130] loss: 0.057\n",
      "[9960/46130] loss: 0.063\n",
      "[9990/46130] loss: 0.066\n",
      "[10020/46130] loss: 0.097\n",
      "[10050/46130] loss: 0.089\n",
      "[10080/46130] loss: 0.067\n",
      "[10110/46130] loss: 0.052\n",
      "[10140/46130] loss: 0.088\n",
      "[10170/46130] loss: 0.083\n",
      "[10200/46130] loss: 0.070\n",
      "[10230/46130] loss: 0.039\n",
      "[10260/46130] loss: 0.059\n",
      "[10290/46130] loss: 0.076\n",
      "[10320/46130] loss: 0.085\n",
      "[10350/46130] loss: 0.057\n",
      "[10380/46130] loss: 0.100\n",
      "[10410/46130] loss: 0.064\n",
      "[10440/46130] loss: 0.103\n",
      "[10470/46130] loss: 0.070\n",
      "[10500/46130] loss: 0.072\n",
      "[10530/46130] loss: 0.076\n",
      "[10560/46130] loss: 0.089\n",
      "[10590/46130] loss: 0.075\n",
      "[10620/46130] loss: 0.072\n",
      "[10650/46130] loss: 0.070\n",
      "[10680/46130] loss: 0.090\n",
      "[10710/46130] loss: 0.068\n",
      "[10740/46130] loss: 0.072\n",
      "[10770/46130] loss: 0.046\n",
      "[10800/46130] loss: 0.081\n",
      "[10830/46130] loss: 0.102\n",
      "[10860/46130] loss: 0.055\n",
      "[10890/46130] loss: 0.076\n",
      "[10920/46130] loss: 0.091\n",
      "[10950/46130] loss: 0.082\n",
      "[10980/46130] loss: 0.081\n",
      "[11010/46130] loss: 0.085\n",
      "[11040/46130] loss: 0.063\n",
      "[11070/46130] loss: 0.074\n",
      "[11100/46130] loss: 0.072\n",
      "[11130/46130] loss: 0.082\n",
      "[11160/46130] loss: 0.083\n",
      "[11190/46130] loss: 0.075\n",
      "[11220/46130] loss: 0.059\n",
      "[11250/46130] loss: 0.074\n",
      "[11280/46130] loss: 0.062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11310/46130] loss: 0.080\n",
      "[11340/46130] loss: 0.058\n",
      "[11370/46130] loss: 0.089\n",
      "[11400/46130] loss: 0.064\n",
      "[11430/46130] loss: 0.083\n",
      "[11460/46130] loss: 0.069\n",
      "[11490/46130] loss: 0.069\n",
      "[11520/46130] loss: 0.054\n",
      "[11550/46130] loss: 0.070\n",
      "[11580/46130] loss: 0.083\n",
      "[11610/46130] loss: 0.057\n",
      "[11640/46130] loss: 0.096\n",
      "[11670/46130] loss: 0.073\n",
      "[11700/46130] loss: 0.069\n",
      "[11730/46130] loss: 0.066\n",
      "[11760/46130] loss: 0.061\n",
      "[11790/46130] loss: 0.074\n",
      "[11820/46130] loss: 0.072\n",
      "[11850/46130] loss: 0.092\n",
      "[11880/46130] loss: 0.068\n",
      "[11910/46130] loss: 0.088\n",
      "[11940/46130] loss: 0.072\n",
      "[11970/46130] loss: 0.068\n",
      "[12000/46130] loss: 0.056\n",
      "[12030/46130] loss: 0.057\n",
      "[12060/46130] loss: 0.081\n",
      "[12090/46130] loss: 0.097\n",
      "[12120/46130] loss: 0.068\n",
      "[12150/46130] loss: 0.059\n",
      "[12180/46130] loss: 0.065\n",
      "[12210/46130] loss: 0.070\n",
      "[12240/46130] loss: 0.104\n",
      "[12270/46130] loss: 0.066\n",
      "[12300/46130] loss: 0.124\n",
      "[12330/46130] loss: 0.082\n",
      "[12360/46130] loss: 0.059\n",
      "[12390/46130] loss: 0.100\n",
      "[12420/46130] loss: 0.065\n",
      "[12450/46130] loss: 0.087\n",
      "[12480/46130] loss: 0.077\n",
      "[12510/46130] loss: 0.056\n",
      "[12540/46130] loss: 0.088\n",
      "[12570/46130] loss: 0.071\n",
      "[12600/46130] loss: 0.052\n",
      "[12630/46130] loss: 0.048\n",
      "[12660/46130] loss: 0.071\n",
      "[12690/46130] loss: 0.076\n",
      "[12720/46130] loss: 0.066\n",
      "[12750/46130] loss: 0.068\n",
      "[12780/46130] loss: 0.090\n",
      "[12810/46130] loss: 0.087\n",
      "[12840/46130] loss: 0.054\n",
      "[12870/46130] loss: 0.068\n",
      "[12900/46130] loss: 0.064\n",
      "[12930/46130] loss: 0.063\n",
      "[12960/46130] loss: 0.081\n",
      "[12990/46130] loss: 0.064\n",
      "[13020/46130] loss: 0.058\n",
      "[13050/46130] loss: 0.098\n",
      "[13080/46130] loss: 0.061\n",
      "[13110/46130] loss: 0.069\n",
      "[13140/46130] loss: 0.099\n",
      "[13170/46130] loss: 0.073\n",
      "[13200/46130] loss: 0.056\n",
      "[13230/46130] loss: 0.087\n",
      "[13260/46130] loss: 0.070\n",
      "[13290/46130] loss: 0.051\n",
      "[13320/46130] loss: 0.057\n",
      "[13350/46130] loss: 0.087\n",
      "[13380/46130] loss: 0.091\n",
      "[13410/46130] loss: 0.086\n",
      "[13440/46130] loss: 0.062\n",
      "[13470/46130] loss: 0.063\n",
      "[13500/46130] loss: 0.076\n",
      "[13530/46130] loss: 0.065\n",
      "[13560/46130] loss: 0.072\n",
      "[13590/46130] loss: 0.111\n",
      "[13620/46130] loss: 0.067\n",
      "[13650/46130] loss: 0.065\n",
      "[13680/46130] loss: 0.087\n",
      "[13710/46130] loss: 0.084\n",
      "[13740/46130] loss: 0.086\n",
      "[13770/46130] loss: 0.088\n",
      "[13800/46130] loss: 0.066\n",
      "[13830/46130] loss: 0.098\n",
      "[13860/46130] loss: 0.081\n",
      "[13890/46130] loss: 0.101\n",
      "[13920/46130] loss: 0.066\n",
      "[13950/46130] loss: 0.042\n",
      "[13980/46130] loss: 0.069\n",
      "[14010/46130] loss: 0.091\n",
      "[14040/46130] loss: 0.077\n",
      "[14070/46130] loss: 0.094\n",
      "[14100/46130] loss: 0.074\n",
      "[14130/46130] loss: 0.095\n",
      "[14160/46130] loss: 0.051\n",
      "[14190/46130] loss: 0.070\n",
      "[14220/46130] loss: 0.088\n",
      "[14250/46130] loss: 0.073\n",
      "[14280/46130] loss: 0.107\n",
      "[14310/46130] loss: 0.077\n",
      "[14340/46130] loss: 0.071\n",
      "[14370/46130] loss: 0.039\n",
      "[14400/46130] loss: 0.063\n",
      "[14430/46130] loss: 0.048\n",
      "[14460/46130] loss: 0.062\n",
      "[14490/46130] loss: 0.083\n",
      "[14520/46130] loss: 0.060\n",
      "[14550/46130] loss: 0.070\n",
      "[14580/46130] loss: 0.063\n",
      "[14610/46130] loss: 0.056\n",
      "[14640/46130] loss: 0.065\n",
      "[14670/46130] loss: 0.074\n",
      "[14700/46130] loss: 0.093\n",
      "[14730/46130] loss: 0.059\n",
      "[14760/46130] loss: 0.058\n",
      "[14790/46130] loss: 0.060\n",
      "[14820/46130] loss: 0.048\n",
      "[14850/46130] loss: 0.076\n",
      "[14880/46130] loss: 0.064\n",
      "[14910/46130] loss: 0.067\n",
      "[14940/46130] loss: 0.091\n",
      "[14970/46130] loss: 0.055\n",
      "[15000/46130] loss: 0.070\n",
      "[15030/46130] loss: 0.075\n",
      "[15060/46130] loss: 0.069\n",
      "[15090/46130] loss: 0.067\n",
      "[15120/46130] loss: 0.063\n",
      "[15150/46130] loss: 0.065\n",
      "[15180/46130] loss: 0.049\n",
      "[15210/46130] loss: 0.067\n",
      "[15240/46130] loss: 0.109\n",
      "[15270/46130] loss: 0.057\n",
      "[15300/46130] loss: 0.117\n",
      "[15330/46130] loss: 0.084\n",
      "[15360/46130] loss: 0.077\n",
      "[15390/46130] loss: 0.078\n",
      "[15420/46130] loss: 0.076\n",
      "[15450/46130] loss: 0.070\n",
      "[15480/46130] loss: 0.075\n",
      "[15510/46130] loss: 0.071\n",
      "[15540/46130] loss: 0.065\n",
      "[15570/46130] loss: 0.062\n",
      "[15600/46130] loss: 0.055\n",
      "[15630/46130] loss: 0.078\n",
      "[15660/46130] loss: 0.060\n",
      "[15690/46130] loss: 0.068\n",
      "[15720/46130] loss: 0.069\n",
      "[15750/46130] loss: 0.056\n",
      "[15780/46130] loss: 0.066\n",
      "[15810/46130] loss: 0.095\n",
      "[15840/46130] loss: 0.082\n",
      "[15870/46130] loss: 0.080\n",
      "[15900/46130] loss: 0.112\n",
      "[15930/46130] loss: 0.082\n",
      "[15960/46130] loss: 0.096\n",
      "[15990/46130] loss: 0.092\n",
      "[16020/46130] loss: 0.088\n",
      "[16050/46130] loss: 0.060\n",
      "[16080/46130] loss: 0.071\n",
      "[16110/46130] loss: 0.068\n",
      "[16140/46130] loss: 0.085\n",
      "[16170/46130] loss: 0.078\n",
      "[16200/46130] loss: 0.088\n",
      "[16230/46130] loss: 0.073\n",
      "[16260/46130] loss: 0.085\n",
      "[16290/46130] loss: 0.058\n",
      "[16320/46130] loss: 0.068\n",
      "[16350/46130] loss: 0.083\n",
      "[16380/46130] loss: 0.066\n",
      "[16410/46130] loss: 0.076\n",
      "[16440/46130] loss: 0.092\n",
      "[16470/46130] loss: 0.105\n",
      "[16500/46130] loss: 0.048\n",
      "[16530/46130] loss: 0.076\n",
      "[16560/46130] loss: 0.076\n",
      "[16590/46130] loss: 0.058\n",
      "[16620/46130] loss: 0.088\n",
      "[16650/46130] loss: 0.066\n",
      "[16680/46130] loss: 0.084\n",
      "[16710/46130] loss: 0.054\n",
      "[16740/46130] loss: 0.074\n",
      "[16770/46130] loss: 0.067\n",
      "[16800/46130] loss: 0.064\n",
      "[16830/46130] loss: 0.065\n",
      "[16860/46130] loss: 0.067\n",
      "[16890/46130] loss: 0.085\n",
      "[16920/46130] loss: 0.080\n",
      "[16950/46130] loss: 0.068\n",
      "[16980/46130] loss: 0.089\n",
      "[17010/46130] loss: 0.075\n",
      "[17040/46130] loss: 0.121\n",
      "[17070/46130] loss: 0.072\n",
      "[17100/46130] loss: 0.080\n",
      "[17130/46130] loss: 0.103\n",
      "[17160/46130] loss: 0.080\n",
      "[17190/46130] loss: 0.073\n",
      "[17220/46130] loss: 0.067\n",
      "[17250/46130] loss: 0.073\n",
      "[17280/46130] loss: 0.084\n",
      "[17310/46130] loss: 0.057\n",
      "[17340/46130] loss: 0.091\n",
      "[17370/46130] loss: 0.079\n",
      "[17400/46130] loss: 0.066\n",
      "[17430/46130] loss: 0.076\n",
      "[17460/46130] loss: 0.071\n",
      "[17490/46130] loss: 0.053\n",
      "[17520/46130] loss: 0.076\n",
      "[17550/46130] loss: 0.070\n",
      "[17580/46130] loss: 0.062\n",
      "[17610/46130] loss: 0.080\n",
      "[17640/46130] loss: 0.075\n",
      "[17670/46130] loss: 0.072\n",
      "[17700/46130] loss: 0.084\n",
      "[17730/46130] loss: 0.065\n",
      "[17760/46130] loss: 0.078\n",
      "[17790/46130] loss: 0.075\n",
      "[17820/46130] loss: 0.054\n",
      "[17850/46130] loss: 0.066\n",
      "[17880/46130] loss: 0.061\n",
      "[17910/46130] loss: 0.066\n",
      "[17940/46130] loss: 0.090\n",
      "[17970/46130] loss: 0.093\n",
      "[18000/46130] loss: 0.079\n",
      "[18030/46130] loss: 0.066\n",
      "[18060/46130] loss: 0.051\n",
      "[18090/46130] loss: 0.075\n",
      "[18120/46130] loss: 0.058\n",
      "[18150/46130] loss: 0.062\n",
      "[18180/46130] loss: 0.068\n",
      "[18210/46130] loss: 0.055\n",
      "[18240/46130] loss: 0.110\n",
      "[18270/46130] loss: 0.066\n",
      "[18300/46130] loss: 0.083\n",
      "[18330/46130] loss: 0.049\n",
      "[18360/46130] loss: 0.061\n",
      "[18390/46130] loss: 0.042\n",
      "[18420/46130] loss: 0.056\n",
      "[18450/46130] loss: 0.059\n",
      "[18480/46130] loss: 0.064\n",
      "[18510/46130] loss: 0.100\n",
      "[18540/46130] loss: 0.065\n",
      "[18570/46130] loss: 0.087\n",
      "[18600/46130] loss: 0.070\n",
      "[18630/46130] loss: 0.059\n",
      "[18660/46130] loss: 0.070\n",
      "[18690/46130] loss: 0.072\n",
      "[18720/46130] loss: 0.081\n",
      "[18750/46130] loss: 0.097\n",
      "[18780/46130] loss: 0.062\n",
      "[18810/46130] loss: 0.082\n",
      "[18840/46130] loss: 0.091\n",
      "[18870/46130] loss: 0.057\n",
      "[18900/46130] loss: 0.069\n",
      "[18930/46130] loss: 0.081\n",
      "[18960/46130] loss: 0.079\n",
      "[18990/46130] loss: 0.055\n",
      "[19020/46130] loss: 0.081\n",
      "[19050/46130] loss: 0.052\n",
      "[19080/46130] loss: 0.059\n",
      "[19110/46130] loss: 0.111\n",
      "[19140/46130] loss: 0.048\n",
      "[19170/46130] loss: 0.089\n",
      "[19200/46130] loss: 0.081\n",
      "[19230/46130] loss: 0.052\n",
      "[19260/46130] loss: 0.076\n",
      "[19290/46130] loss: 0.082\n",
      "[19320/46130] loss: 0.059\n",
      "[19350/46130] loss: 0.055\n",
      "[19380/46130] loss: 0.066\n",
      "[19410/46130] loss: 0.100\n",
      "[19440/46130] loss: 0.082\n",
      "[19470/46130] loss: 0.107\n",
      "[19500/46130] loss: 0.064\n",
      "[19530/46130] loss: 0.099\n",
      "[19560/46130] loss: 0.056\n",
      "[19590/46130] loss: 0.057\n",
      "[19620/46130] loss: 0.075\n",
      "[19650/46130] loss: 0.066\n",
      "[19680/46130] loss: 0.048\n",
      "[19710/46130] loss: 0.094\n",
      "[19740/46130] loss: 0.085\n",
      "[19770/46130] loss: 0.049\n",
      "[19800/46130] loss: 0.069\n",
      "[19830/46130] loss: 0.059\n",
      "[19860/46130] loss: 0.068\n",
      "[19890/46130] loss: 0.063\n",
      "[19920/46130] loss: 0.048\n",
      "[19950/46130] loss: 0.081\n",
      "[19980/46130] loss: 0.074\n",
      "[20010/46130] loss: 0.084\n",
      "[20040/46130] loss: 0.087\n",
      "[20070/46130] loss: 0.056\n",
      "[20100/46130] loss: 0.072\n",
      "[20130/46130] loss: 0.061\n",
      "[20160/46130] loss: 0.100\n",
      "[20190/46130] loss: 0.075\n",
      "[20220/46130] loss: 0.077\n",
      "[20250/46130] loss: 0.046\n",
      "[20280/46130] loss: 0.075\n",
      "[20310/46130] loss: 0.070\n",
      "[20340/46130] loss: 0.073\n",
      "[20370/46130] loss: 0.101\n",
      "[20400/46130] loss: 0.090\n",
      "[20430/46130] loss: 0.075\n",
      "[20460/46130] loss: 0.072\n",
      "[20490/46130] loss: 0.061\n",
      "[20520/46130] loss: 0.090\n",
      "[20550/46130] loss: 0.064\n",
      "[20580/46130] loss: 0.071\n",
      "[20610/46130] loss: 0.053\n",
      "[20640/46130] loss: 0.063\n",
      "[20670/46130] loss: 0.081\n",
      "[20700/46130] loss: 0.084\n",
      "[20730/46130] loss: 0.069\n",
      "[20760/46130] loss: 0.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20790/46130] loss: 0.069\n",
      "[20820/46130] loss: 0.088\n",
      "[20850/46130] loss: 0.068\n",
      "[20880/46130] loss: 0.077\n",
      "[20910/46130] loss: 0.085\n",
      "[20940/46130] loss: 0.076\n",
      "[20970/46130] loss: 0.070\n",
      "[21000/46130] loss: 0.067\n",
      "[21030/46130] loss: 0.068\n",
      "[21060/46130] loss: 0.092\n",
      "[21090/46130] loss: 0.061\n",
      "[21120/46130] loss: 0.074\n",
      "[21150/46130] loss: 0.066\n",
      "[21180/46130] loss: 0.071\n",
      "[21210/46130] loss: 0.051\n",
      "[21240/46130] loss: 0.092\n",
      "[21270/46130] loss: 0.064\n",
      "[21300/46130] loss: 0.108\n",
      "[21330/46130] loss: 0.057\n",
      "[21360/46130] loss: 0.075\n",
      "[21390/46130] loss: 0.055\n",
      "[21420/46130] loss: 0.091\n",
      "[21450/46130] loss: 0.074\n",
      "[21480/46130] loss: 0.064\n",
      "[21510/46130] loss: 0.087\n",
      "[21540/46130] loss: 0.086\n",
      "[21570/46130] loss: 0.061\n",
      "[21600/46130] loss: 0.070\n",
      "[21630/46130] loss: 0.055\n",
      "[21660/46130] loss: 0.081\n",
      "[21690/46130] loss: 0.081\n",
      "[21720/46130] loss: 0.063\n",
      "[21750/46130] loss: 0.089\n",
      "[21780/46130] loss: 0.057\n",
      "[21810/46130] loss: 0.077\n",
      "[21840/46130] loss: 0.054\n",
      "[21870/46130] loss: 0.099\n",
      "[21900/46130] loss: 0.049\n",
      "[21930/46130] loss: 0.073\n",
      "[21960/46130] loss: 0.063\n",
      "[21990/46130] loss: 0.096\n",
      "[22020/46130] loss: 0.083\n",
      "[22050/46130] loss: 0.085\n",
      "[22080/46130] loss: 0.052\n",
      "[22110/46130] loss: 0.116\n",
      "[22140/46130] loss: 0.076\n",
      "[22170/46130] loss: 0.071\n",
      "[22200/46130] loss: 0.060\n",
      "[22230/46130] loss: 0.055\n",
      "[22260/46130] loss: 0.082\n",
      "[22290/46130] loss: 0.082\n",
      "[22320/46130] loss: 0.063\n",
      "[22350/46130] loss: 0.052\n",
      "[22380/46130] loss: 0.065\n",
      "[22410/46130] loss: 0.099\n",
      "[22440/46130] loss: 0.091\n",
      "[22470/46130] loss: 0.060\n",
      "[22500/46130] loss: 0.092\n",
      "[22530/46130] loss: 0.064\n",
      "[22560/46130] loss: 0.091\n",
      "[22590/46130] loss: 0.062\n",
      "[22620/46130] loss: 0.084\n",
      "[22650/46130] loss: 0.048\n",
      "[22680/46130] loss: 0.052\n",
      "[22710/46130] loss: 0.052\n",
      "[22740/46130] loss: 0.074\n",
      "[22770/46130] loss: 0.088\n",
      "[22800/46130] loss: 0.071\n",
      "[22830/46130] loss: 0.055\n",
      "[22860/46130] loss: 0.083\n",
      "[22890/46130] loss: 0.070\n",
      "[22920/46130] loss: 0.064\n",
      "[22950/46130] loss: 0.085\n",
      "[22980/46130] loss: 0.075\n",
      "[23010/46130] loss: 0.102\n",
      "[23040/46130] loss: 0.066\n",
      "[23070/46130] loss: 0.072\n",
      "[23100/46130] loss: 0.077\n",
      "[23130/46130] loss: 0.056\n",
      "[23160/46130] loss: 0.083\n",
      "[23190/46130] loss: 0.091\n",
      "[23220/46130] loss: 0.068\n",
      "[23250/46130] loss: 0.085\n",
      "[23280/46130] loss: 0.081\n",
      "[23310/46130] loss: 0.109\n",
      "[23340/46130] loss: 0.066\n",
      "[23370/46130] loss: 0.078\n",
      "[23400/46130] loss: 0.066\n",
      "[23430/46130] loss: 0.100\n",
      "[23460/46130] loss: 0.059\n",
      "[23490/46130] loss: 0.069\n",
      "[23520/46130] loss: 0.068\n",
      "[23550/46130] loss: 0.076\n",
      "[23580/46130] loss: 0.075\n",
      "[23610/46130] loss: 0.061\n",
      "[23640/46130] loss: 0.071\n",
      "[23670/46130] loss: 0.059\n",
      "[23700/46130] loss: 0.084\n",
      "[23730/46130] loss: 0.054\n",
      "[23760/46130] loss: 0.063\n",
      "[23790/46130] loss: 0.082\n",
      "[23820/46130] loss: 0.070\n",
      "[23850/46130] loss: 0.069\n",
      "[23880/46130] loss: 0.092\n",
      "[23910/46130] loss: 0.094\n",
      "[23940/46130] loss: 0.097\n",
      "[23970/46130] loss: 0.072\n",
      "[24000/46130] loss: 0.078\n",
      "[24030/46130] loss: 0.077\n",
      "[24060/46130] loss: 0.082\n",
      "[24090/46130] loss: 0.058\n",
      "[24120/46130] loss: 0.066\n",
      "[24150/46130] loss: 0.057\n",
      "[24180/46130] loss: 0.077\n",
      "[24210/46130] loss: 0.099\n",
      "[24240/46130] loss: 0.073\n",
      "[24270/46130] loss: 0.089\n",
      "[24300/46130] loss: 0.073\n",
      "[24330/46130] loss: 0.076\n",
      "[24360/46130] loss: 0.075\n",
      "[24390/46130] loss: 0.092\n",
      "[24420/46130] loss: 0.068\n",
      "[24450/46130] loss: 0.073\n",
      "[24480/46130] loss: 0.079\n",
      "[24510/46130] loss: 0.071\n",
      "[24540/46130] loss: 0.064\n",
      "[24570/46130] loss: 0.053\n",
      "[24600/46130] loss: 0.053\n",
      "[24630/46130] loss: 0.075\n",
      "[24660/46130] loss: 0.079\n",
      "[24690/46130] loss: 0.084\n",
      "[24720/46130] loss: 0.080\n",
      "[24750/46130] loss: 0.096\n",
      "[24780/46130] loss: 0.090\n",
      "[24810/46130] loss: 0.111\n",
      "[24840/46130] loss: 0.082\n",
      "[24870/46130] loss: 0.071\n",
      "[24900/46130] loss: 0.082\n",
      "[24930/46130] loss: 0.065\n",
      "[24960/46130] loss: 0.075\n",
      "[24990/46130] loss: 0.076\n",
      "[25020/46130] loss: 0.085\n",
      "[25050/46130] loss: 0.073\n",
      "[25080/46130] loss: 0.084\n",
      "[25110/46130] loss: 0.064\n",
      "[25140/46130] loss: 0.072\n",
      "[25170/46130] loss: 0.079\n",
      "[25200/46130] loss: 0.058\n",
      "[25230/46130] loss: 0.087\n",
      "[25260/46130] loss: 0.073\n",
      "[25290/46130] loss: 0.052\n",
      "[25320/46130] loss: 0.064\n",
      "[25350/46130] loss: 0.066\n",
      "[25380/46130] loss: 0.060\n",
      "[25410/46130] loss: 0.085\n",
      "[25440/46130] loss: 0.087\n",
      "[25470/46130] loss: 0.060\n",
      "[25500/46130] loss: 0.089\n",
      "[25530/46130] loss: 0.068\n",
      "[25560/46130] loss: 0.059\n",
      "[25590/46130] loss: 0.058\n",
      "[25620/46130] loss: 0.072\n",
      "[25650/46130] loss: 0.104\n",
      "[25680/46130] loss: 0.057\n",
      "[25710/46130] loss: 0.075\n",
      "[25740/46130] loss: 0.096\n",
      "[25770/46130] loss: 0.091\n",
      "[25800/46130] loss: 0.083\n",
      "[25830/46130] loss: 0.064\n",
      "[25860/46130] loss: 0.076\n",
      "[25890/46130] loss: 0.064\n",
      "[25920/46130] loss: 0.084\n",
      "[25950/46130] loss: 0.069\n",
      "[25980/46130] loss: 0.092\n",
      "[26010/46130] loss: 0.080\n",
      "[26040/46130] loss: 0.072\n",
      "[26070/46130] loss: 0.071\n",
      "[26100/46130] loss: 0.060\n",
      "[26130/46130] loss: 0.080\n",
      "[26160/46130] loss: 0.073\n",
      "[26190/46130] loss: 0.064\n",
      "[26220/46130] loss: 0.106\n",
      "[26250/46130] loss: 0.056\n",
      "[26280/46130] loss: 0.064\n",
      "[26310/46130] loss: 0.098\n",
      "[26340/46130] loss: 0.078\n",
      "[26370/46130] loss: 0.068\n",
      "[26400/46130] loss: 0.041\n",
      "[26430/46130] loss: 0.047\n",
      "[26460/46130] loss: 0.056\n",
      "[26490/46130] loss: 0.064\n",
      "[26520/46130] loss: 0.083\n",
      "[26550/46130] loss: 0.101\n",
      "[26580/46130] loss: 0.072\n",
      "[26610/46130] loss: 0.081\n",
      "[26640/46130] loss: 0.060\n",
      "[26670/46130] loss: 0.086\n",
      "[26700/46130] loss: 0.085\n",
      "[26730/46130] loss: 0.071\n",
      "[26760/46130] loss: 0.059\n",
      "[26790/46130] loss: 0.104\n",
      "[26820/46130] loss: 0.052\n",
      "[26850/46130] loss: 0.072\n",
      "[26880/46130] loss: 0.065\n",
      "[26910/46130] loss: 0.112\n",
      "[26940/46130] loss: 0.092\n",
      "[26970/46130] loss: 0.069\n",
      "[27000/46130] loss: 0.074\n",
      "[27030/46130] loss: 0.067\n",
      "[27060/46130] loss: 0.055\n",
      "[27090/46130] loss: 0.094\n",
      "[27120/46130] loss: 0.059\n",
      "[27150/46130] loss: 0.057\n",
      "[27180/46130] loss: 0.059\n",
      "[27210/46130] loss: 0.065\n",
      "[27240/46130] loss: 0.061\n",
      "[27270/46130] loss: 0.078\n",
      "[27300/46130] loss: 0.067\n",
      "[27330/46130] loss: 0.065\n",
      "[27360/46130] loss: 0.086\n",
      "[27390/46130] loss: 0.041\n",
      "[27420/46130] loss: 0.073\n",
      "[27450/46130] loss: 0.078\n",
      "[27480/46130] loss: 0.064\n",
      "[27510/46130] loss: 0.086\n",
      "[27540/46130] loss: 0.075\n",
      "[27570/46130] loss: 0.079\n",
      "[27600/46130] loss: 0.072\n",
      "[27630/46130] loss: 0.066\n",
      "[27660/46130] loss: 0.073\n",
      "[27690/46130] loss: 0.051\n",
      "[27720/46130] loss: 0.065\n",
      "[27750/46130] loss: 0.089\n",
      "[27780/46130] loss: 0.063\n",
      "[27810/46130] loss: 0.067\n",
      "[27840/46130] loss: 0.063\n",
      "[27870/46130] loss: 0.061\n",
      "[27900/46130] loss: 0.072\n",
      "[27930/46130] loss: 0.076\n",
      "[27960/46130] loss: 0.056\n",
      "[27990/46130] loss: 0.053\n",
      "[28020/46130] loss: 0.063\n",
      "[28050/46130] loss: 0.069\n",
      "[28080/46130] loss: 0.072\n",
      "[28110/46130] loss: 0.057\n",
      "[28140/46130] loss: 0.069\n",
      "[28170/46130] loss: 0.075\n",
      "[28200/46130] loss: 0.067\n",
      "[28230/46130] loss: 0.105\n",
      "[28260/46130] loss: 0.059\n",
      "[28290/46130] loss: 0.066\n",
      "[28320/46130] loss: 0.072\n",
      "[28350/46130] loss: 0.062\n",
      "[28380/46130] loss: 0.065\n",
      "[28410/46130] loss: 0.083\n",
      "[28440/46130] loss: 0.052\n",
      "[28470/46130] loss: 0.068\n",
      "[28500/46130] loss: 0.074\n",
      "[28530/46130] loss: 0.056\n",
      "[28560/46130] loss: 0.065\n",
      "[28590/46130] loss: 0.081\n",
      "[28620/46130] loss: 0.058\n",
      "[28650/46130] loss: 0.085\n",
      "[28680/46130] loss: 0.048\n",
      "[28710/46130] loss: 0.053\n",
      "[28740/46130] loss: 0.081\n",
      "[28770/46130] loss: 0.073\n",
      "[28800/46130] loss: 0.081\n",
      "[28830/46130] loss: 0.091\n",
      "[28860/46130] loss: 0.067\n",
      "[28890/46130] loss: 0.058\n",
      "[28920/46130] loss: 0.093\n",
      "[28950/46130] loss: 0.067\n",
      "[28980/46130] loss: 0.067\n",
      "[29010/46130] loss: 0.079\n",
      "[29040/46130] loss: 0.080\n",
      "[29070/46130] loss: 0.066\n",
      "[29100/46130] loss: 0.059\n",
      "[29130/46130] loss: 0.078\n",
      "[29160/46130] loss: 0.105\n",
      "[29190/46130] loss: 0.090\n",
      "[29220/46130] loss: 0.085\n",
      "[29250/46130] loss: 0.068\n",
      "[29280/46130] loss: 0.046\n",
      "[29310/46130] loss: 0.061\n",
      "[29340/46130] loss: 0.098\n",
      "[29370/46130] loss: 0.050\n",
      "[29400/46130] loss: 0.070\n",
      "[29430/46130] loss: 0.064\n",
      "[29460/46130] loss: 0.087\n",
      "[29490/46130] loss: 0.057\n",
      "[29520/46130] loss: 0.047\n",
      "[29550/46130] loss: 0.056\n",
      "[29580/46130] loss: 0.090\n",
      "[29610/46130] loss: 0.067\n",
      "[29640/46130] loss: 0.058\n",
      "[29670/46130] loss: 0.091\n",
      "[29700/46130] loss: 0.066\n",
      "[29730/46130] loss: 0.116\n",
      "[29760/46130] loss: 0.066\n",
      "[29790/46130] loss: 0.087\n",
      "[29820/46130] loss: 0.079\n",
      "[29850/46130] loss: 0.049\n",
      "[29880/46130] loss: 0.078\n",
      "[29910/46130] loss: 0.075\n",
      "[29940/46130] loss: 0.074\n",
      "[29970/46130] loss: 0.074\n",
      "[30000/46130] loss: 0.077\n",
      "[30030/46130] loss: 0.048\n",
      "[30060/46130] loss: 0.052\n",
      "[30090/46130] loss: 0.061\n",
      "[30120/46130] loss: 0.077\n",
      "[30150/46130] loss: 0.053\n",
      "[30180/46130] loss: 0.106\n",
      "[30210/46130] loss: 0.081\n",
      "[30240/46130] loss: 0.070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30270/46130] loss: 0.073\n",
      "[30300/46130] loss: 0.074\n",
      "[30330/46130] loss: 0.065\n",
      "[30360/46130] loss: 0.075\n",
      "[30390/46130] loss: 0.066\n",
      "[30420/46130] loss: 0.072\n",
      "[30450/46130] loss: 0.069\n",
      "[30480/46130] loss: 0.092\n",
      "[30510/46130] loss: 0.054\n",
      "[30540/46130] loss: 0.081\n",
      "[30570/46130] loss: 0.068\n",
      "[30600/46130] loss: 0.075\n",
      "[30630/46130] loss: 0.070\n",
      "[30660/46130] loss: 0.051\n",
      "[30690/46130] loss: 0.052\n",
      "[30720/46130] loss: 0.092\n",
      "[30750/46130] loss: 0.038\n",
      "[30780/46130] loss: 0.069\n",
      "[30810/46130] loss: 0.080\n",
      "[30840/46130] loss: 0.069\n",
      "[30870/46130] loss: 0.078\n",
      "[30900/46130] loss: 0.076\n",
      "[30930/46130] loss: 0.075\n",
      "[30960/46130] loss: 0.051\n",
      "[30990/46130] loss: 0.066\n",
      "[31020/46130] loss: 0.089\n",
      "[31050/46130] loss: 0.056\n",
      "[31080/46130] loss: 0.075\n",
      "[31110/46130] loss: 0.043\n",
      "[31140/46130] loss: 0.105\n",
      "[31170/46130] loss: 0.082\n",
      "[31200/46130] loss: 0.089\n",
      "[31230/46130] loss: 0.109\n",
      "[31260/46130] loss: 0.074\n",
      "[31290/46130] loss: 0.062\n",
      "[31320/46130] loss: 0.085\n",
      "[31350/46130] loss: 0.043\n",
      "[31380/46130] loss: 0.098\n",
      "[31410/46130] loss: 0.085\n",
      "[31440/46130] loss: 0.101\n",
      "[31470/46130] loss: 0.074\n",
      "[31500/46130] loss: 0.090\n",
      "[31530/46130] loss: 0.068\n",
      "[31560/46130] loss: 0.062\n",
      "[31590/46130] loss: 0.086\n",
      "[31620/46130] loss: 0.071\n",
      "[31650/46130] loss: 0.082\n",
      "[31680/46130] loss: 0.077\n",
      "[31710/46130] loss: 0.056\n",
      "[31740/46130] loss: 0.071\n",
      "[31770/46130] loss: 0.064\n",
      "[31800/46130] loss: 0.072\n",
      "[31830/46130] loss: 0.064\n",
      "[31860/46130] loss: 0.087\n",
      "[31890/46130] loss: 0.076\n",
      "[31920/46130] loss: 0.072\n",
      "[31950/46130] loss: 0.064\n",
      "[31980/46130] loss: 0.081\n",
      "[32010/46130] loss: 0.109\n",
      "[32040/46130] loss: 0.056\n",
      "[32070/46130] loss: 0.046\n",
      "[32100/46130] loss: 0.073\n",
      "[32130/46130] loss: 0.064\n",
      "[32160/46130] loss: 0.074\n",
      "[32190/46130] loss: 0.060\n",
      "[32220/46130] loss: 0.075\n",
      "[32250/46130] loss: 0.088\n",
      "[32280/46130] loss: 0.064\n",
      "[32310/46130] loss: 0.060\n",
      "[32340/46130] loss: 0.080\n",
      "[32370/46130] loss: 0.080\n",
      "[32400/46130] loss: 0.082\n",
      "[32430/46130] loss: 0.051\n",
      "[32460/46130] loss: 0.066\n",
      "[32490/46130] loss: 0.051\n",
      "[32520/46130] loss: 0.071\n",
      "[32550/46130] loss: 0.087\n",
      "[32580/46130] loss: 0.059\n",
      "[32610/46130] loss: 0.066\n",
      "[32640/46130] loss: 0.099\n",
      "[32670/46130] loss: 0.057\n",
      "[32700/46130] loss: 0.078\n",
      "[32730/46130] loss: 0.063\n",
      "[32760/46130] loss: 0.079\n",
      "[32790/46130] loss: 0.085\n",
      "[32820/46130] loss: 0.059\n",
      "[32850/46130] loss: 0.101\n",
      "[32880/46130] loss: 0.064\n",
      "[32910/46130] loss: 0.066\n",
      "[32940/46130] loss: 0.055\n",
      "[32970/46130] loss: 0.073\n",
      "[33000/46130] loss: 0.079\n",
      "[33030/46130] loss: 0.062\n",
      "[33060/46130] loss: 0.073\n",
      "[33090/46130] loss: 0.051\n",
      "[33120/46130] loss: 0.082\n",
      "[33150/46130] loss: 0.068\n",
      "[33180/46130] loss: 0.066\n",
      "[33210/46130] loss: 0.079\n",
      "[33240/46130] loss: 0.056\n",
      "[33270/46130] loss: 0.073\n",
      "[33300/46130] loss: 0.085\n",
      "[33330/46130] loss: 0.068\n",
      "[33360/46130] loss: 0.123\n",
      "[33390/46130] loss: 0.068\n",
      "[33420/46130] loss: 0.088\n",
      "[33450/46130] loss: 0.049\n",
      "[33480/46130] loss: 0.079\n",
      "[33510/46130] loss: 0.069\n",
      "[33540/46130] loss: 0.076\n",
      "[33570/46130] loss: 0.055\n",
      "[33600/46130] loss: 0.070\n",
      "[33630/46130] loss: 0.057\n",
      "[33660/46130] loss: 0.062\n",
      "[33690/46130] loss: 0.044\n",
      "[33720/46130] loss: 0.060\n",
      "[33750/46130] loss: 0.085\n",
      "[33780/46130] loss: 0.069\n",
      "[33810/46130] loss: 0.078\n",
      "[33840/46130] loss: 0.072\n",
      "[33870/46130] loss: 0.060\n",
      "[33900/46130] loss: 0.077\n",
      "[33930/46130] loss: 0.054\n",
      "[33960/46130] loss: 0.059\n",
      "[33990/46130] loss: 0.060\n",
      "[34020/46130] loss: 0.067\n",
      "[34050/46130] loss: 0.061\n",
      "[34080/46130] loss: 0.056\n",
      "[34110/46130] loss: 0.066\n",
      "[34140/46130] loss: 0.087\n",
      "[34170/46130] loss: 0.074\n",
      "[34200/46130] loss: 0.100\n",
      "[34230/46130] loss: 0.072\n",
      "[34260/46130] loss: 0.082\n",
      "[34290/46130] loss: 0.071\n",
      "[34320/46130] loss: 0.081\n",
      "[34350/46130] loss: 0.057\n",
      "[34380/46130] loss: 0.063\n",
      "[34410/46130] loss: 0.074\n",
      "[34440/46130] loss: 0.097\n",
      "[34470/46130] loss: 0.081\n",
      "[34500/46130] loss: 0.077\n",
      "[34530/46130] loss: 0.059\n",
      "[34560/46130] loss: 0.081\n",
      "[34590/46130] loss: 0.073\n",
      "[34620/46130] loss: 0.073\n",
      "[34650/46130] loss: 0.060\n",
      "[34680/46130] loss: 0.068\n",
      "[34710/46130] loss: 0.060\n",
      "[34740/46130] loss: 0.078\n",
      "[34770/46130] loss: 0.079\n",
      "[34800/46130] loss: 0.104\n",
      "[34830/46130] loss: 0.060\n",
      "[34860/46130] loss: 0.059\n",
      "[34890/46130] loss: 0.059\n",
      "[34920/46130] loss: 0.055\n",
      "[34950/46130] loss: 0.068\n",
      "[34980/46130] loss: 0.077\n",
      "[35010/46130] loss: 0.078\n",
      "[35040/46130] loss: 0.057\n",
      "[35070/46130] loss: 0.067\n",
      "[35100/46130] loss: 0.079\n",
      "[35130/46130] loss: 0.057\n",
      "[35160/46130] loss: 0.068\n",
      "[35190/46130] loss: 0.081\n",
      "[35220/46130] loss: 0.084\n",
      "[35250/46130] loss: 0.069\n",
      "[35280/46130] loss: 0.126\n",
      "[35310/46130] loss: 0.062\n",
      "[35340/46130] loss: 0.050\n",
      "[35370/46130] loss: 0.075\n",
      "[35400/46130] loss: 0.056\n",
      "[35430/46130] loss: 0.069\n",
      "[35460/46130] loss: 0.071\n",
      "[35490/46130] loss: 0.082\n",
      "[35520/46130] loss: 0.073\n",
      "[35550/46130] loss: 0.082\n",
      "[35580/46130] loss: 0.048\n",
      "[35610/46130] loss: 0.068\n",
      "[35640/46130] loss: 0.065\n",
      "[35670/46130] loss: 0.071\n",
      "[35700/46130] loss: 0.076\n",
      "[35730/46130] loss: 0.069\n",
      "[35760/46130] loss: 0.071\n",
      "[35790/46130] loss: 0.069\n",
      "[35820/46130] loss: 0.063\n",
      "[35850/46130] loss: 0.062\n",
      "[35880/46130] loss: 0.101\n",
      "[35910/46130] loss: 0.064\n",
      "[35940/46130] loss: 0.066\n",
      "[35970/46130] loss: 0.053\n",
      "[36000/46130] loss: 0.079\n",
      "[36030/46130] loss: 0.078\n",
      "[36060/46130] loss: 0.089\n",
      "[36090/46130] loss: 0.103\n",
      "[36120/46130] loss: 0.058\n",
      "[36150/46130] loss: 0.071\n",
      "[36180/46130] loss: 0.068\n",
      "[36210/46130] loss: 0.072\n",
      "[36240/46130] loss: 0.057\n",
      "[36270/46130] loss: 0.103\n",
      "[36300/46130] loss: 0.045\n",
      "[36330/46130] loss: 0.092\n",
      "[36360/46130] loss: 0.079\n",
      "[36390/46130] loss: 0.064\n",
      "[36420/46130] loss: 0.079\n",
      "[36450/46130] loss: 0.077\n",
      "[36480/46130] loss: 0.069\n",
      "[36510/46130] loss: 0.071\n",
      "[36540/46130] loss: 0.071\n",
      "[36570/46130] loss: 0.052\n",
      "[36600/46130] loss: 0.061\n",
      "[36630/46130] loss: 0.075\n",
      "[36660/46130] loss: 0.075\n",
      "[36690/46130] loss: 0.072\n",
      "[36720/46130] loss: 0.058\n",
      "[36750/46130] loss: 0.067\n",
      "[36780/46130] loss: 0.084\n",
      "[36810/46130] loss: 0.081\n",
      "[36840/46130] loss: 0.078\n",
      "[36870/46130] loss: 0.080\n",
      "[36900/46130] loss: 0.065\n",
      "[36930/46130] loss: 0.042\n",
      "[36960/46130] loss: 0.070\n",
      "[36990/46130] loss: 0.070\n",
      "[37020/46130] loss: 0.069\n",
      "[37050/46130] loss: 0.094\n",
      "[37080/46130] loss: 0.044\n",
      "[37110/46130] loss: 0.094\n",
      "[37140/46130] loss: 0.067\n",
      "[37170/46130] loss: 0.066\n",
      "[37200/46130] loss: 0.061\n",
      "[37230/46130] loss: 0.066\n",
      "[37260/46130] loss: 0.056\n",
      "[37290/46130] loss: 0.090\n",
      "[37320/46130] loss: 0.093\n",
      "[37350/46130] loss: 0.075\n",
      "[37380/46130] loss: 0.069\n",
      "[37410/46130] loss: 0.072\n",
      "[37440/46130] loss: 0.041\n",
      "[37470/46130] loss: 0.064\n",
      "[37500/46130] loss: 0.053\n",
      "[37530/46130] loss: 0.087\n",
      "[37560/46130] loss: 0.081\n",
      "[37590/46130] loss: 0.064\n",
      "[37620/46130] loss: 0.083\n",
      "[37650/46130] loss: 0.048\n",
      "[37680/46130] loss: 0.063\n",
      "[37710/46130] loss: 0.059\n",
      "[37740/46130] loss: 0.072\n",
      "[37770/46130] loss: 0.053\n",
      "[37800/46130] loss: 0.048\n",
      "[37830/46130] loss: 0.058\n",
      "[37860/46130] loss: 0.098\n",
      "[37890/46130] loss: 0.085\n",
      "[37920/46130] loss: 0.081\n",
      "[37950/46130] loss: 0.050\n",
      "[37980/46130] loss: 0.102\n",
      "[38010/46130] loss: 0.063\n",
      "[38040/46130] loss: 0.097\n",
      "[38070/46130] loss: 0.077\n",
      "[38100/46130] loss: 0.066\n",
      "[38130/46130] loss: 0.077\n",
      "[38160/46130] loss: 0.101\n",
      "[38190/46130] loss: 0.060\n",
      "[38220/46130] loss: 0.087\n",
      "[38250/46130] loss: 0.067\n",
      "[38280/46130] loss: 0.074\n",
      "[38310/46130] loss: 0.058\n",
      "[38340/46130] loss: 0.076\n",
      "[38370/46130] loss: 0.067\n",
      "[38400/46130] loss: 0.059\n",
      "[38430/46130] loss: 0.060\n",
      "[38460/46130] loss: 0.096\n",
      "[38490/46130] loss: 0.066\n",
      "[38520/46130] loss: 0.072\n",
      "[38550/46130] loss: 0.066\n",
      "[38580/46130] loss: 0.094\n",
      "[38610/46130] loss: 0.075\n",
      "[38640/46130] loss: 0.073\n",
      "[38670/46130] loss: 0.088\n",
      "[38700/46130] loss: 0.059\n",
      "[38730/46130] loss: 0.084\n",
      "[38760/46130] loss: 0.066\n",
      "[38790/46130] loss: 0.057\n",
      "[38820/46130] loss: 0.082\n",
      "[38850/46130] loss: 0.085\n",
      "[38880/46130] loss: 0.063\n",
      "[38910/46130] loss: 0.084\n",
      "[38940/46130] loss: 0.077\n",
      "[38970/46130] loss: 0.098\n",
      "[39000/46130] loss: 0.073\n",
      "[39030/46130] loss: 0.061\n",
      "[39060/46130] loss: 0.069\n",
      "[39090/46130] loss: 0.074\n",
      "[39120/46130] loss: 0.068\n",
      "[39150/46130] loss: 0.089\n",
      "[39180/46130] loss: 0.072\n",
      "[39210/46130] loss: 0.041\n",
      "[39240/46130] loss: 0.097\n",
      "[39270/46130] loss: 0.049\n",
      "[39300/46130] loss: 0.073\n",
      "[39330/46130] loss: 0.081\n",
      "[39360/46130] loss: 0.054\n",
      "[39390/46130] loss: 0.076\n",
      "[39420/46130] loss: 0.050\n",
      "[39450/46130] loss: 0.070\n",
      "[39480/46130] loss: 0.068\n",
      "[39510/46130] loss: 0.068\n",
      "[39540/46130] loss: 0.110\n",
      "[39570/46130] loss: 0.078\n",
      "[39600/46130] loss: 0.071\n",
      "[39630/46130] loss: 0.062\n",
      "[39660/46130] loss: 0.077\n",
      "[39690/46130] loss: 0.058\n",
      "[39720/46130] loss: 0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39750/46130] loss: 0.062\n",
      "[39780/46130] loss: 0.084\n",
      "[39810/46130] loss: 0.069\n",
      "[39840/46130] loss: 0.052\n",
      "[39870/46130] loss: 0.110\n",
      "[39900/46130] loss: 0.068\n",
      "[39930/46130] loss: 0.087\n",
      "[39960/46130] loss: 0.067\n",
      "[39990/46130] loss: 0.088\n",
      "[40020/46130] loss: 0.069\n",
      "[40050/46130] loss: 0.091\n",
      "[40080/46130] loss: 0.066\n",
      "[40110/46130] loss: 0.079\n",
      "[40140/46130] loss: 0.062\n",
      "[40170/46130] loss: 0.098\n",
      "[40200/46130] loss: 0.059\n",
      "[40230/46130] loss: 0.058\n",
      "[40260/46130] loss: 0.056\n",
      "[40290/46130] loss: 0.120\n",
      "[40320/46130] loss: 0.092\n",
      "[40350/46130] loss: 0.062\n",
      "[40380/46130] loss: 0.061\n",
      "[40410/46130] loss: 0.070\n",
      "[40440/46130] loss: 0.083\n",
      "[40470/46130] loss: 0.044\n",
      "[40500/46130] loss: 0.088\n",
      "[40530/46130] loss: 0.079\n",
      "[40560/46130] loss: 0.083\n",
      "[40590/46130] loss: 0.054\n",
      "[40620/46130] loss: 0.059\n",
      "[40650/46130] loss: 0.060\n",
      "[40680/46130] loss: 0.074\n",
      "[40710/46130] loss: 0.069\n",
      "[40740/46130] loss: 0.060\n",
      "[40770/46130] loss: 0.084\n",
      "[40800/46130] loss: 0.092\n",
      "[40830/46130] loss: 0.062\n",
      "[40860/46130] loss: 0.065\n",
      "[40890/46130] loss: 0.081\n",
      "[40920/46130] loss: 0.079\n",
      "[40950/46130] loss: 0.092\n",
      "[40980/46130] loss: 0.050\n",
      "[41010/46130] loss: 0.069\n",
      "[41040/46130] loss: 0.069\n",
      "[41070/46130] loss: 0.070\n",
      "[41100/46130] loss: 0.081\n",
      "[41130/46130] loss: 0.083\n",
      "[41160/46130] loss: 0.069\n",
      "[41190/46130] loss: 0.035\n",
      "[41220/46130] loss: 0.097\n",
      "[41250/46130] loss: 0.063\n",
      "[41280/46130] loss: 0.056\n",
      "[41310/46130] loss: 0.091\n",
      "[41340/46130] loss: 0.065\n",
      "[41370/46130] loss: 0.075\n",
      "[41400/46130] loss: 0.057\n",
      "[41430/46130] loss: 0.066\n",
      "[41460/46130] loss: 0.075\n",
      "[41490/46130] loss: 0.071\n",
      "[41520/46130] loss: 0.085\n",
      "[41550/46130] loss: 0.075\n",
      "[41580/46130] loss: 0.078\n",
      "[41610/46130] loss: 0.068\n",
      "[41640/46130] loss: 0.074\n",
      "[41670/46130] loss: 0.061\n",
      "[41700/46130] loss: 0.074\n",
      "[41730/46130] loss: 0.071\n",
      "[41760/46130] loss: 0.103\n",
      "[41790/46130] loss: 0.059\n",
      "[41820/46130] loss: 0.062\n",
      "[41850/46130] loss: 0.066\n",
      "[41880/46130] loss: 0.066\n",
      "[41910/46130] loss: 0.058\n",
      "[41940/46130] loss: 0.079\n",
      "[41970/46130] loss: 0.080\n",
      "[42000/46130] loss: 0.065\n",
      "[42030/46130] loss: 0.068\n",
      "[42060/46130] loss: 0.060\n",
      "[42090/46130] loss: 0.092\n",
      "[42120/46130] loss: 0.063\n",
      "[42150/46130] loss: 0.055\n",
      "[42180/46130] loss: 0.068\n",
      "[42210/46130] loss: 0.068\n",
      "[42240/46130] loss: 0.060\n",
      "[42270/46130] loss: 0.088\n",
      "[42300/46130] loss: 0.062\n",
      "[42330/46130] loss: 0.053\n",
      "[42360/46130] loss: 0.087\n",
      "[42390/46130] loss: 0.082\n",
      "[42420/46130] loss: 0.054\n",
      "[42450/46130] loss: 0.062\n",
      "[42480/46130] loss: 0.068\n",
      "[42510/46130] loss: 0.071\n",
      "[42540/46130] loss: 0.053\n",
      "[42570/46130] loss: 0.066\n",
      "[42600/46130] loss: 0.046\n",
      "[42630/46130] loss: 0.060\n",
      "[42660/46130] loss: 0.074\n",
      "[42690/46130] loss: 0.067\n",
      "[42720/46130] loss: 0.108\n",
      "[42750/46130] loss: 0.064\n",
      "[42780/46130] loss: 0.074\n",
      "[42810/46130] loss: 0.054\n",
      "[42840/46130] loss: 0.075\n",
      "[42870/46130] loss: 0.066\n",
      "[42900/46130] loss: 0.056\n",
      "[42930/46130] loss: 0.070\n",
      "[42960/46130] loss: 0.095\n",
      "[42990/46130] loss: 0.064\n",
      "[43020/46130] loss: 0.048\n",
      "[43050/46130] loss: 0.090\n",
      "[43080/46130] loss: 0.075\n",
      "[43110/46130] loss: 0.071\n",
      "[43140/46130] loss: 0.092\n",
      "[43170/46130] loss: 0.077\n",
      "[43200/46130] loss: 0.055\n",
      "[43230/46130] loss: 0.055\n",
      "[43260/46130] loss: 0.066\n",
      "[43290/46130] loss: 0.049\n",
      "[43320/46130] loss: 0.093\n",
      "[43350/46130] loss: 0.052\n",
      "[43380/46130] loss: 0.048\n",
      "[43410/46130] loss: 0.080\n",
      "[43440/46130] loss: 0.088\n",
      "[43470/46130] loss: 0.063\n",
      "[43500/46130] loss: 0.055\n",
      "[43530/46130] loss: 0.060\n",
      "[43560/46130] loss: 0.056\n",
      "[43590/46130] loss: 0.086\n",
      "[43620/46130] loss: 0.074\n",
      "[43650/46130] loss: 0.060\n",
      "[43680/46130] loss: 0.057\n",
      "[43710/46130] loss: 0.085\n",
      "[43740/46130] loss: 0.063\n",
      "[43770/46130] loss: 0.102\n",
      "[43800/46130] loss: 0.071\n",
      "[43830/46130] loss: 0.063\n",
      "[43860/46130] loss: 0.069\n",
      "[43890/46130] loss: 0.062\n",
      "[43920/46130] loss: 0.051\n",
      "[43950/46130] loss: 0.068\n",
      "[43980/46130] loss: 0.060\n",
      "[44010/46130] loss: 0.054\n",
      "[44040/46130] loss: 0.038\n",
      "[44070/46130] loss: 0.069\n",
      "[44100/46130] loss: 0.080\n",
      "[44130/46130] loss: 0.061\n",
      "[44160/46130] loss: 0.080\n",
      "[44190/46130] loss: 0.058\n",
      "[44220/46130] loss: 0.064\n",
      "[44250/46130] loss: 0.064\n",
      "[44280/46130] loss: 0.051\n",
      "[44310/46130] loss: 0.084\n",
      "[44340/46130] loss: 0.057\n",
      "[44370/46130] loss: 0.090\n",
      "[44400/46130] loss: 0.065\n",
      "[44430/46130] loss: 0.073\n",
      "[44460/46130] loss: 0.063\n",
      "[44490/46130] loss: 0.039\n",
      "[44520/46130] loss: 0.065\n",
      "[44550/46130] loss: 0.069\n",
      "[44580/46130] loss: 0.082\n",
      "[44610/46130] loss: 0.079\n",
      "[44640/46130] loss: 0.069\n",
      "[44670/46130] loss: 0.062\n",
      "[44700/46130] loss: 0.096\n",
      "[44730/46130] loss: 0.072\n",
      "[44760/46130] loss: 0.073\n",
      "[44790/46130] loss: 0.093\n",
      "[44820/46130] loss: 0.062\n",
      "[44850/46130] loss: 0.087\n",
      "[44880/46130] loss: 0.055\n",
      "[44910/46130] loss: 0.065\n",
      "[44940/46130] loss: 0.062\n",
      "[44970/46130] loss: 0.074\n",
      "[45000/46130] loss: 0.061\n",
      "[45030/46130] loss: 0.081\n",
      "[45060/46130] loss: 0.054\n",
      "[45090/46130] loss: 0.051\n",
      "[45120/46130] loss: 0.065\n",
      "[45150/46130] loss: 0.082\n",
      "[45180/46130] loss: 0.137\n",
      "[45210/46130] loss: 0.065\n",
      "[45240/46130] loss: 0.079\n",
      "[45270/46130] loss: 0.066\n",
      "[45300/46130] loss: 0.058\n",
      "[45330/46130] loss: 0.087\n",
      "[45360/46130] loss: 0.079\n",
      "[45390/46130] loss: 0.062\n",
      "[45420/46130] loss: 0.076\n",
      "[45450/46130] loss: 0.063\n",
      "[45480/46130] loss: 0.084\n",
      "[45510/46130] loss: 0.056\n",
      "[45540/46130] loss: 0.076\n",
      "[45570/46130] loss: 0.074\n",
      "[45600/46130] loss: 0.068\n",
      "[45630/46130] loss: 0.077\n",
      "[45660/46130] loss: 0.073\n",
      "[45690/46130] loss: 0.084\n",
      "[45720/46130] loss: 0.054\n",
      "[45750/46130] loss: 0.086\n",
      "[45780/46130] loss: 0.060\n",
      "[45810/46130] loss: 0.066\n",
      "[45840/46130] loss: 0.093\n",
      "[45870/46130] loss: 0.105\n",
      "[45900/46130] loss: 0.063\n",
      "[45930/46130] loss: 0.043\n",
      "[45960/46130] loss: 0.078\n",
      "[45990/46130] loss: 0.042\n",
      "[46020/46130] loss: 0.073\n",
      "[46050/46130] loss: 0.060\n",
      "[46080/46130] loss: 0.049\n",
      "[46110/46130] loss: 0.043\n",
      "Epoch 1 train loss: 0.0723\n",
      "Validation Accuracy: 0.994839\n",
      "Precision: 0.6945349952061362\n",
      "Recall: 0.9660384068278806\n",
      "Validation F0.5-Score: 0.7358996586660886\n",
      "Epoch 1 val loss: 0.0613\n",
      "--------------------------------------------------\n",
      "Epoch 2/2\n",
      "[30/46130] loss: 0.049\n",
      "[60/46130] loss: 0.073\n",
      "[90/46130] loss: 0.054\n",
      "[120/46130] loss: 0.035\n",
      "[150/46130] loss: 0.047\n",
      "[180/46130] loss: 0.073\n",
      "[210/46130] loss: 0.066\n",
      "[240/46130] loss: 0.048\n",
      "[270/46130] loss: 0.058\n",
      "[300/46130] loss: 0.057\n",
      "[330/46130] loss: 0.027\n",
      "[360/46130] loss: 0.052\n",
      "[390/46130] loss: 0.057\n",
      "[420/46130] loss: 0.060\n",
      "[450/46130] loss: 0.056\n",
      "[480/46130] loss: 0.061\n",
      "[510/46130] loss: 0.087\n",
      "[540/46130] loss: 0.036\n",
      "[570/46130] loss: 0.041\n",
      "[600/46130] loss: 0.041\n",
      "[630/46130] loss: 0.047\n",
      "[660/46130] loss: 0.060\n",
      "[690/46130] loss: 0.032\n",
      "[720/46130] loss: 0.057\n",
      "[750/46130] loss: 0.064\n",
      "[780/46130] loss: 0.074\n",
      "[810/46130] loss: 0.047\n",
      "[840/46130] loss: 0.050\n",
      "[870/46130] loss: 0.055\n",
      "[900/46130] loss: 0.044\n",
      "[930/46130] loss: 0.055\n",
      "[960/46130] loss: 0.055\n",
      "[990/46130] loss: 0.052\n",
      "[1020/46130] loss: 0.072\n",
      "[1050/46130] loss: 0.055\n",
      "[1080/46130] loss: 0.051\n",
      "[1110/46130] loss: 0.067\n",
      "[1140/46130] loss: 0.069\n",
      "[1170/46130] loss: 0.048\n",
      "[1200/46130] loss: 0.059\n",
      "[1230/46130] loss: 0.053\n",
      "[1260/46130] loss: 0.072\n",
      "[1290/46130] loss: 0.029\n",
      "[1320/46130] loss: 0.040\n",
      "[1350/46130] loss: 0.055\n",
      "[1380/46130] loss: 0.064\n",
      "[1410/46130] loss: 0.048\n",
      "[1440/46130] loss: 0.075\n",
      "[1470/46130] loss: 0.042\n",
      "[1500/46130] loss: 0.060\n",
      "[1530/46130] loss: 0.075\n",
      "[1560/46130] loss: 0.062\n",
      "[1590/46130] loss: 0.051\n",
      "[1620/46130] loss: 0.045\n",
      "[1650/46130] loss: 0.062\n",
      "[1680/46130] loss: 0.046\n",
      "[1710/46130] loss: 0.033\n",
      "[1740/46130] loss: 0.061\n",
      "[1770/46130] loss: 0.054\n",
      "[1800/46130] loss: 0.052\n",
      "[1830/46130] loss: 0.058\n",
      "[1860/46130] loss: 0.053\n",
      "[1890/46130] loss: 0.049\n",
      "[1920/46130] loss: 0.046\n",
      "[1950/46130] loss: 0.060\n",
      "[1980/46130] loss: 0.068\n",
      "[2010/46130] loss: 0.045\n",
      "[2040/46130] loss: 0.042\n",
      "[2070/46130] loss: 0.046\n",
      "[2100/46130] loss: 0.049\n",
      "[2130/46130] loss: 0.051\n",
      "[2160/46130] loss: 0.049\n",
      "[2190/46130] loss: 0.063\n",
      "[2220/46130] loss: 0.053\n",
      "[2250/46130] loss: 0.054\n",
      "[2280/46130] loss: 0.050\n",
      "[2310/46130] loss: 0.062\n",
      "[2340/46130] loss: 0.041\n",
      "[2370/46130] loss: 0.045\n",
      "[2400/46130] loss: 0.041\n",
      "[2430/46130] loss: 0.045\n",
      "[2460/46130] loss: 0.064\n",
      "[2490/46130] loss: 0.060\n",
      "[2520/46130] loss: 0.070\n",
      "[2550/46130] loss: 0.061\n",
      "[2580/46130] loss: 0.065\n",
      "[2610/46130] loss: 0.047\n",
      "[2640/46130] loss: 0.046\n",
      "[2670/46130] loss: 0.035\n",
      "[2700/46130] loss: 0.049\n",
      "[2730/46130] loss: 0.070\n",
      "[2760/46130] loss: 0.060\n",
      "[2790/46130] loss: 0.053\n",
      "[2820/46130] loss: 0.054\n",
      "[2850/46130] loss: 0.065\n",
      "[2880/46130] loss: 0.063\n",
      "[2910/46130] loss: 0.066\n",
      "[2940/46130] loss: 0.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2970/46130] loss: 0.046\n",
      "[3000/46130] loss: 0.050\n",
      "[3030/46130] loss: 0.066\n",
      "[3060/46130] loss: 0.056\n",
      "[3090/46130] loss: 0.052\n",
      "[3120/46130] loss: 0.059\n",
      "[3150/46130] loss: 0.069\n",
      "[3180/46130] loss: 0.042\n",
      "[3210/46130] loss: 0.064\n",
      "[3240/46130] loss: 0.059\n",
      "[3270/46130] loss: 0.050\n",
      "[3300/46130] loss: 0.062\n",
      "[3330/46130] loss: 0.063\n",
      "[3360/46130] loss: 0.050\n",
      "[3390/46130] loss: 0.037\n",
      "[3420/46130] loss: 0.057\n",
      "[3450/46130] loss: 0.059\n",
      "[3480/46130] loss: 0.081\n",
      "[3510/46130] loss: 0.063\n",
      "[3540/46130] loss: 0.075\n",
      "[3570/46130] loss: 0.077\n",
      "[3600/46130] loss: 0.065\n",
      "[3630/46130] loss: 0.073\n",
      "[3660/46130] loss: 0.039\n",
      "[3690/46130] loss: 0.050\n",
      "[3720/46130] loss: 0.056\n",
      "[3750/46130] loss: 0.047\n",
      "[3780/46130] loss: 0.073\n",
      "[3810/46130] loss: 0.068\n",
      "[3840/46130] loss: 0.049\n",
      "[3870/46130] loss: 0.069\n",
      "[3900/46130] loss: 0.053\n",
      "[3930/46130] loss: 0.051\n",
      "[3960/46130] loss: 0.050\n",
      "[3990/46130] loss: 0.052\n",
      "[4020/46130] loss: 0.065\n",
      "[4050/46130] loss: 0.042\n",
      "[4080/46130] loss: 0.076\n",
      "[4110/46130] loss: 0.065\n",
      "[4140/46130] loss: 0.067\n",
      "[4170/46130] loss: 0.044\n",
      "[4200/46130] loss: 0.053\n",
      "[4230/46130] loss: 0.070\n",
      "[4260/46130] loss: 0.042\n",
      "[4290/46130] loss: 0.051\n",
      "[4320/46130] loss: 0.065\n",
      "[4350/46130] loss: 0.071\n",
      "[4380/46130] loss: 0.049\n",
      "[4410/46130] loss: 0.069\n",
      "[4440/46130] loss: 0.062\n",
      "[4470/46130] loss: 0.051\n",
      "[4500/46130] loss: 0.071\n",
      "[4530/46130] loss: 0.046\n",
      "[4560/46130] loss: 0.056\n",
      "[4590/46130] loss: 0.054\n",
      "[4620/46130] loss: 0.030\n",
      "[4650/46130] loss: 0.087\n",
      "[4680/46130] loss: 0.042\n",
      "[4710/46130] loss: 0.076\n",
      "[4740/46130] loss: 0.055\n",
      "[4770/46130] loss: 0.054\n",
      "[4800/46130] loss: 0.091\n",
      "[4830/46130] loss: 0.066\n",
      "[4860/46130] loss: 0.050\n",
      "[4890/46130] loss: 0.063\n",
      "[4920/46130] loss: 0.048\n",
      "[4950/46130] loss: 0.037\n",
      "[4980/46130] loss: 0.057\n",
      "[5010/46130] loss: 0.055\n",
      "[5040/46130] loss: 0.092\n",
      "[5070/46130] loss: 0.064\n",
      "[5100/46130] loss: 0.062\n",
      "[5130/46130] loss: 0.052\n",
      "[5160/46130] loss: 0.070\n",
      "[5190/46130] loss: 0.043\n",
      "[5220/46130] loss: 0.054\n",
      "[5250/46130] loss: 0.064\n",
      "[5280/46130] loss: 0.037\n",
      "[5310/46130] loss: 0.059\n",
      "[5340/46130] loss: 0.051\n",
      "[5370/46130] loss: 0.065\n",
      "[5400/46130] loss: 0.090\n",
      "[5430/46130] loss: 0.046\n",
      "[5460/46130] loss: 0.060\n",
      "[5490/46130] loss: 0.063\n",
      "[5520/46130] loss: 0.068\n",
      "[5550/46130] loss: 0.049\n",
      "[5580/46130] loss: 0.073\n",
      "[5610/46130] loss: 0.088\n",
      "[5640/46130] loss: 0.053\n",
      "[5670/46130] loss: 0.037\n",
      "[5700/46130] loss: 0.057\n",
      "[5730/46130] loss: 0.071\n",
      "[5760/46130] loss: 0.042\n",
      "[5790/46130] loss: 0.044\n",
      "[5820/46130] loss: 0.058\n",
      "[5850/46130] loss: 0.036\n",
      "[5880/46130] loss: 0.054\n",
      "[5910/46130] loss: 0.042\n",
      "[5940/46130] loss: 0.065\n",
      "[5970/46130] loss: 0.076\n",
      "[6000/46130] loss: 0.069\n",
      "[6030/46130] loss: 0.059\n",
      "[6060/46130] loss: 0.065\n",
      "[6090/46130] loss: 0.043\n",
      "[6120/46130] loss: 0.058\n",
      "[6150/46130] loss: 0.075\n",
      "[6180/46130] loss: 0.060\n",
      "[6210/46130] loss: 0.037\n",
      "[6240/46130] loss: 0.066\n",
      "[6270/46130] loss: 0.053\n",
      "[6300/46130] loss: 0.067\n",
      "[6330/46130] loss: 0.064\n",
      "[6360/46130] loss: 0.042\n",
      "[6390/46130] loss: 0.064\n",
      "[6420/46130] loss: 0.065\n",
      "[6450/46130] loss: 0.041\n",
      "[6480/46130] loss: 0.048\n",
      "[6510/46130] loss: 0.042\n",
      "[6540/46130] loss: 0.071\n",
      "[6570/46130] loss: 0.055\n",
      "[6600/46130] loss: 0.047\n",
      "[6630/46130] loss: 0.068\n",
      "[6660/46130] loss: 0.062\n",
      "[6690/46130] loss: 0.062\n",
      "[6720/46130] loss: 0.053\n",
      "[6750/46130] loss: 0.033\n",
      "[6780/46130] loss: 0.050\n",
      "[6810/46130] loss: 0.080\n",
      "[6840/46130] loss: 0.053\n",
      "[6870/46130] loss: 0.026\n",
      "[6900/46130] loss: 0.046\n",
      "[6930/46130] loss: 0.068\n",
      "[6960/46130] loss: 0.039\n",
      "[6990/46130] loss: 0.042\n",
      "[7020/46130] loss: 0.053\n",
      "[7050/46130] loss: 0.045\n",
      "[7080/46130] loss: 0.073\n",
      "[7110/46130] loss: 0.045\n",
      "[7140/46130] loss: 0.062\n",
      "[7170/46130] loss: 0.051\n",
      "[7200/46130] loss: 0.068\n",
      "[7230/46130] loss: 0.042\n",
      "[7260/46130] loss: 0.049\n",
      "[7290/46130] loss: 0.048\n",
      "[7320/46130] loss: 0.052\n",
      "[7350/46130] loss: 0.052\n",
      "[7380/46130] loss: 0.058\n",
      "[7410/46130] loss: 0.058\n",
      "[7440/46130] loss: 0.079\n",
      "[7470/46130] loss: 0.044\n",
      "[7500/46130] loss: 0.060\n",
      "[7530/46130] loss: 0.042\n",
      "[7560/46130] loss: 0.059\n",
      "[7590/46130] loss: 0.050\n",
      "[7620/46130] loss: 0.050\n",
      "[7650/46130] loss: 0.069\n",
      "[7680/46130] loss: 0.052\n",
      "[7710/46130] loss: 0.091\n",
      "[7740/46130] loss: 0.067\n",
      "[7770/46130] loss: 0.054\n",
      "[7800/46130] loss: 0.054\n",
      "[7830/46130] loss: 0.054\n",
      "[7860/46130] loss: 0.059\n",
      "[7890/46130] loss: 0.038\n",
      "[7920/46130] loss: 0.077\n",
      "[7950/46130] loss: 0.068\n",
      "[7980/46130] loss: 0.063\n",
      "[8010/46130] loss: 0.043\n",
      "[8040/46130] loss: 0.067\n",
      "[8070/46130] loss: 0.051\n",
      "[8100/46130] loss: 0.053\n",
      "[8130/46130] loss: 0.062\n",
      "[8160/46130] loss: 0.057\n",
      "[8190/46130] loss: 0.056\n",
      "[8220/46130] loss: 0.058\n",
      "[8250/46130] loss: 0.052\n",
      "[8280/46130] loss: 0.079\n",
      "[8310/46130] loss: 0.050\n",
      "[8340/46130] loss: 0.051\n",
      "[8370/46130] loss: 0.034\n",
      "[8400/46130] loss: 0.051\n",
      "[8430/46130] loss: 0.082\n",
      "[8460/46130] loss: 0.050\n",
      "[8490/46130] loss: 0.035\n",
      "[8520/46130] loss: 0.043\n",
      "[8550/46130] loss: 0.046\n",
      "[8580/46130] loss: 0.050\n",
      "[8610/46130] loss: 0.058\n",
      "[8640/46130] loss: 0.049\n",
      "[8670/46130] loss: 0.052\n",
      "[8700/46130] loss: 0.061\n",
      "[8730/46130] loss: 0.072\n",
      "[8760/46130] loss: 0.043\n",
      "[8790/46130] loss: 0.061\n",
      "[8820/46130] loss: 0.060\n",
      "[8850/46130] loss: 0.035\n",
      "[8880/46130] loss: 0.043\n",
      "[8910/46130] loss: 0.068\n",
      "[8940/46130] loss: 0.045\n",
      "[8970/46130] loss: 0.049\n",
      "[9000/46130] loss: 0.058\n",
      "[9030/46130] loss: 0.089\n",
      "[9060/46130] loss: 0.047\n",
      "[9090/46130] loss: 0.042\n",
      "[9120/46130] loss: 0.050\n",
      "[9150/46130] loss: 0.054\n",
      "[9180/46130] loss: 0.053\n",
      "[9210/46130] loss: 0.048\n",
      "[9240/46130] loss: 0.046\n",
      "[9270/46130] loss: 0.037\n",
      "[9300/46130] loss: 0.067\n",
      "[9330/46130] loss: 0.050\n",
      "[9360/46130] loss: 0.047\n",
      "[9390/46130] loss: 0.040\n",
      "[9420/46130] loss: 0.042\n",
      "[9450/46130] loss: 0.030\n",
      "[9480/46130] loss: 0.055\n",
      "[9510/46130] loss: 0.047\n",
      "[9540/46130] loss: 0.041\n",
      "[9570/46130] loss: 0.063\n",
      "[9600/46130] loss: 0.057\n",
      "[9630/46130] loss: 0.056\n",
      "[9660/46130] loss: 0.052\n",
      "[9690/46130] loss: 0.069\n",
      "[9720/46130] loss: 0.049\n",
      "[9750/46130] loss: 0.061\n",
      "[9780/46130] loss: 0.046\n",
      "[9810/46130] loss: 0.056\n",
      "[9840/46130] loss: 0.099\n",
      "[9870/46130] loss: 0.056\n",
      "[9900/46130] loss: 0.058\n",
      "[9930/46130] loss: 0.048\n",
      "[9960/46130] loss: 0.042\n",
      "[9990/46130] loss: 0.060\n",
      "[10020/46130] loss: 0.068\n",
      "[10050/46130] loss: 0.051\n",
      "[10080/46130] loss: 0.075\n",
      "[10110/46130] loss: 0.042\n",
      "[10140/46130] loss: 0.040\n",
      "[10170/46130] loss: 0.085\n",
      "[10200/46130] loss: 0.040\n",
      "[10230/46130] loss: 0.038\n",
      "[10260/46130] loss: 0.066\n",
      "[10290/46130] loss: 0.057\n",
      "[10320/46130] loss: 0.050\n",
      "[10350/46130] loss: 0.052\n",
      "[10380/46130] loss: 0.065\n",
      "[10410/46130] loss: 0.061\n",
      "[10440/46130] loss: 0.050\n",
      "[10470/46130] loss: 0.049\n",
      "[10500/46130] loss: 0.041\n",
      "[10530/46130] loss: 0.044\n",
      "[10560/46130] loss: 0.045\n",
      "[10590/46130] loss: 0.031\n",
      "[10620/46130] loss: 0.056\n",
      "[10650/46130] loss: 0.048\n",
      "[10680/46130] loss: 0.069\n",
      "[10710/46130] loss: 0.069\n",
      "[10740/46130] loss: 0.075\n",
      "[10770/46130] loss: 0.039\n",
      "[10800/46130] loss: 0.041\n",
      "[10830/46130] loss: 0.068\n",
      "[10860/46130] loss: 0.038\n",
      "[10890/46130] loss: 0.064\n",
      "[10920/46130] loss: 0.056\n",
      "[10950/46130] loss: 0.030\n",
      "[10980/46130] loss: 0.070\n",
      "[11010/46130] loss: 0.061\n",
      "[11040/46130] loss: 0.042\n",
      "[11070/46130] loss: 0.044\n",
      "[11100/46130] loss: 0.065\n",
      "[11130/46130] loss: 0.039\n",
      "[11160/46130] loss: 0.051\n",
      "[11190/46130] loss: 0.079\n",
      "[11220/46130] loss: 0.049\n",
      "[11250/46130] loss: 0.058\n",
      "[11280/46130] loss: 0.032\n",
      "[11310/46130] loss: 0.063\n",
      "[11340/46130] loss: 0.065\n",
      "[11370/46130] loss: 0.039\n",
      "[11400/46130] loss: 0.051\n",
      "[11430/46130] loss: 0.032\n",
      "[11460/46130] loss: 0.051\n",
      "[11490/46130] loss: 0.053\n",
      "[11520/46130] loss: 0.065\n",
      "[11550/46130] loss: 0.056\n",
      "[11580/46130] loss: 0.046\n",
      "[11610/46130] loss: 0.079\n",
      "[11640/46130] loss: 0.056\n",
      "[11670/46130] loss: 0.063\n",
      "[11700/46130] loss: 0.037\n",
      "[11730/46130] loss: 0.069\n",
      "[11760/46130] loss: 0.042\n",
      "[11790/46130] loss: 0.078\n",
      "[11820/46130] loss: 0.059\n",
      "[11850/46130] loss: 0.066\n",
      "[11880/46130] loss: 0.072\n",
      "[11910/46130] loss: 0.043\n",
      "[11940/46130] loss: 0.030\n",
      "[11970/46130] loss: 0.041\n",
      "[12000/46130] loss: 0.061\n",
      "[12030/46130] loss: 0.072\n",
      "[12060/46130] loss: 0.055\n",
      "[12090/46130] loss: 0.068\n",
      "[12120/46130] loss: 0.063\n",
      "[12150/46130] loss: 0.037\n",
      "[12180/46130] loss: 0.043\n",
      "[12210/46130] loss: 0.064\n",
      "[12240/46130] loss: 0.054\n",
      "[12270/46130] loss: 0.042\n",
      "[12300/46130] loss: 0.070\n",
      "[12330/46130] loss: 0.053\n",
      "[12360/46130] loss: 0.070\n",
      "[12390/46130] loss: 0.077\n",
      "[12420/46130] loss: 0.058\n",
      "[12450/46130] loss: 0.048\n",
      "[12480/46130] loss: 0.057\n",
      "[12510/46130] loss: 0.046\n",
      "[12540/46130] loss: 0.059\n",
      "[12570/46130] loss: 0.044\n",
      "[12600/46130] loss: 0.065\n",
      "[12630/46130] loss: 0.098\n",
      "[12660/46130] loss: 0.049\n",
      "[12690/46130] loss: 0.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12720/46130] loss: 0.090\n",
      "[12750/46130] loss: 0.067\n",
      "[12780/46130] loss: 0.075\n",
      "[12810/46130] loss: 0.092\n",
      "[12840/46130] loss: 0.063\n",
      "[12870/46130] loss: 0.083\n",
      "[12900/46130] loss: 0.057\n",
      "[12930/46130] loss: 0.033\n",
      "[12960/46130] loss: 0.035\n",
      "[12990/46130] loss: 0.054\n",
      "[13020/46130] loss: 0.077\n",
      "[13050/46130] loss: 0.051\n",
      "[13080/46130] loss: 0.064\n",
      "[13110/46130] loss: 0.048\n",
      "[13140/46130] loss: 0.048\n",
      "[13170/46130] loss: 0.061\n",
      "[13200/46130] loss: 0.058\n",
      "[13230/46130] loss: 0.064\n",
      "[13260/46130] loss: 0.054\n",
      "[13290/46130] loss: 0.051\n",
      "[13320/46130] loss: 0.036\n",
      "[13350/46130] loss: 0.044\n",
      "[13380/46130] loss: 0.047\n",
      "[13410/46130] loss: 0.042\n",
      "[13440/46130] loss: 0.067\n",
      "[13470/46130] loss: 0.066\n",
      "[13500/46130] loss: 0.055\n",
      "[13530/46130] loss: 0.037\n",
      "[13560/46130] loss: 0.044\n",
      "[13590/46130] loss: 0.054\n",
      "[13620/46130] loss: 0.047\n",
      "[13650/46130] loss: 0.036\n",
      "[13680/46130] loss: 0.058\n",
      "[13710/46130] loss: 0.046\n",
      "[13740/46130] loss: 0.053\n",
      "[13770/46130] loss: 0.043\n",
      "[13800/46130] loss: 0.044\n",
      "[13830/46130] loss: 0.069\n",
      "[13860/46130] loss: 0.047\n",
      "[13890/46130] loss: 0.055\n",
      "[13920/46130] loss: 0.037\n",
      "[13950/46130] loss: 0.040\n",
      "[13980/46130] loss: 0.066\n",
      "[14010/46130] loss: 0.047\n",
      "[14040/46130] loss: 0.054\n",
      "[14070/46130] loss: 0.053\n",
      "[14100/46130] loss: 0.054\n",
      "[14130/46130] loss: 0.055\n",
      "[14160/46130] loss: 0.043\n",
      "[14190/46130] loss: 0.062\n",
      "[14220/46130] loss: 0.074\n",
      "[14250/46130] loss: 0.040\n",
      "[14280/46130] loss: 0.035\n",
      "[14310/46130] loss: 0.042\n",
      "[14340/46130] loss: 0.035\n",
      "[14370/46130] loss: 0.058\n",
      "[14400/46130] loss: 0.062\n",
      "[14430/46130] loss: 0.072\n",
      "[14460/46130] loss: 0.050\n",
      "[14490/46130] loss: 0.084\n",
      "[14520/46130] loss: 0.039\n",
      "[14550/46130] loss: 0.046\n",
      "[14580/46130] loss: 0.052\n",
      "[14610/46130] loss: 0.046\n",
      "[14640/46130] loss: 0.051\n",
      "[14670/46130] loss: 0.042\n",
      "[14700/46130] loss: 0.038\n",
      "[14730/46130] loss: 0.073\n",
      "[14760/46130] loss: 0.040\n",
      "[14790/46130] loss: 0.054\n",
      "[14820/46130] loss: 0.041\n",
      "[14850/46130] loss: 0.085\n",
      "[14880/46130] loss: 0.046\n",
      "[14910/46130] loss: 0.062\n",
      "[14940/46130] loss: 0.059\n",
      "[14970/46130] loss: 0.053\n",
      "[15000/46130] loss: 0.064\n",
      "[15030/46130] loss: 0.042\n",
      "[15060/46130] loss: 0.053\n",
      "[15090/46130] loss: 0.049\n",
      "[15120/46130] loss: 0.049\n",
      "[15150/46130] loss: 0.049\n",
      "[15180/46130] loss: 0.057\n",
      "[15210/46130] loss: 0.044\n",
      "[15240/46130] loss: 0.051\n",
      "[15270/46130] loss: 0.074\n",
      "[15300/46130] loss: 0.048\n",
      "[15330/46130] loss: 0.048\n",
      "[15360/46130] loss: 0.048\n",
      "[15390/46130] loss: 0.053\n",
      "[15420/46130] loss: 0.070\n",
      "[15450/46130] loss: 0.047\n",
      "[15480/46130] loss: 0.042\n",
      "[15510/46130] loss: 0.054\n",
      "[15540/46130] loss: 0.092\n",
      "[15570/46130] loss: 0.047\n",
      "[15600/46130] loss: 0.047\n",
      "[15630/46130] loss: 0.059\n",
      "[15660/46130] loss: 0.060\n",
      "[15690/46130] loss: 0.089\n",
      "[15720/46130] loss: 0.043\n",
      "[15750/46130] loss: 0.056\n",
      "[15780/46130] loss: 0.040\n",
      "[15810/46130] loss: 0.047\n",
      "[15840/46130] loss: 0.055\n",
      "[15870/46130] loss: 0.041\n",
      "[15900/46130] loss: 0.051\n",
      "[15930/46130] loss: 0.042\n",
      "[15960/46130] loss: 0.050\n",
      "[15990/46130] loss: 0.049\n",
      "[16020/46130] loss: 0.054\n",
      "[16050/46130] loss: 0.049\n",
      "[16080/46130] loss: 0.059\n",
      "[16110/46130] loss: 0.082\n",
      "[16140/46130] loss: 0.064\n",
      "[16170/46130] loss: 0.060\n",
      "[16200/46130] loss: 0.075\n",
      "[16230/46130] loss: 0.056\n",
      "[16260/46130] loss: 0.068\n",
      "[16290/46130] loss: 0.048\n",
      "[16320/46130] loss: 0.042\n",
      "[16350/46130] loss: 0.055\n",
      "[16380/46130] loss: 0.065\n",
      "[16410/46130] loss: 0.068\n",
      "[16440/46130] loss: 0.071\n",
      "[16470/46130] loss: 0.043\n",
      "[16500/46130] loss: 0.047\n",
      "[16530/46130] loss: 0.064\n",
      "[16560/46130] loss: 0.063\n",
      "[16590/46130] loss: 0.041\n",
      "[16620/46130] loss: 0.065\n",
      "[16650/46130] loss: 0.048\n",
      "[16680/46130] loss: 0.044\n",
      "[16710/46130] loss: 0.060\n",
      "[16740/46130] loss: 0.044\n",
      "[16770/46130] loss: 0.080\n",
      "[16800/46130] loss: 0.030\n",
      "[16830/46130] loss: 0.062\n",
      "[16860/46130] loss: 0.072\n",
      "[16890/46130] loss: 0.046\n",
      "[16920/46130] loss: 0.041\n",
      "[16950/46130] loss: 0.057\n",
      "[16980/46130] loss: 0.032\n",
      "[17010/46130] loss: 0.040\n",
      "[17040/46130] loss: 0.036\n",
      "[17070/46130] loss: 0.038\n",
      "[17100/46130] loss: 0.042\n",
      "[17130/46130] loss: 0.045\n",
      "[17160/46130] loss: 0.046\n",
      "[17190/46130] loss: 0.079\n",
      "[17220/46130] loss: 0.050\n",
      "[17250/46130] loss: 0.059\n",
      "[17280/46130] loss: 0.058\n",
      "[17310/46130] loss: 0.073\n",
      "[17340/46130] loss: 0.049\n",
      "[17370/46130] loss: 0.081\n",
      "[17400/46130] loss: 0.056\n",
      "[17430/46130] loss: 0.051\n",
      "[17460/46130] loss: 0.054\n",
      "[17490/46130] loss: 0.057\n",
      "[17520/46130] loss: 0.055\n",
      "[17550/46130] loss: 0.057\n",
      "[17580/46130] loss: 0.041\n",
      "[17610/46130] loss: 0.070\n",
      "[17640/46130] loss: 0.067\n",
      "[17670/46130] loss: 0.090\n",
      "[17700/46130] loss: 0.077\n",
      "[17730/46130] loss: 0.050\n",
      "[17760/46130] loss: 0.053\n",
      "[17790/46130] loss: 0.051\n",
      "[17820/46130] loss: 0.043\n",
      "[17850/46130] loss: 0.052\n",
      "[17880/46130] loss: 0.052\n",
      "[17910/46130] loss: 0.034\n",
      "[17940/46130] loss: 0.038\n",
      "[17970/46130] loss: 0.087\n",
      "[18000/46130] loss: 0.050\n",
      "[18030/46130] loss: 0.077\n",
      "[18060/46130] loss: 0.065\n",
      "[18090/46130] loss: 0.067\n",
      "[18120/46130] loss: 0.054\n",
      "[18150/46130] loss: 0.069\n",
      "[18180/46130] loss: 0.053\n",
      "[18210/46130] loss: 0.046\n",
      "[18240/46130] loss: 0.066\n",
      "[18270/46130] loss: 0.041\n",
      "[18300/46130] loss: 0.066\n",
      "[18330/46130] loss: 0.053\n",
      "[18360/46130] loss: 0.051\n",
      "[18390/46130] loss: 0.035\n",
      "[18420/46130] loss: 0.030\n",
      "[18450/46130] loss: 0.041\n",
      "[18480/46130] loss: 0.050\n",
      "[18510/46130] loss: 0.044\n",
      "[18540/46130] loss: 0.073\n",
      "[18570/46130] loss: 0.046\n",
      "[18600/46130] loss: 0.038\n",
      "[18630/46130] loss: 0.056\n",
      "[18660/46130] loss: 0.054\n",
      "[18690/46130] loss: 0.043\n",
      "[18720/46130] loss: 0.037\n",
      "[18750/46130] loss: 0.084\n",
      "[18780/46130] loss: 0.089\n",
      "[18810/46130] loss: 0.046\n",
      "[18840/46130] loss: 0.060\n",
      "[18870/46130] loss: 0.061\n",
      "[18900/46130] loss: 0.060\n",
      "[18930/46130] loss: 0.057\n",
      "[18960/46130] loss: 0.064\n",
      "[18990/46130] loss: 0.038\n",
      "[19020/46130] loss: 0.069\n",
      "[19050/46130] loss: 0.069\n",
      "[19080/46130] loss: 0.054\n",
      "[19110/46130] loss: 0.055\n",
      "[19140/46130] loss: 0.072\n",
      "[19170/46130] loss: 0.057\n",
      "[19200/46130] loss: 0.052\n",
      "[19230/46130] loss: 0.079\n",
      "[19260/46130] loss: 0.051\n",
      "[19290/46130] loss: 0.053\n",
      "[19320/46130] loss: 0.045\n",
      "[19350/46130] loss: 0.054\n",
      "[19380/46130] loss: 0.051\n",
      "[19410/46130] loss: 0.059\n",
      "[19440/46130] loss: 0.039\n",
      "[19470/46130] loss: 0.051\n",
      "[19500/46130] loss: 0.053\n",
      "[19530/46130] loss: 0.038\n",
      "[19560/46130] loss: 0.053\n",
      "[19590/46130] loss: 0.054\n",
      "[19620/46130] loss: 0.051\n",
      "[19650/46130] loss: 0.049\n",
      "[19680/46130] loss: 0.039\n",
      "[19710/46130] loss: 0.049\n",
      "[19740/46130] loss: 0.076\n",
      "[19770/46130] loss: 0.041\n",
      "[19800/46130] loss: 0.050\n",
      "[19830/46130] loss: 0.059\n",
      "[19860/46130] loss: 0.056\n",
      "[19890/46130] loss: 0.056\n",
      "[19920/46130] loss: 0.063\n",
      "[19950/46130] loss: 0.065\n",
      "[19980/46130] loss: 0.059\n",
      "[20010/46130] loss: 0.061\n",
      "[20040/46130] loss: 0.043\n",
      "[20070/46130] loss: 0.060\n",
      "[20100/46130] loss: 0.044\n",
      "[20130/46130] loss: 0.066\n",
      "[20160/46130] loss: 0.066\n",
      "[20190/46130] loss: 0.058\n",
      "[20220/46130] loss: 0.048\n",
      "[20250/46130] loss: 0.067\n",
      "[20280/46130] loss: 0.066\n",
      "[20310/46130] loss: 0.042\n",
      "[20340/46130] loss: 0.048\n",
      "[20370/46130] loss: 0.035\n",
      "[20400/46130] loss: 0.060\n",
      "[20430/46130] loss: 0.057\n",
      "[20460/46130] loss: 0.070\n",
      "[20490/46130] loss: 0.040\n",
      "[20520/46130] loss: 0.056\n",
      "[20550/46130] loss: 0.061\n",
      "[20580/46130] loss: 0.057\n",
      "[20610/46130] loss: 0.045\n",
      "[20640/46130] loss: 0.033\n",
      "[20670/46130] loss: 0.039\n",
      "[20700/46130] loss: 0.063\n",
      "[20730/46130] loss: 0.048\n",
      "[20760/46130] loss: 0.050\n",
      "[20790/46130] loss: 0.040\n",
      "[20820/46130] loss: 0.058\n",
      "[20850/46130] loss: 0.043\n",
      "[20880/46130] loss: 0.056\n",
      "[20910/46130] loss: 0.055\n",
      "[20940/46130] loss: 0.037\n",
      "[20970/46130] loss: 0.043\n",
      "[21000/46130] loss: 0.057\n",
      "[21030/46130] loss: 0.058\n",
      "[21060/46130] loss: 0.048\n",
      "[21090/46130] loss: 0.058\n",
      "[21120/46130] loss: 0.055\n",
      "[21150/46130] loss: 0.061\n",
      "[21180/46130] loss: 0.045\n",
      "[21210/46130] loss: 0.060\n",
      "[21240/46130] loss: 0.066\n",
      "[21270/46130] loss: 0.026\n",
      "[21300/46130] loss: 0.055\n",
      "[21330/46130] loss: 0.048\n",
      "[21360/46130] loss: 0.050\n",
      "[21390/46130] loss: 0.073\n",
      "[21420/46130] loss: 0.039\n",
      "[21450/46130] loss: 0.029\n",
      "[21480/46130] loss: 0.048\n",
      "[21510/46130] loss: 0.060\n",
      "[21540/46130] loss: 0.048\n",
      "[21570/46130] loss: 0.046\n",
      "[21600/46130] loss: 0.046\n",
      "[21630/46130] loss: 0.046\n",
      "[21660/46130] loss: 0.043\n",
      "[21690/46130] loss: 0.049\n",
      "[21720/46130] loss: 0.046\n",
      "[21750/46130] loss: 0.030\n",
      "[21780/46130] loss: 0.036\n",
      "[21810/46130] loss: 0.049\n",
      "[21840/46130] loss: 0.058\n",
      "[21870/46130] loss: 0.052\n",
      "[21900/46130] loss: 0.043\n",
      "[21930/46130] loss: 0.038\n",
      "[21960/46130] loss: 0.046\n",
      "[21990/46130] loss: 0.059\n",
      "[22020/46130] loss: 0.060\n",
      "[22050/46130] loss: 0.065\n",
      "[22080/46130] loss: 0.050\n",
      "[22110/46130] loss: 0.062\n",
      "[22140/46130] loss: 0.043\n",
      "[22170/46130] loss: 0.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22200/46130] loss: 0.048\n",
      "[22230/46130] loss: 0.055\n",
      "[22260/46130] loss: 0.051\n",
      "[22290/46130] loss: 0.064\n",
      "[22320/46130] loss: 0.039\n",
      "[22350/46130] loss: 0.033\n",
      "[22380/46130] loss: 0.072\n",
      "[22410/46130] loss: 0.044\n",
      "[22440/46130] loss: 0.059\n",
      "[22470/46130] loss: 0.046\n",
      "[22500/46130] loss: 0.045\n",
      "[22530/46130] loss: 0.039\n",
      "[22560/46130] loss: 0.075\n",
      "[22590/46130] loss: 0.064\n",
      "[22620/46130] loss: 0.059\n",
      "[22650/46130] loss: 0.050\n",
      "[22680/46130] loss: 0.070\n",
      "[22710/46130] loss: 0.042\n",
      "[22740/46130] loss: 0.054\n",
      "[22770/46130] loss: 0.055\n",
      "[22800/46130] loss: 0.059\n",
      "[22830/46130] loss: 0.074\n",
      "[22860/46130] loss: 0.043\n",
      "[22890/46130] loss: 0.055\n",
      "[22920/46130] loss: 0.037\n",
      "[22950/46130] loss: 0.058\n",
      "[22980/46130] loss: 0.050\n",
      "[23010/46130] loss: 0.042\n",
      "[23040/46130] loss: 0.055\n",
      "[23070/46130] loss: 0.078\n",
      "[23100/46130] loss: 0.047\n",
      "[23130/46130] loss: 0.049\n",
      "[23160/46130] loss: 0.042\n",
      "[23190/46130] loss: 0.067\n",
      "[23220/46130] loss: 0.061\n",
      "[23250/46130] loss: 0.049\n",
      "[23280/46130] loss: 0.062\n",
      "[23310/46130] loss: 0.063\n",
      "[23340/46130] loss: 0.052\n",
      "[23370/46130] loss: 0.042\n",
      "[23400/46130] loss: 0.045\n",
      "[23430/46130] loss: 0.055\n",
      "[23460/46130] loss: 0.055\n",
      "[23490/46130] loss: 0.076\n",
      "[23520/46130] loss: 0.082\n",
      "[23550/46130] loss: 0.040\n",
      "[23580/46130] loss: 0.076\n",
      "[23610/46130] loss: 0.052\n",
      "[23640/46130] loss: 0.046\n",
      "[23670/46130] loss: 0.078\n",
      "[23700/46130] loss: 0.036\n",
      "[23730/46130] loss: 0.056\n",
      "[23760/46130] loss: 0.057\n",
      "[23790/46130] loss: 0.069\n",
      "[23820/46130] loss: 0.031\n",
      "[23850/46130] loss: 0.046\n",
      "[23880/46130] loss: 0.066\n",
      "[23910/46130] loss: 0.054\n",
      "[23940/46130] loss: 0.049\n",
      "[23970/46130] loss: 0.053\n",
      "[24000/46130] loss: 0.054\n",
      "[24030/46130] loss: 0.065\n",
      "[24060/46130] loss: 0.059\n",
      "[24090/46130] loss: 0.049\n",
      "[24120/46130] loss: 0.033\n",
      "[24150/46130] loss: 0.078\n",
      "[24180/46130] loss: 0.044\n",
      "[24210/46130] loss: 0.048\n",
      "[24240/46130] loss: 0.072\n",
      "[24270/46130] loss: 0.073\n",
      "[24300/46130] loss: 0.044\n",
      "[24330/46130] loss: 0.049\n",
      "[24360/46130] loss: 0.034\n",
      "[24390/46130] loss: 0.028\n",
      "[24420/46130] loss: 0.059\n",
      "[24450/46130] loss: 0.049\n",
      "[24480/46130] loss: 0.064\n",
      "[24510/46130] loss: 0.032\n",
      "[24540/46130] loss: 0.029\n",
      "[24570/46130] loss: 0.052\n",
      "[24600/46130] loss: 0.050\n",
      "[24630/46130] loss: 0.028\n",
      "[24660/46130] loss: 0.062\n",
      "[24690/46130] loss: 0.039\n",
      "[24720/46130] loss: 0.061\n",
      "[24750/46130] loss: 0.049\n",
      "[24780/46130] loss: 0.057\n",
      "[24810/46130] loss: 0.062\n",
      "[24840/46130] loss: 0.058\n",
      "[24870/46130] loss: 0.039\n",
      "[24900/46130] loss: 0.042\n",
      "[24930/46130] loss: 0.040\n",
      "[24960/46130] loss: 0.044\n",
      "[24990/46130] loss: 0.057\n",
      "[25020/46130] loss: 0.045\n",
      "[25050/46130] loss: 0.053\n",
      "[25080/46130] loss: 0.053\n",
      "[25110/46130] loss: 0.055\n",
      "[25140/46130] loss: 0.056\n",
      "[25170/46130] loss: 0.051\n",
      "[25200/46130] loss: 0.057\n",
      "[25230/46130] loss: 0.037\n",
      "[25260/46130] loss: 0.058\n",
      "[25290/46130] loss: 0.044\n",
      "[25320/46130] loss: 0.043\n",
      "[25350/46130] loss: 0.063\n",
      "[25380/46130] loss: 0.051\n",
      "[25410/46130] loss: 0.046\n",
      "[25440/46130] loss: 0.062\n",
      "[25470/46130] loss: 0.057\n",
      "[25500/46130] loss: 0.056\n",
      "[25530/46130] loss: 0.062\n",
      "[25560/46130] loss: 0.056\n",
      "[25590/46130] loss: 0.063\n",
      "[25620/46130] loss: 0.068\n",
      "[25650/46130] loss: 0.067\n",
      "[25680/46130] loss: 0.057\n",
      "[25710/46130] loss: 0.055\n",
      "[25740/46130] loss: 0.034\n",
      "[25770/46130] loss: 0.072\n",
      "[25800/46130] loss: 0.075\n",
      "[25830/46130] loss: 0.051\n",
      "[25860/46130] loss: 0.044\n",
      "[25890/46130] loss: 0.080\n",
      "[25920/46130] loss: 0.032\n",
      "[25950/46130] loss: 0.059\n",
      "[25980/46130] loss: 0.070\n",
      "[26010/46130] loss: 0.052\n",
      "[26040/46130] loss: 0.047\n",
      "[26070/46130] loss: 0.058\n",
      "[26100/46130] loss: 0.061\n",
      "[26130/46130] loss: 0.061\n",
      "[26160/46130] loss: 0.058\n",
      "[26190/46130] loss: 0.059\n",
      "[26220/46130] loss: 0.069\n",
      "[26250/46130] loss: 0.043\n",
      "[26280/46130] loss: 0.053\n",
      "[26310/46130] loss: 0.045\n",
      "[26340/46130] loss: 0.073\n",
      "[26370/46130] loss: 0.040\n",
      "[26400/46130] loss: 0.058\n",
      "[26430/46130] loss: 0.030\n",
      "[26460/46130] loss: 0.042\n",
      "[26490/46130] loss: 0.043\n",
      "[26520/46130] loss: 0.053\n",
      "[26550/46130] loss: 0.063\n",
      "[26580/46130] loss: 0.070\n",
      "[26610/46130] loss: 0.046\n",
      "[26640/46130] loss: 0.062\n",
      "[26670/46130] loss: 0.047\n",
      "[26700/46130] loss: 0.064\n",
      "[26730/46130] loss: 0.057\n",
      "[26760/46130] loss: 0.048\n",
      "[26790/46130] loss: 0.050\n",
      "[26820/46130] loss: 0.050\n",
      "[26850/46130] loss: 0.045\n",
      "[26880/46130] loss: 0.054\n",
      "[26910/46130] loss: 0.059\n",
      "[26940/46130] loss: 0.054\n",
      "[26970/46130] loss: 0.060\n",
      "[27000/46130] loss: 0.052\n",
      "[27030/46130] loss: 0.047\n",
      "[27060/46130] loss: 0.042\n",
      "[27090/46130] loss: 0.060\n",
      "[27120/46130] loss: 0.047\n",
      "[27150/46130] loss: 0.039\n",
      "[27180/46130] loss: 0.062\n",
      "[27210/46130] loss: 0.047\n",
      "[27240/46130] loss: 0.059\n",
      "[27270/46130] loss: 0.041\n",
      "[27300/46130] loss: 0.054\n",
      "[27330/46130] loss: 0.052\n",
      "[27360/46130] loss: 0.038\n",
      "[27390/46130] loss: 0.058\n",
      "[27420/46130] loss: 0.062\n",
      "[27450/46130] loss: 0.048\n",
      "[27480/46130] loss: 0.070\n",
      "[27510/46130] loss: 0.060\n",
      "[27540/46130] loss: 0.059\n",
      "[27570/46130] loss: 0.052\n",
      "[27600/46130] loss: 0.052\n",
      "[27630/46130] loss: 0.059\n",
      "[27660/46130] loss: 0.078\n",
      "[27690/46130] loss: 0.042\n",
      "[27720/46130] loss: 0.077\n",
      "[27750/46130] loss: 0.060\n",
      "[27780/46130] loss: 0.060\n",
      "[27810/46130] loss: 0.062\n",
      "[27840/46130] loss: 0.070\n",
      "[27870/46130] loss: 0.045\n",
      "[27900/46130] loss: 0.066\n",
      "[27930/46130] loss: 0.061\n",
      "[27960/46130] loss: 0.078\n",
      "[27990/46130] loss: 0.065\n",
      "[28020/46130] loss: 0.051\n",
      "[28050/46130] loss: 0.074\n",
      "[28080/46130] loss: 0.038\n",
      "[28110/46130] loss: 0.068\n",
      "[28140/46130] loss: 0.047\n",
      "[28170/46130] loss: 0.072\n",
      "[28200/46130] loss: 0.047\n",
      "[28230/46130] loss: 0.045\n",
      "[28260/46130] loss: 0.073\n",
      "[28290/46130] loss: 0.053\n",
      "[28320/46130] loss: 0.046\n",
      "[28350/46130] loss: 0.057\n",
      "[28380/46130] loss: 0.065\n",
      "[28410/46130] loss: 0.055\n",
      "[28440/46130] loss: 0.054\n",
      "[28470/46130] loss: 0.030\n",
      "[28500/46130] loss: 0.055\n",
      "[28530/46130] loss: 0.038\n",
      "[28560/46130] loss: 0.091\n",
      "[28590/46130] loss: 0.046\n",
      "[28620/46130] loss: 0.050\n",
      "[28650/46130] loss: 0.057\n",
      "[28680/46130] loss: 0.072\n",
      "[28710/46130] loss: 0.039\n",
      "[28740/46130] loss: 0.046\n",
      "[28770/46130] loss: 0.035\n",
      "[28800/46130] loss: 0.064\n",
      "[28830/46130] loss: 0.042\n",
      "[28860/46130] loss: 0.080\n",
      "[28890/46130] loss: 0.045\n",
      "[28920/46130] loss: 0.064\n",
      "[28950/46130] loss: 0.043\n",
      "[28980/46130] loss: 0.040\n",
      "[29010/46130] loss: 0.047\n",
      "[29040/46130] loss: 0.064\n",
      "[29070/46130] loss: 0.047\n",
      "[29100/46130] loss: 0.087\n",
      "[29130/46130] loss: 0.064\n",
      "[29160/46130] loss: 0.070\n",
      "[29190/46130] loss: 0.047\n",
      "[29220/46130] loss: 0.082\n",
      "[29250/46130] loss: 0.030\n",
      "[29280/46130] loss: 0.082\n",
      "[29310/46130] loss: 0.046\n",
      "[29340/46130] loss: 0.072\n",
      "[29370/46130] loss: 0.057\n",
      "[29400/46130] loss: 0.043\n",
      "[29430/46130] loss: 0.043\n",
      "[29460/46130] loss: 0.049\n",
      "[29490/46130] loss: 0.053\n",
      "[29520/46130] loss: 0.050\n",
      "[29550/46130] loss: 0.051\n",
      "[29580/46130] loss: 0.040\n",
      "[29610/46130] loss: 0.048\n",
      "[29640/46130] loss: 0.047\n",
      "[29670/46130] loss: 0.036\n",
      "[29700/46130] loss: 0.034\n",
      "[29730/46130] loss: 0.074\n",
      "[29760/46130] loss: 0.071\n",
      "[29790/46130] loss: 0.052\n",
      "[29820/46130] loss: 0.077\n",
      "[29850/46130] loss: 0.044\n",
      "[29880/46130] loss: 0.038\n",
      "[29910/46130] loss: 0.073\n",
      "[29940/46130] loss: 0.063\n",
      "[29970/46130] loss: 0.048\n",
      "[30000/46130] loss: 0.051\n",
      "[30030/46130] loss: 0.073\n",
      "[30060/46130] loss: 0.095\n",
      "[30090/46130] loss: 0.043\n",
      "[30120/46130] loss: 0.049\n",
      "[30150/46130] loss: 0.043\n",
      "[30180/46130] loss: 0.053\n",
      "[30210/46130] loss: 0.080\n",
      "[30240/46130] loss: 0.057\n",
      "[30270/46130] loss: 0.038\n",
      "[30300/46130] loss: 0.042\n",
      "[30330/46130] loss: 0.034\n",
      "[30360/46130] loss: 0.040\n",
      "[30390/46130] loss: 0.058\n",
      "[30420/46130] loss: 0.052\n",
      "[30450/46130] loss: 0.055\n",
      "[30480/46130] loss: 0.046\n",
      "[30510/46130] loss: 0.066\n",
      "[30540/46130] loss: 0.052\n",
      "[30570/46130] loss: 0.051\n",
      "[30600/46130] loss: 0.046\n",
      "[30630/46130] loss: 0.083\n",
      "[30660/46130] loss: 0.066\n",
      "[30690/46130] loss: 0.069\n",
      "[30720/46130] loss: 0.052\n",
      "[30750/46130] loss: 0.047\n",
      "[30780/46130] loss: 0.049\n",
      "[30810/46130] loss: 0.034\n",
      "[30840/46130] loss: 0.059\n",
      "[30870/46130] loss: 0.044\n",
      "[30900/46130] loss: 0.048\n",
      "[30930/46130] loss: 0.072\n",
      "[30960/46130] loss: 0.067\n",
      "[30990/46130] loss: 0.048\n",
      "[31020/46130] loss: 0.051\n",
      "[31050/46130] loss: 0.048\n",
      "[31080/46130] loss: 0.050\n",
      "[31110/46130] loss: 0.047\n",
      "[31140/46130] loss: 0.041\n",
      "[31170/46130] loss: 0.048\n",
      "[31200/46130] loss: 0.031\n",
      "[31230/46130] loss: 0.075\n",
      "[31260/46130] loss: 0.059\n",
      "[31290/46130] loss: 0.045\n",
      "[31320/46130] loss: 0.069\n",
      "[31350/46130] loss: 0.034\n",
      "[31380/46130] loss: 0.040\n",
      "[31410/46130] loss: 0.039\n",
      "[31440/46130] loss: 0.042\n",
      "[31470/46130] loss: 0.039\n",
      "[31500/46130] loss: 0.046\n",
      "[31530/46130] loss: 0.043\n",
      "[31560/46130] loss: 0.057\n",
      "[31590/46130] loss: 0.038\n",
      "[31620/46130] loss: 0.036\n",
      "[31650/46130] loss: 0.055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31680/46130] loss: 0.059\n",
      "[31710/46130] loss: 0.066\n",
      "[31740/46130] loss: 0.071\n",
      "[31770/46130] loss: 0.037\n",
      "[31800/46130] loss: 0.053\n",
      "[31830/46130] loss: 0.055\n",
      "[31860/46130] loss: 0.063\n",
      "[31890/46130] loss: 0.047\n",
      "[31920/46130] loss: 0.055\n",
      "[31950/46130] loss: 0.041\n",
      "[31980/46130] loss: 0.079\n",
      "[32010/46130] loss: 0.038\n",
      "[32040/46130] loss: 0.071\n",
      "[32070/46130] loss: 0.040\n",
      "[32100/46130] loss: 0.037\n",
      "[32130/46130] loss: 0.044\n",
      "[32160/46130] loss: 0.047\n",
      "[32190/46130] loss: 0.063\n",
      "[32220/46130] loss: 0.075\n",
      "[32250/46130] loss: 0.058\n",
      "[32280/46130] loss: 0.073\n",
      "[32310/46130] loss: 0.046\n",
      "[32340/46130] loss: 0.041\n",
      "[32370/46130] loss: 0.056\n",
      "[32400/46130] loss: 0.062\n",
      "[32430/46130] loss: 0.040\n",
      "[32460/46130] loss: 0.056\n",
      "[32490/46130] loss: 0.070\n",
      "[32520/46130] loss: 0.083\n",
      "[32550/46130] loss: 0.081\n",
      "[32580/46130] loss: 0.031\n",
      "[32610/46130] loss: 0.066\n",
      "[32640/46130] loss: 0.050\n",
      "[32670/46130] loss: 0.044\n",
      "[32700/46130] loss: 0.046\n",
      "[32730/46130] loss: 0.037\n",
      "[32760/46130] loss: 0.063\n",
      "[32790/46130] loss: 0.072\n",
      "[32820/46130] loss: 0.072\n",
      "[32850/46130] loss: 0.046\n",
      "[32880/46130] loss: 0.033\n",
      "[32910/46130] loss: 0.071\n",
      "[32940/46130] loss: 0.054\n",
      "[32970/46130] loss: 0.050\n",
      "[33000/46130] loss: 0.055\n",
      "[33030/46130] loss: 0.068\n",
      "[33060/46130] loss: 0.070\n",
      "[33090/46130] loss: 0.040\n",
      "[33120/46130] loss: 0.062\n",
      "[33150/46130] loss: 0.079\n",
      "[33180/46130] loss: 0.048\n",
      "[33210/46130] loss: 0.056\n",
      "[33240/46130] loss: 0.038\n",
      "[33270/46130] loss: 0.046\n",
      "[33300/46130] loss: 0.046\n",
      "[33330/46130] loss: 0.038\n",
      "[33360/46130] loss: 0.050\n",
      "[33390/46130] loss: 0.063\n",
      "[33420/46130] loss: 0.063\n",
      "[33450/46130] loss: 0.058\n",
      "[33480/46130] loss: 0.055\n",
      "[33510/46130] loss: 0.057\n",
      "[33540/46130] loss: 0.052\n",
      "[33570/46130] loss: 0.052\n",
      "[33600/46130] loss: 0.057\n",
      "[33630/46130] loss: 0.077\n",
      "[33660/46130] loss: 0.062\n",
      "[33690/46130] loss: 0.055\n",
      "[33720/46130] loss: 0.046\n",
      "[33750/46130] loss: 0.055\n",
      "[33780/46130] loss: 0.058\n",
      "[33810/46130] loss: 0.075\n",
      "[33840/46130] loss: 0.052\n",
      "[33870/46130] loss: 0.041\n",
      "[33900/46130] loss: 0.064\n",
      "[33930/46130] loss: 0.039\n",
      "[33960/46130] loss: 0.044\n",
      "[33990/46130] loss: 0.055\n",
      "[34020/46130] loss: 0.070\n",
      "[34050/46130] loss: 0.042\n",
      "[34080/46130] loss: 0.063\n",
      "[34110/46130] loss: 0.027\n",
      "[34140/46130] loss: 0.041\n",
      "[34170/46130] loss: 0.061\n",
      "[34200/46130] loss: 0.045\n",
      "[34230/46130] loss: 0.055\n",
      "[34260/46130] loss: 0.072\n",
      "[34290/46130] loss: 0.057\n",
      "[34320/46130] loss: 0.066\n",
      "[34350/46130] loss: 0.032\n",
      "[34380/46130] loss: 0.041\n",
      "[34410/46130] loss: 0.058\n",
      "[34440/46130] loss: 0.095\n",
      "[34470/46130] loss: 0.060\n",
      "[34500/46130] loss: 0.039\n",
      "[34530/46130] loss: 0.053\n",
      "[34560/46130] loss: 0.053\n",
      "[34590/46130] loss: 0.055\n",
      "[34620/46130] loss: 0.066\n",
      "[34650/46130] loss: 0.027\n",
      "[34680/46130] loss: 0.038\n",
      "[34710/46130] loss: 0.063\n",
      "[34740/46130] loss: 0.044\n",
      "[34770/46130] loss: 0.068\n",
      "[34800/46130] loss: 0.027\n",
      "[34830/46130] loss: 0.049\n",
      "[34860/46130] loss: 0.044\n",
      "[34890/46130] loss: 0.051\n",
      "[34920/46130] loss: 0.049\n",
      "[34950/46130] loss: 0.051\n",
      "[34980/46130] loss: 0.057\n",
      "[35010/46130] loss: 0.064\n",
      "[35040/46130] loss: 0.046\n",
      "[35070/46130] loss: 0.031\n",
      "[35100/46130] loss: 0.101\n",
      "[35130/46130] loss: 0.048\n",
      "[35160/46130] loss: 0.043\n",
      "[35190/46130] loss: 0.083\n",
      "[35220/46130] loss: 0.066\n",
      "[35250/46130] loss: 0.037\n",
      "[35280/46130] loss: 0.064\n",
      "[35310/46130] loss: 0.083\n",
      "[35340/46130] loss: 0.069\n",
      "[35370/46130] loss: 0.056\n",
      "[35400/46130] loss: 0.049\n",
      "[35430/46130] loss: 0.072\n",
      "[35460/46130] loss: 0.052\n",
      "[35490/46130] loss: 0.055\n",
      "[35520/46130] loss: 0.054\n",
      "[35550/46130] loss: 0.070\n",
      "[35580/46130] loss: 0.048\n",
      "[35610/46130] loss: 0.079\n",
      "[35640/46130] loss: 0.058\n",
      "[35670/46130] loss: 0.040\n",
      "[35700/46130] loss: 0.049\n",
      "[35730/46130] loss: 0.071\n",
      "[35760/46130] loss: 0.049\n",
      "[35790/46130] loss: 0.056\n",
      "[35820/46130] loss: 0.036\n",
      "[35850/46130] loss: 0.042\n",
      "[35880/46130] loss: 0.029\n",
      "[35910/46130] loss: 0.043\n",
      "[35940/46130] loss: 0.036\n",
      "[35970/46130] loss: 0.063\n",
      "[36000/46130] loss: 0.075\n",
      "[36030/46130] loss: 0.043\n",
      "[36060/46130] loss: 0.044\n",
      "[36090/46130] loss: 0.055\n",
      "[36120/46130] loss: 0.054\n",
      "[36150/46130] loss: 0.064\n",
      "[36180/46130] loss: 0.060\n",
      "[36210/46130] loss: 0.053\n",
      "[36240/46130] loss: 0.039\n",
      "[36270/46130] loss: 0.058\n",
      "[36300/46130] loss: 0.057\n",
      "[36330/46130] loss: 0.046\n",
      "[36360/46130] loss: 0.040\n",
      "[36390/46130] loss: 0.039\n",
      "[36420/46130] loss: 0.073\n",
      "[36450/46130] loss: 0.060\n",
      "[36480/46130] loss: 0.058\n",
      "[36510/46130] loss: 0.061\n",
      "[36540/46130] loss: 0.083\n",
      "[36570/46130] loss: 0.060\n",
      "[36600/46130] loss: 0.071\n",
      "[36630/46130] loss: 0.058\n",
      "[36660/46130] loss: 0.049\n",
      "[36690/46130] loss: 0.053\n",
      "[36720/46130] loss: 0.049\n",
      "[36750/46130] loss: 0.056\n",
      "[36780/46130] loss: 0.055\n",
      "[36810/46130] loss: 0.036\n",
      "[36840/46130] loss: 0.057\n",
      "[36870/46130] loss: 0.045\n",
      "[36900/46130] loss: 0.057\n",
      "[36930/46130] loss: 0.065\n",
      "[36960/46130] loss: 0.040\n",
      "[36990/46130] loss: 0.061\n",
      "[37020/46130] loss: 0.039\n",
      "[37050/46130] loss: 0.048\n",
      "[37080/46130] loss: 0.068\n",
      "[37110/46130] loss: 0.054\n",
      "[37140/46130] loss: 0.046\n",
      "[37170/46130] loss: 0.059\n",
      "[37200/46130] loss: 0.038\n",
      "[37230/46130] loss: 0.069\n",
      "[37260/46130] loss: 0.059\n",
      "[37290/46130] loss: 0.051\n",
      "[37320/46130] loss: 0.048\n",
      "[37350/46130] loss: 0.046\n",
      "[37380/46130] loss: 0.042\n",
      "[37410/46130] loss: 0.030\n",
      "[37440/46130] loss: 0.080\n",
      "[37470/46130] loss: 0.052\n",
      "[37500/46130] loss: 0.067\n",
      "[37530/46130] loss: 0.043\n",
      "[37560/46130] loss: 0.046\n",
      "[37590/46130] loss: 0.059\n",
      "[37620/46130] loss: 0.053\n",
      "[37650/46130] loss: 0.040\n",
      "[37680/46130] loss: 0.064\n",
      "[37710/46130] loss: 0.040\n",
      "[37740/46130] loss: 0.081\n",
      "[37770/46130] loss: 0.040\n",
      "[37800/46130] loss: 0.051\n",
      "[37830/46130] loss: 0.046\n",
      "[37860/46130] loss: 0.055\n",
      "[37890/46130] loss: 0.041\n",
      "[37920/46130] loss: 0.061\n",
      "[37950/46130] loss: 0.045\n",
      "[37980/46130] loss: 0.052\n",
      "[38010/46130] loss: 0.075\n",
      "[38040/46130] loss: 0.045\n",
      "[38070/46130] loss: 0.057\n",
      "[38100/46130] loss: 0.038\n",
      "[38130/46130] loss: 0.054\n",
      "[38160/46130] loss: 0.047\n",
      "[38190/46130] loss: 0.055\n",
      "[38220/46130] loss: 0.046\n",
      "[38250/46130] loss: 0.054\n",
      "[38280/46130] loss: 0.051\n",
      "[38310/46130] loss: 0.050\n",
      "[38340/46130] loss: 0.057\n",
      "[38370/46130] loss: 0.049\n",
      "[38400/46130] loss: 0.055\n",
      "[38430/46130] loss: 0.048\n",
      "[38460/46130] loss: 0.056\n",
      "[38490/46130] loss: 0.054\n",
      "[38520/46130] loss: 0.050\n",
      "[38550/46130] loss: 0.041\n",
      "[38580/46130] loss: 0.056\n",
      "[38610/46130] loss: 0.062\n",
      "[38640/46130] loss: 0.040\n",
      "[38670/46130] loss: 0.042\n",
      "[38700/46130] loss: 0.049\n",
      "[38730/46130] loss: 0.042\n",
      "[38760/46130] loss: 0.057\n",
      "[38790/46130] loss: 0.044\n",
      "[38820/46130] loss: 0.031\n",
      "[38850/46130] loss: 0.049\n",
      "[38880/46130] loss: 0.033\n",
      "[38910/46130] loss: 0.040\n",
      "[38940/46130] loss: 0.040\n",
      "[38970/46130] loss: 0.080\n",
      "[39000/46130] loss: 0.063\n",
      "[39030/46130] loss: 0.061\n",
      "[39060/46130] loss: 0.048\n",
      "[39090/46130] loss: 0.048\n",
      "[39120/46130] loss: 0.046\n",
      "[39150/46130] loss: 0.053\n",
      "[39180/46130] loss: 0.067\n",
      "[39210/46130] loss: 0.063\n",
      "[39240/46130] loss: 0.070\n",
      "[39270/46130] loss: 0.036\n",
      "[39300/46130] loss: 0.050\n",
      "[39330/46130] loss: 0.061\n",
      "[39360/46130] loss: 0.086\n",
      "[39390/46130] loss: 0.051\n",
      "[39420/46130] loss: 0.045\n",
      "[39450/46130] loss: 0.032\n",
      "[39480/46130] loss: 0.036\n",
      "[39510/46130] loss: 0.044\n",
      "[39540/46130] loss: 0.047\n",
      "[39570/46130] loss: 0.073\n",
      "[39600/46130] loss: 0.049\n",
      "[39630/46130] loss: 0.038\n",
      "[39660/46130] loss: 0.045\n",
      "[39690/46130] loss: 0.070\n",
      "[39720/46130] loss: 0.057\n",
      "[39750/46130] loss: 0.044\n",
      "[39780/46130] loss: 0.043\n",
      "[39810/46130] loss: 0.042\n",
      "[39840/46130] loss: 0.053\n",
      "[39870/46130] loss: 0.079\n",
      "[39900/46130] loss: 0.035\n",
      "[39930/46130] loss: 0.044\n",
      "[39960/46130] loss: 0.051\n",
      "[39990/46130] loss: 0.048\n",
      "[40020/46130] loss: 0.050\n",
      "[40050/46130] loss: 0.047\n",
      "[40080/46130] loss: 0.055\n",
      "[40110/46130] loss: 0.068\n",
      "[40140/46130] loss: 0.055\n",
      "[40170/46130] loss: 0.045\n",
      "[40200/46130] loss: 0.049\n",
      "[40230/46130] loss: 0.051\n",
      "[40260/46130] loss: 0.058\n",
      "[40290/46130] loss: 0.051\n",
      "[40320/46130] loss: 0.045\n",
      "[40350/46130] loss: 0.073\n",
      "[40380/46130] loss: 0.062\n",
      "[40410/46130] loss: 0.041\n",
      "[40440/46130] loss: 0.035\n",
      "[40470/46130] loss: 0.052\n",
      "[40500/46130] loss: 0.086\n",
      "[40530/46130] loss: 0.083\n",
      "[40560/46130] loss: 0.042\n",
      "[40590/46130] loss: 0.057\n",
      "[40620/46130] loss: 0.040\n",
      "[40650/46130] loss: 0.048\n",
      "[40680/46130] loss: 0.054\n",
      "[40710/46130] loss: 0.044\n",
      "[40740/46130] loss: 0.051\n",
      "[40770/46130] loss: 0.050\n",
      "[40800/46130] loss: 0.041\n",
      "[40830/46130] loss: 0.056\n",
      "[40860/46130] loss: 0.036\n",
      "[40890/46130] loss: 0.054\n",
      "[40920/46130] loss: 0.050\n",
      "[40950/46130] loss: 0.074\n",
      "[40980/46130] loss: 0.054\n",
      "[41010/46130] loss: 0.057\n",
      "[41040/46130] loss: 0.062\n",
      "[41070/46130] loss: 0.050\n",
      "[41100/46130] loss: 0.044\n",
      "[41130/46130] loss: 0.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41160/46130] loss: 0.068\n",
      "[41190/46130] loss: 0.034\n",
      "[41220/46130] loss: 0.059\n",
      "[41250/46130] loss: 0.044\n",
      "[41280/46130] loss: 0.025\n",
      "[41310/46130] loss: 0.075\n",
      "[41340/46130] loss: 0.039\n",
      "[41370/46130] loss: 0.062\n",
      "[41400/46130] loss: 0.039\n",
      "[41430/46130] loss: 0.058\n",
      "[41460/46130] loss: 0.038\n",
      "[41490/46130] loss: 0.053\n",
      "[41520/46130] loss: 0.055\n",
      "[41550/46130] loss: 0.057\n",
      "[41580/46130] loss: 0.059\n",
      "[41610/46130] loss: 0.061\n",
      "[41640/46130] loss: 0.074\n",
      "[41670/46130] loss: 0.056\n",
      "[41700/46130] loss: 0.063\n",
      "[41730/46130] loss: 0.060\n",
      "[41760/46130] loss: 0.051\n",
      "[41790/46130] loss: 0.052\n",
      "[41820/46130] loss: 0.074\n",
      "[41850/46130] loss: 0.089\n",
      "[41880/46130] loss: 0.069\n",
      "[41910/46130] loss: 0.068\n",
      "[41940/46130] loss: 0.043\n",
      "[41970/46130] loss: 0.035\n",
      "[42000/46130] loss: 0.096\n",
      "[42030/46130] loss: 0.042\n",
      "[42060/46130] loss: 0.042\n",
      "[42090/46130] loss: 0.090\n",
      "[42120/46130] loss: 0.036\n",
      "[42150/46130] loss: 0.061\n",
      "[42180/46130] loss: 0.050\n",
      "[42210/46130] loss: 0.077\n",
      "[42240/46130] loss: 0.069\n",
      "[42270/46130] loss: 0.036\n",
      "[42300/46130] loss: 0.049\n",
      "[42330/46130] loss: 0.041\n",
      "[42360/46130] loss: 0.055\n",
      "[42390/46130] loss: 0.055\n",
      "[42420/46130] loss: 0.058\n",
      "[42450/46130] loss: 0.041\n",
      "[42480/46130] loss: 0.056\n",
      "[42510/46130] loss: 0.060\n",
      "[42540/46130] loss: 0.052\n",
      "[42570/46130] loss: 0.053\n",
      "[42600/46130] loss: 0.080\n",
      "[42630/46130] loss: 0.051\n",
      "[42660/46130] loss: 0.058\n",
      "[42690/46130] loss: 0.041\n",
      "[42720/46130] loss: 0.043\n",
      "[42750/46130] loss: 0.039\n",
      "[42780/46130] loss: 0.033\n",
      "[42810/46130] loss: 0.058\n",
      "[42840/46130] loss: 0.047\n",
      "[42870/46130] loss: 0.051\n",
      "[42900/46130] loss: 0.033\n",
      "[42930/46130] loss: 0.041\n",
      "[42960/46130] loss: 0.050\n",
      "[42990/46130] loss: 0.056\n",
      "[43020/46130] loss: 0.056\n",
      "[43050/46130] loss: 0.044\n",
      "[43080/46130] loss: 0.064\n",
      "[43110/46130] loss: 0.069\n",
      "[43140/46130] loss: 0.054\n",
      "[43170/46130] loss: 0.056\n",
      "[43200/46130] loss: 0.045\n",
      "[43230/46130] loss: 0.043\n",
      "[43260/46130] loss: 0.066\n",
      "[43290/46130] loss: 0.035\n",
      "[43320/46130] loss: 0.059\n",
      "[43350/46130] loss: 0.039\n",
      "[43380/46130] loss: 0.043\n",
      "[43410/46130] loss: 0.087\n",
      "[43440/46130] loss: 0.050\n",
      "[43470/46130] loss: 0.046\n",
      "[43500/46130] loss: 0.061\n",
      "[43530/46130] loss: 0.054\n",
      "[43560/46130] loss: 0.053\n",
      "[43590/46130] loss: 0.058\n",
      "[43620/46130] loss: 0.036\n",
      "[43650/46130] loss: 0.043\n",
      "[43680/46130] loss: 0.048\n",
      "[43710/46130] loss: 0.038\n",
      "[43740/46130] loss: 0.040\n",
      "[43770/46130] loss: 0.043\n",
      "[43800/46130] loss: 0.062\n",
      "[43830/46130] loss: 0.062\n",
      "[43860/46130] loss: 0.064\n",
      "[43890/46130] loss: 0.062\n",
      "[43920/46130] loss: 0.043\n",
      "[43950/46130] loss: 0.059\n",
      "[43980/46130] loss: 0.063\n",
      "[44010/46130] loss: 0.049\n",
      "[44040/46130] loss: 0.059\n",
      "[44070/46130] loss: 0.051\n",
      "[44100/46130] loss: 0.057\n",
      "[44130/46130] loss: 0.055\n",
      "[44160/46130] loss: 0.077\n",
      "[44190/46130] loss: 0.058\n",
      "[44220/46130] loss: 0.041\n",
      "[44250/46130] loss: 0.043\n",
      "[44280/46130] loss: 0.081\n",
      "[44310/46130] loss: 0.052\n",
      "[44340/46130] loss: 0.058\n",
      "[44370/46130] loss: 0.055\n",
      "[44400/46130] loss: 0.053\n",
      "[44430/46130] loss: 0.050\n",
      "[44460/46130] loss: 0.059\n",
      "[44490/46130] loss: 0.033\n",
      "[44520/46130] loss: 0.055\n",
      "[44550/46130] loss: 0.058\n",
      "[44580/46130] loss: 0.048\n",
      "[44610/46130] loss: 0.057\n",
      "[44640/46130] loss: 0.058\n",
      "[44670/46130] loss: 0.047\n",
      "[44700/46130] loss: 0.033\n",
      "[44730/46130] loss: 0.063\n",
      "[44760/46130] loss: 0.055\n",
      "[44790/46130] loss: 0.061\n",
      "[44820/46130] loss: 0.051\n",
      "[44850/46130] loss: 0.061\n",
      "[44880/46130] loss: 0.052\n",
      "[44910/46130] loss: 0.054\n",
      "[44940/46130] loss: 0.074\n",
      "[44970/46130] loss: 0.056\n",
      "[45000/46130] loss: 0.050\n",
      "[45030/46130] loss: 0.046\n",
      "[45060/46130] loss: 0.057\n",
      "[45090/46130] loss: 0.051\n",
      "[45120/46130] loss: 0.052\n",
      "[45150/46130] loss: 0.086\n",
      "[45180/46130] loss: 0.064\n",
      "[45210/46130] loss: 0.055\n",
      "[45240/46130] loss: 0.038\n",
      "[45270/46130] loss: 0.057\n",
      "[45300/46130] loss: 0.043\n",
      "[45330/46130] loss: 0.044\n",
      "[45360/46130] loss: 0.058\n",
      "[45390/46130] loss: 0.032\n",
      "[45420/46130] loss: 0.043\n",
      "[45450/46130] loss: 0.045\n",
      "[45480/46130] loss: 0.049\n",
      "[45510/46130] loss: 0.064\n",
      "[45540/46130] loss: 0.049\n",
      "[45570/46130] loss: 0.062\n",
      "[45600/46130] loss: 0.062\n",
      "[45630/46130] loss: 0.039\n",
      "[45660/46130] loss: 0.042\n",
      "[45690/46130] loss: 0.038\n",
      "[45720/46130] loss: 0.061\n",
      "[45750/46130] loss: 0.049\n",
      "[45780/46130] loss: 0.046\n",
      "[45810/46130] loss: 0.028\n",
      "[45840/46130] loss: 0.049\n",
      "[45870/46130] loss: 0.043\n",
      "[45900/46130] loss: 0.041\n",
      "[45930/46130] loss: 0.059\n",
      "[45960/46130] loss: 0.053\n",
      "[45990/46130] loss: 0.071\n",
      "[46020/46130] loss: 0.037\n",
      "[46050/46130] loss: 0.065\n",
      "[46080/46130] loss: 0.037\n",
      "[46110/46130] loss: 0.048\n",
      "Epoch 2 train loss: 0.0542\n",
      "Validation Accuracy: 0.9943985\n",
      "Precision: 0.6766684396608367\n",
      "Recall: 0.9613709103840683\n",
      "Validation F0.5-Score: 0.7192696554476521\n",
      "Epoch 2 val loss: 0.0563\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = trainer.fit(train_loader, val_loader, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "[30/46130] loss: 0.043\n",
      "[60/46130] loss: 0.047\n",
      "[90/46130] loss: 0.033\n",
      "[120/46130] loss: 0.046\n",
      "[150/46130] loss: 0.047\n",
      "[180/46130] loss: 0.047\n",
      "[210/46130] loss: 0.047\n",
      "[240/46130] loss: 0.060\n",
      "[270/46130] loss: 0.053\n",
      "[300/46130] loss: 0.072\n",
      "[330/46130] loss: 0.063\n",
      "[360/46130] loss: 0.047\n",
      "[390/46130] loss: 0.054\n",
      "[420/46130] loss: 0.047\n",
      "[450/46130] loss: 0.048\n",
      "[480/46130] loss: 0.070\n",
      "[510/46130] loss: 0.051\n",
      "[540/46130] loss: 0.059\n",
      "[570/46130] loss: 0.049\n",
      "[600/46130] loss: 0.054\n",
      "[630/46130] loss: 0.048\n",
      "[660/46130] loss: 0.041\n",
      "[690/46130] loss: 0.046\n",
      "[720/46130] loss: 0.062\n",
      "[750/46130] loss: 0.053\n",
      "[780/46130] loss: 0.049\n",
      "[810/46130] loss: 0.072\n",
      "[840/46130] loss: 0.045\n",
      "[870/46130] loss: 0.073\n",
      "[900/46130] loss: 0.056\n",
      "[930/46130] loss: 0.047\n",
      "[960/46130] loss: 0.057\n",
      "[990/46130] loss: 0.063\n",
      "[1020/46130] loss: 0.077\n",
      "[1050/46130] loss: 0.062\n",
      "[1080/46130] loss: 0.052\n",
      "[1110/46130] loss: 0.072\n",
      "[1140/46130] loss: 0.066\n",
      "[1170/46130] loss: 0.085\n",
      "[1200/46130] loss: 0.062\n",
      "[1230/46130] loss: 0.077\n",
      "[1260/46130] loss: 0.063\n",
      "[1290/46130] loss: 0.052\n",
      "[1320/46130] loss: 0.061\n",
      "[1350/46130] loss: 0.054\n",
      "[1380/46130] loss: 0.068\n",
      "[1410/46130] loss: 0.053\n",
      "[1440/46130] loss: 0.048\n",
      "[1470/46130] loss: 0.043\n",
      "[1500/46130] loss: 0.049\n",
      "[1530/46130] loss: 0.048\n",
      "[1560/46130] loss: 0.066\n",
      "[1590/46130] loss: 0.062\n",
      "[1620/46130] loss: 0.039\n",
      "[1650/46130] loss: 0.070\n",
      "[1680/46130] loss: 0.088\n",
      "[1710/46130] loss: 0.041\n",
      "[1740/46130] loss: 0.048\n",
      "[1770/46130] loss: 0.030\n",
      "[1800/46130] loss: 0.056\n",
      "[1830/46130] loss: 0.058\n",
      "[1860/46130] loss: 0.070\n",
      "[1890/46130] loss: 0.037\n",
      "[1920/46130] loss: 0.069\n",
      "[1950/46130] loss: 0.037\n",
      "[1980/46130] loss: 0.055\n",
      "[2010/46130] loss: 0.077\n",
      "[2040/46130] loss: 0.062\n",
      "[2070/46130] loss: 0.068\n",
      "[2100/46130] loss: 0.065\n",
      "[2130/46130] loss: 0.053\n",
      "[2160/46130] loss: 0.061\n",
      "[2190/46130] loss: 0.076\n",
      "[2220/46130] loss: 0.044\n",
      "[2250/46130] loss: 0.058\n",
      "[2280/46130] loss: 0.046\n",
      "[2310/46130] loss: 0.045\n",
      "[2340/46130] loss: 0.073\n",
      "[2370/46130] loss: 0.057\n",
      "[2400/46130] loss: 0.064\n",
      "[2430/46130] loss: 0.055\n",
      "[2460/46130] loss: 0.062\n",
      "[2490/46130] loss: 0.074\n",
      "[2520/46130] loss: 0.110\n",
      "[2550/46130] loss: 0.041\n",
      "[2580/46130] loss: 0.045\n",
      "[2610/46130] loss: 0.081\n",
      "[2640/46130] loss: 0.086\n",
      "[2670/46130] loss: 0.057\n",
      "[2700/46130] loss: 0.047\n",
      "[2730/46130] loss: 0.035\n",
      "[2760/46130] loss: 0.050\n",
      "[2790/46130] loss: 0.076\n",
      "[2820/46130] loss: 0.036\n",
      "[2850/46130] loss: 0.064\n",
      "[2880/46130] loss: 0.059\n",
      "[2910/46130] loss: 0.033\n",
      "[2940/46130] loss: 0.056\n",
      "[2970/46130] loss: 0.059\n",
      "[3000/46130] loss: 0.074\n",
      "[3030/46130] loss: 0.047\n",
      "[3060/46130] loss: 0.047\n",
      "[3090/46130] loss: 0.047\n",
      "[3120/46130] loss: 0.059\n",
      "[3150/46130] loss: 0.069\n",
      "[3180/46130] loss: 0.056\n",
      "[3210/46130] loss: 0.071\n",
      "[3240/46130] loss: 0.085\n",
      "[3270/46130] loss: 0.080\n",
      "[3300/46130] loss: 0.061\n",
      "[3330/46130] loss: 0.058\n",
      "[3360/46130] loss: 0.048\n",
      "[3390/46130] loss: 0.038\n",
      "[3420/46130] loss: 0.055\n",
      "[3450/46130] loss: 0.057\n",
      "[3480/46130] loss: 0.064\n",
      "[3510/46130] loss: 0.064\n",
      "[3540/46130] loss: 0.092\n",
      "[3570/46130] loss: 0.073\n",
      "[3600/46130] loss: 0.095\n",
      "[3630/46130] loss: 0.064\n",
      "[3660/46130] loss: 0.045\n",
      "[3690/46130] loss: 0.040\n",
      "[3720/46130] loss: 0.046\n",
      "[3750/46130] loss: 0.074\n",
      "[3780/46130] loss: 0.082\n",
      "[3810/46130] loss: 0.050\n",
      "[3840/46130] loss: 0.091\n",
      "[3870/46130] loss: 0.065\n",
      "[3900/46130] loss: 0.065\n",
      "[3930/46130] loss: 0.061\n",
      "[3960/46130] loss: 0.057\n",
      "[3990/46130] loss: 0.060\n",
      "[4020/46130] loss: 0.056\n",
      "[4050/46130] loss: 0.048\n",
      "[4080/46130] loss: 0.056\n",
      "[4110/46130] loss: 0.043\n",
      "[4140/46130] loss: 0.061\n",
      "[4170/46130] loss: 0.065\n",
      "[4200/46130] loss: 0.046\n",
      "[4230/46130] loss: 0.070\n",
      "[4260/46130] loss: 0.073\n",
      "[4290/46130] loss: 0.055\n",
      "[4320/46130] loss: 0.069\n",
      "[4350/46130] loss: 0.059\n",
      "[4380/46130] loss: 0.078\n",
      "[4410/46130] loss: 0.073\n",
      "[4440/46130] loss: 0.054\n",
      "[4470/46130] loss: 0.076\n",
      "[4500/46130] loss: 0.053\n",
      "[4530/46130] loss: 0.094\n",
      "[4560/46130] loss: 0.053\n",
      "[4590/46130] loss: 0.074\n",
      "[4620/46130] loss: 0.048\n",
      "[4650/46130] loss: 0.079\n",
      "[4680/46130] loss: 0.069\n",
      "[4710/46130] loss: 0.071\n",
      "[4740/46130] loss: 0.066\n",
      "[4770/46130] loss: 0.068\n",
      "[4800/46130] loss: 0.076\n",
      "[4830/46130] loss: 0.059\n",
      "[4860/46130] loss: 0.060\n",
      "[4890/46130] loss: 0.096\n",
      "[4920/46130] loss: 0.040\n",
      "[4950/46130] loss: 0.056\n",
      "[4980/46130] loss: 0.058\n",
      "[5010/46130] loss: 0.048\n",
      "[5040/46130] loss: 0.068\n",
      "[5070/46130] loss: 0.057\n",
      "[5100/46130] loss: 0.090\n",
      "[5130/46130] loss: 0.054\n",
      "[5160/46130] loss: 0.075\n",
      "[5190/46130] loss: 0.052\n",
      "[5220/46130] loss: 0.098\n",
      "[5250/46130] loss: 0.080\n",
      "[5280/46130] loss: 0.063\n",
      "[5310/46130] loss: 0.052\n",
      "[5340/46130] loss: 0.086\n",
      "[5370/46130] loss: 0.057\n",
      "[5400/46130] loss: 0.089\n",
      "[5430/46130] loss: 0.058\n",
      "[5460/46130] loss: 0.074\n",
      "[5490/46130] loss: 0.065\n",
      "[5520/46130] loss: 0.061\n",
      "[5550/46130] loss: 0.061\n",
      "[5580/46130] loss: 0.061\n",
      "[5610/46130] loss: 0.066\n",
      "[5640/46130] loss: 0.053\n",
      "[5670/46130] loss: 0.046\n",
      "[5700/46130] loss: 0.071\n",
      "[5730/46130] loss: 0.058\n",
      "[5760/46130] loss: 0.060\n",
      "[5790/46130] loss: 0.066\n",
      "[5820/46130] loss: 0.050\n",
      "[5850/46130] loss: 0.063\n",
      "[5880/46130] loss: 0.067\n",
      "[5910/46130] loss: 0.078\n",
      "[5940/46130] loss: 0.056\n",
      "[5970/46130] loss: 0.062\n",
      "[6000/46130] loss: 0.053\n",
      "[6030/46130] loss: 0.056\n",
      "[6060/46130] loss: 0.068\n",
      "[6090/46130] loss: 0.069\n",
      "[6120/46130] loss: 0.057\n",
      "[6150/46130] loss: 0.066\n",
      "[6180/46130] loss: 0.058\n",
      "[6210/46130] loss: 0.064\n",
      "[6240/46130] loss: 0.082\n",
      "[6270/46130] loss: 0.058\n",
      "[6300/46130] loss: 0.053\n",
      "[6330/46130] loss: 0.045\n",
      "[6360/46130] loss: 0.069\n",
      "[6390/46130] loss: 0.060\n",
      "[6420/46130] loss: 0.083\n",
      "[6450/46130] loss: 0.089\n",
      "[6480/46130] loss: 0.087\n",
      "[6510/46130] loss: 0.074\n",
      "[6540/46130] loss: 0.072\n",
      "[6570/46130] loss: 0.065\n",
      "[6600/46130] loss: 0.056\n",
      "[6630/46130] loss: 0.070\n",
      "[6660/46130] loss: 0.069\n",
      "[6690/46130] loss: 0.054\n",
      "[6720/46130] loss: 0.068\n",
      "[6750/46130] loss: 0.044\n",
      "[6780/46130] loss: 0.054\n",
      "[6810/46130] loss: 0.068\n",
      "[6840/46130] loss: 0.059\n",
      "[6870/46130] loss: 0.054\n",
      "[6900/46130] loss: 0.055\n",
      "[6930/46130] loss: 0.056\n",
      "[6960/46130] loss: 0.082\n",
      "[6990/46130] loss: 0.052\n",
      "[7020/46130] loss: 0.065\n",
      "[7050/46130] loss: 0.055\n",
      "[7080/46130] loss: 0.064\n",
      "[7110/46130] loss: 0.048\n",
      "[7140/46130] loss: 0.067\n",
      "[7170/46130] loss: 0.048\n",
      "[7200/46130] loss: 0.081\n",
      "[7230/46130] loss: 0.074\n",
      "[7260/46130] loss: 0.075\n",
      "[7290/46130] loss: 0.045\n",
      "[7320/46130] loss: 0.057\n",
      "[7350/46130] loss: 0.076\n",
      "[7380/46130] loss: 0.061\n",
      "[7410/46130] loss: 0.053\n",
      "[7440/46130] loss: 0.078\n",
      "[7470/46130] loss: 0.060\n",
      "[7500/46130] loss: 0.062\n",
      "[7530/46130] loss: 0.051\n",
      "[7560/46130] loss: 0.102\n",
      "[7590/46130] loss: 0.054\n",
      "[7620/46130] loss: 0.061\n",
      "[7650/46130] loss: 0.073\n",
      "[7680/46130] loss: 0.067\n",
      "[7710/46130] loss: 0.073\n",
      "[7740/46130] loss: 0.058\n",
      "[7770/46130] loss: 0.077\n",
      "[7800/46130] loss: 0.047\n",
      "[7830/46130] loss: 0.065\n",
      "[7860/46130] loss: 0.052\n",
      "[7890/46130] loss: 0.063\n",
      "[7920/46130] loss: 0.084\n",
      "[7950/46130] loss: 0.063\n",
      "[7980/46130] loss: 0.078\n",
      "[8010/46130] loss: 0.069\n",
      "[8040/46130] loss: 0.072\n",
      "[8070/46130] loss: 0.077\n",
      "[8100/46130] loss: 0.081\n",
      "[8130/46130] loss: 0.062\n",
      "[8160/46130] loss: 0.063\n",
      "[8190/46130] loss: 0.074\n",
      "[8220/46130] loss: 0.077\n",
      "[8250/46130] loss: 0.050\n",
      "[8280/46130] loss: 0.056\n",
      "[8310/46130] loss: 0.084\n",
      "[8340/46130] loss: 0.082\n",
      "[8370/46130] loss: 0.068\n",
      "[8400/46130] loss: 0.057\n",
      "[8430/46130] loss: 0.067\n",
      "[8460/46130] loss: 0.053\n",
      "[8490/46130] loss: 0.075\n",
      "[8520/46130] loss: 0.059\n",
      "[8550/46130] loss: 0.069\n",
      "[8580/46130] loss: 0.055\n",
      "[8610/46130] loss: 0.072\n",
      "[8640/46130] loss: 0.078\n",
      "[8670/46130] loss: 0.098\n",
      "[8700/46130] loss: 0.085\n",
      "[8730/46130] loss: 0.057\n",
      "[8760/46130] loss: 0.068\n",
      "[8790/46130] loss: 0.065\n",
      "[8820/46130] loss: 0.076\n",
      "[8850/46130] loss: 0.073\n",
      "[8880/46130] loss: 0.052\n",
      "[8910/46130] loss: 0.075\n",
      "[8940/46130] loss: 0.071\n",
      "[8970/46130] loss: 0.045\n",
      "[9000/46130] loss: 0.070\n",
      "[9030/46130] loss: 0.042\n",
      "[9060/46130] loss: 0.081\n",
      "[9090/46130] loss: 0.067\n",
      "[9120/46130] loss: 0.051\n",
      "[9150/46130] loss: 0.058\n",
      "[9180/46130] loss: 0.080\n",
      "[9210/46130] loss: 0.075\n",
      "[9240/46130] loss: 0.058\n",
      "[9270/46130] loss: 0.061\n",
      "[9300/46130] loss: 0.053\n",
      "[9330/46130] loss: 0.048\n",
      "[9360/46130] loss: 0.081\n",
      "[9390/46130] loss: 0.059\n",
      "[9420/46130] loss: 0.084\n",
      "[9450/46130] loss: 0.065\n",
      "[9480/46130] loss: 0.080\n",
      "[9510/46130] loss: 0.073\n",
      "[9540/46130] loss: 0.059\n",
      "[9570/46130] loss: 0.082\n",
      "[9600/46130] loss: 0.047\n",
      "[9630/46130] loss: 0.068\n",
      "[9660/46130] loss: 0.079\n",
      "[9690/46130] loss: 0.095\n",
      "[9720/46130] loss: 0.072\n",
      "[9750/46130] loss: 0.055\n",
      "[9780/46130] loss: 0.082\n",
      "[9810/46130] loss: 0.059\n",
      "[9840/46130] loss: 0.061\n",
      "[9870/46130] loss: 0.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9900/46130] loss: 0.053\n",
      "[9930/46130] loss: 0.060\n",
      "[9960/46130] loss: 0.055\n",
      "[9990/46130] loss: 0.058\n",
      "[10020/46130] loss: 0.060\n",
      "[10050/46130] loss: 0.052\n",
      "[10080/46130] loss: 0.081\n",
      "[10110/46130] loss: 0.073\n",
      "[10140/46130] loss: 0.072\n",
      "[10170/46130] loss: 0.061\n",
      "[10200/46130] loss: 0.061\n",
      "[10230/46130] loss: 0.072\n",
      "[10260/46130] loss: 0.047\n",
      "[10290/46130] loss: 0.071\n",
      "[10320/46130] loss: 0.055\n",
      "[10350/46130] loss: 0.094\n",
      "[10380/46130] loss: 0.060\n",
      "[10410/46130] loss: 0.078\n",
      "[10440/46130] loss: 0.081\n",
      "[10470/46130] loss: 0.078\n",
      "[10500/46130] loss: 0.063\n",
      "[10530/46130] loss: 0.073\n",
      "[10560/46130] loss: 0.042\n",
      "[10590/46130] loss: 0.054\n",
      "[10620/46130] loss: 0.068\n",
      "[10650/46130] loss: 0.051\n",
      "[10680/46130] loss: 0.067\n",
      "[10710/46130] loss: 0.070\n",
      "[10740/46130] loss: 0.048\n",
      "[10770/46130] loss: 0.043\n",
      "[10800/46130] loss: 0.046\n",
      "[10830/46130] loss: 0.075\n",
      "[10860/46130] loss: 0.058\n",
      "[10890/46130] loss: 0.068\n",
      "[10920/46130] loss: 0.063\n",
      "[10950/46130] loss: 0.083\n",
      "[10980/46130] loss: 0.058\n",
      "[11010/46130] loss: 0.045\n",
      "[11040/46130] loss: 0.061\n",
      "[11070/46130] loss: 0.051\n",
      "[11100/46130] loss: 0.093\n",
      "[11130/46130] loss: 0.075\n",
      "[11160/46130] loss: 0.071\n",
      "[11190/46130] loss: 0.059\n",
      "[11220/46130] loss: 0.068\n",
      "[11250/46130] loss: 0.046\n",
      "[11280/46130] loss: 0.067\n",
      "[11310/46130] loss: 0.060\n",
      "[11340/46130] loss: 0.072\n",
      "[11370/46130] loss: 0.061\n",
      "[11400/46130] loss: 0.047\n",
      "[11430/46130] loss: 0.069\n",
      "[11460/46130] loss: 0.080\n",
      "[11490/46130] loss: 0.050\n",
      "[11520/46130] loss: 0.058\n",
      "[11550/46130] loss: 0.076\n",
      "[11580/46130] loss: 0.054\n",
      "[11610/46130] loss: 0.070\n",
      "[11640/46130] loss: 0.077\n",
      "[11670/46130] loss: 0.055\n",
      "[11700/46130] loss: 0.088\n",
      "[11730/46130] loss: 0.074\n",
      "[11760/46130] loss: 0.081\n",
      "[11790/46130] loss: 0.066\n",
      "[11820/46130] loss: 0.059\n",
      "[11850/46130] loss: 0.049\n",
      "[11880/46130] loss: 0.071\n",
      "[11910/46130] loss: 0.057\n",
      "[11940/46130] loss: 0.063\n",
      "[11970/46130] loss: 0.084\n",
      "[12000/46130] loss: 0.072\n",
      "[12030/46130] loss: 0.060\n",
      "[12060/46130] loss: 0.072\n",
      "[12090/46130] loss: 0.061\n",
      "[12120/46130] loss: 0.056\n",
      "[12150/46130] loss: 0.046\n",
      "[12180/46130] loss: 0.086\n",
      "[12210/46130] loss: 0.060\n",
      "[12240/46130] loss: 0.073\n",
      "[12270/46130] loss: 0.047\n",
      "[12300/46130] loss: 0.064\n",
      "[12330/46130] loss: 0.067\n",
      "[12360/46130] loss: 0.079\n",
      "[12390/46130] loss: 0.066\n",
      "[12420/46130] loss: 0.085\n",
      "[12450/46130] loss: 0.065\n",
      "[12480/46130] loss: 0.054\n",
      "[12510/46130] loss: 0.069\n",
      "[12540/46130] loss: 0.059\n",
      "[12570/46130] loss: 0.048\n",
      "[12600/46130] loss: 0.082\n",
      "[12630/46130] loss: 0.054\n",
      "[12660/46130] loss: 0.079\n",
      "[12690/46130] loss: 0.092\n",
      "[12720/46130] loss: 0.066\n",
      "[12750/46130] loss: 0.059\n",
      "[12780/46130] loss: 0.061\n",
      "[12810/46130] loss: 0.090\n",
      "[12840/46130] loss: 0.053\n",
      "[12870/46130] loss: 0.059\n",
      "[12900/46130] loss: 0.070\n",
      "[12930/46130] loss: 0.046\n",
      "[12960/46130] loss: 0.071\n",
      "[12990/46130] loss: 0.062\n",
      "[13020/46130] loss: 0.061\n",
      "[13050/46130] loss: 0.094\n",
      "[13080/46130] loss: 0.064\n",
      "[13110/46130] loss: 0.049\n",
      "[13140/46130] loss: 0.064\n",
      "[13170/46130] loss: 0.074\n",
      "[13200/46130] loss: 0.076\n",
      "[13230/46130] loss: 0.058\n",
      "[13260/46130] loss: 0.061\n",
      "[13290/46130] loss: 0.069\n",
      "[13320/46130] loss: 0.039\n",
      "[13350/46130] loss: 0.087\n",
      "[13380/46130] loss: 0.069\n",
      "[13410/46130] loss: 0.091\n",
      "[13440/46130] loss: 0.066\n",
      "[13470/46130] loss: 0.068\n",
      "[13500/46130] loss: 0.069\n",
      "[13530/46130] loss: 0.057\n",
      "[13560/46130] loss: 0.070\n",
      "[13590/46130] loss: 0.075\n",
      "[13620/46130] loss: 0.066\n",
      "[13650/46130] loss: 0.070\n",
      "[13680/46130] loss: 0.054\n",
      "[13710/46130] loss: 0.060\n",
      "[13740/46130] loss: 0.041\n",
      "[13770/46130] loss: 0.065\n",
      "[13800/46130] loss: 0.071\n",
      "[13830/46130] loss: 0.083\n",
      "[13860/46130] loss: 0.061\n",
      "[13890/46130] loss: 0.058\n",
      "[13920/46130] loss: 0.073\n",
      "[13950/46130] loss: 0.062\n",
      "[13980/46130] loss: 0.054\n",
      "[14010/46130] loss: 0.043\n",
      "[14040/46130] loss: 0.083\n",
      "[14070/46130] loss: 0.074\n",
      "[14100/46130] loss: 0.083\n",
      "[14130/46130] loss: 0.089\n",
      "[14160/46130] loss: 0.047\n",
      "[14190/46130] loss: 0.075\n",
      "[14220/46130] loss: 0.061\n",
      "[14250/46130] loss: 0.061\n",
      "[14280/46130] loss: 0.056\n",
      "[14310/46130] loss: 0.047\n",
      "[14340/46130] loss: 0.060\n",
      "[14370/46130] loss: 0.061\n",
      "[14400/46130] loss: 0.043\n",
      "[14430/46130] loss: 0.081\n",
      "[14460/46130] loss: 0.050\n",
      "[14490/46130] loss: 0.051\n",
      "[14520/46130] loss: 0.063\n",
      "[14550/46130] loss: 0.066\n",
      "[14580/46130] loss: 0.072\n",
      "[14610/46130] loss: 0.067\n",
      "[14640/46130] loss: 0.058\n",
      "[14670/46130] loss: 0.074\n",
      "[14700/46130] loss: 0.057\n",
      "[14730/46130] loss: 0.059\n",
      "[14760/46130] loss: 0.058\n",
      "[14790/46130] loss: 0.046\n",
      "[14820/46130] loss: 0.067\n",
      "[14850/46130] loss: 0.054\n",
      "[14880/46130] loss: 0.082\n",
      "[14910/46130] loss: 0.051\n",
      "[14940/46130] loss: 0.084\n",
      "[14970/46130] loss: 0.044\n",
      "[15000/46130] loss: 0.073\n",
      "[15030/46130] loss: 0.073\n",
      "[15060/46130] loss: 0.065\n",
      "[15090/46130] loss: 0.065\n",
      "[15120/46130] loss: 0.068\n",
      "[15150/46130] loss: 0.073\n",
      "[15180/46130] loss: 0.046\n",
      "[15210/46130] loss: 0.056\n",
      "[15240/46130] loss: 0.069\n",
      "[15270/46130] loss: 0.058\n",
      "[15300/46130] loss: 0.058\n",
      "[15330/46130] loss: 0.061\n",
      "[15360/46130] loss: 0.065\n",
      "[15390/46130] loss: 0.085\n",
      "[15420/46130] loss: 0.067\n",
      "[15450/46130] loss: 0.081\n",
      "[15480/46130] loss: 0.086\n",
      "[15510/46130] loss: 0.089\n",
      "[15540/46130] loss: 0.078\n",
      "[15570/46130] loss: 0.079\n",
      "[15600/46130] loss: 0.067\n",
      "[15630/46130] loss: 0.058\n",
      "[15660/46130] loss: 0.072\n",
      "[15690/46130] loss: 0.047\n",
      "[15720/46130] loss: 0.058\n",
      "[15750/46130] loss: 0.043\n",
      "[15780/46130] loss: 0.063\n",
      "[15810/46130] loss: 0.068\n",
      "[15840/46130] loss: 0.060\n",
      "[15870/46130] loss: 0.075\n",
      "[15900/46130] loss: 0.080\n",
      "[15930/46130] loss: 0.057\n",
      "[15960/46130] loss: 0.094\n",
      "[15990/46130] loss: 0.066\n",
      "[16020/46130] loss: 0.072\n",
      "[16050/46130] loss: 0.070\n",
      "[16080/46130] loss: 0.081\n",
      "[16110/46130] loss: 0.071\n",
      "[16140/46130] loss: 0.072\n",
      "[16170/46130] loss: 0.048\n",
      "[16200/46130] loss: 0.056\n",
      "[16230/46130] loss: 0.059\n",
      "[16260/46130] loss: 0.077\n",
      "[16290/46130] loss: 0.076\n",
      "[16320/46130] loss: 0.068\n",
      "[16350/46130] loss: 0.080\n",
      "[16380/46130] loss: 0.069\n",
      "[16410/46130] loss: 0.058\n",
      "[16440/46130] loss: 0.063\n",
      "[16470/46130] loss: 0.082\n",
      "[16500/46130] loss: 0.068\n",
      "[16530/46130] loss: 0.071\n",
      "[16560/46130] loss: 0.061\n",
      "[16590/46130] loss: 0.069\n",
      "[16620/46130] loss: 0.054\n",
      "[16650/46130] loss: 0.051\n",
      "[16680/46130] loss: 0.084\n",
      "[16710/46130] loss: 0.036\n",
      "[16740/46130] loss: 0.064\n",
      "[16770/46130] loss: 0.067\n",
      "[16800/46130] loss: 0.062\n",
      "[16830/46130] loss: 0.062\n",
      "[16860/46130] loss: 0.055\n",
      "[16890/46130] loss: 0.076\n",
      "[16920/46130] loss: 0.044\n",
      "[16950/46130] loss: 0.080\n",
      "[16980/46130] loss: 0.063\n",
      "[17010/46130] loss: 0.066\n",
      "[17040/46130] loss: 0.073\n",
      "[17070/46130] loss: 0.101\n",
      "[17100/46130] loss: 0.093\n",
      "[17130/46130] loss: 0.068\n",
      "[17160/46130] loss: 0.101\n",
      "[17190/46130] loss: 0.070\n",
      "[17220/46130] loss: 0.060\n",
      "[17250/46130] loss: 0.061\n",
      "[17280/46130] loss: 0.083\n",
      "[17310/46130] loss: 0.056\n",
      "[17340/46130] loss: 0.103\n",
      "[17370/46130] loss: 0.065\n",
      "[17400/46130] loss: 0.068\n",
      "[17430/46130] loss: 0.064\n",
      "[17460/46130] loss: 0.076\n",
      "[17490/46130] loss: 0.109\n",
      "[17520/46130] loss: 0.092\n",
      "[17550/46130] loss: 0.068\n",
      "[17580/46130] loss: 0.048\n",
      "[17610/46130] loss: 0.068\n",
      "[17640/46130] loss: 0.070\n",
      "[17670/46130] loss: 0.087\n",
      "[17700/46130] loss: 0.061\n",
      "[17730/46130] loss: 0.058\n",
      "[17760/46130] loss: 0.048\n",
      "[17790/46130] loss: 0.056\n",
      "[17820/46130] loss: 0.056\n",
      "[17850/46130] loss: 0.059\n",
      "[17880/46130] loss: 0.076\n",
      "[17910/46130] loss: 0.050\n",
      "[17940/46130] loss: 0.058\n",
      "[17970/46130] loss: 0.102\n",
      "[18000/46130] loss: 0.077\n",
      "[18030/46130] loss: 0.052\n",
      "[18060/46130] loss: 0.059\n",
      "[18090/46130] loss: 0.056\n",
      "[18120/46130] loss: 0.065\n",
      "[18150/46130] loss: 0.087\n",
      "[18180/46130] loss: 0.045\n",
      "[18210/46130] loss: 0.086\n",
      "[18240/46130] loss: 0.056\n",
      "[18270/46130] loss: 0.093\n",
      "[18300/46130] loss: 0.064\n",
      "[18330/46130] loss: 0.069\n",
      "[18360/46130] loss: 0.068\n",
      "[18390/46130] loss: 0.053\n",
      "[18420/46130] loss: 0.065\n",
      "[18450/46130] loss: 0.089\n",
      "[18480/46130] loss: 0.062\n",
      "[18510/46130] loss: 0.062\n",
      "[18540/46130] loss: 0.078\n",
      "[18570/46130] loss: 0.073\n",
      "[18600/46130] loss: 0.098\n",
      "[18630/46130] loss: 0.055\n",
      "[18660/46130] loss: 0.088\n",
      "[18690/46130] loss: 0.080\n",
      "[18720/46130] loss: 0.079\n",
      "[18750/46130] loss: 0.055\n",
      "[18780/46130] loss: 0.052\n",
      "[18810/46130] loss: 0.057\n",
      "[18840/46130] loss: 0.079\n",
      "[18870/46130] loss: 0.079\n",
      "[18900/46130] loss: 0.048\n",
      "[18930/46130] loss: 0.099\n",
      "[18960/46130] loss: 0.046\n",
      "[18990/46130] loss: 0.081\n",
      "[19020/46130] loss: 0.088\n",
      "[19050/46130] loss: 0.079\n",
      "[19080/46130] loss: 0.084\n",
      "[19110/46130] loss: 0.067\n",
      "[19140/46130] loss: 0.069\n",
      "[19170/46130] loss: 0.063\n",
      "[19200/46130] loss: 0.063\n",
      "[19230/46130] loss: 0.097\n",
      "[19260/46130] loss: 0.073\n",
      "[19290/46130] loss: 0.063\n",
      "[19320/46130] loss: 0.075\n",
      "[19350/46130] loss: 0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19380/46130] loss: 0.049\n",
      "[19410/46130] loss: 0.073\n",
      "[19440/46130] loss: 0.092\n",
      "[19470/46130] loss: 0.086\n",
      "[19500/46130] loss: 0.077\n",
      "[19530/46130] loss: 0.059\n",
      "[19560/46130] loss: 0.069\n",
      "[19590/46130] loss: 0.074\n",
      "[19620/46130] loss: 0.066\n",
      "[19650/46130] loss: 0.037\n",
      "[19680/46130] loss: 0.068\n",
      "[19710/46130] loss: 0.066\n",
      "[19740/46130] loss: 0.054\n",
      "[19770/46130] loss: 0.053\n",
      "[19800/46130] loss: 0.071\n",
      "[19830/46130] loss: 0.056\n",
      "[19860/46130] loss: 0.072\n",
      "[19890/46130] loss: 0.049\n",
      "[19920/46130] loss: 0.073\n",
      "[19950/46130] loss: 0.040\n",
      "[19980/46130] loss: 0.065\n",
      "[20010/46130] loss: 0.073\n",
      "[20040/46130] loss: 0.067\n",
      "[20070/46130] loss: 0.064\n",
      "[20100/46130] loss: 0.049\n",
      "[20130/46130] loss: 0.071\n",
      "[20160/46130] loss: 0.052\n",
      "[20190/46130] loss: 0.086\n",
      "[20220/46130] loss: 0.064\n",
      "[20250/46130] loss: 0.072\n",
      "[20280/46130] loss: 0.063\n",
      "[20310/46130] loss: 0.036\n",
      "[20340/46130] loss: 0.058\n",
      "[20370/46130] loss: 0.055\n",
      "[20400/46130] loss: 0.064\n",
      "[20430/46130] loss: 0.069\n",
      "[20460/46130] loss: 0.059\n",
      "[20490/46130] loss: 0.065\n",
      "[20520/46130] loss: 0.082\n",
      "[20550/46130] loss: 0.093\n",
      "[20580/46130] loss: 0.090\n"
     ]
    }
   ],
   "source": [
    "train_loss2, val_loss2 = trainer.fit(train_loader, val_loader, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(train_loss, label='Train loss')\n",
    "plt.plot(val_loss, label='Val loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss');\n",
    "plt.xlim(0, 60)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('{}/loss.png'.format(weights_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
